{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e975c5",
   "metadata": {},
   "source": [
    "# 3. Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe786c",
   "metadata": {},
   "source": [
    "## 3.1. Environment Setup\n",
    "Detect if running in Google Colab or local environment, handle repository cloning, dependency installation, numpy compatibility fixes, and set up Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import hopsworks\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "for folder in (\"src\", \"airquality\", \"notebooks\"):\n",
    "    if root_dir.parts[-1:] == (folder,):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir)\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "from utils import config\n",
    "\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181ddad",
   "metadata": {},
   "source": [
    "## 3.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import hopsworks\n",
    "from utils import airquality\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63871bc",
   "metadata": {},
   "source": [
    "## 3.3. Hopsworks configuration\n",
    "Configure Hopsworks connection, retrieve API keys, connect to feature store, and get air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "    HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d898071a",
   "metadata": {},
   "source": [
    "## 3.4. Sensor Location Loading\n",
    "Load sensor location metadata from Hopsworks secrets for all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sensor locations from Hopsworks secrets\n",
    "all_secrets = secrets.get_secrets()\n",
    "locations = {}\n",
    "for secret in all_secrets:\n",
    "    if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "        sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "        location_str = secrets.get_secret(secret.name).value\n",
    "        if location_str:\n",
    "            locations[sensor_id] = json.loads(location_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dec32e",
   "metadata": {},
   "source": [
    "## 3.5. Feature View Creation\n",
    "Create multiple feature views with different feature combinations (baseline, rolling windows, lagged features, nearby sensors, complete) for model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "baseline_features = air_quality_fg.select([\"pm25\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "\n",
    "baseline_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_baseline_fv\",\n",
    "    description=\"Weather features for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=baseline_features,\n",
    ")\n",
    "\n",
    "rolling_features = air_quality_fg.select([\"pm25\", \"pm25_rolling_3d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "rolling_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_rolling_fv\",\n",
    "    description=\"Weather features, PM2.5 rolling window (3d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=rolling_features,\n",
    ")\n",
    "\n",
    "nearby_features = air_quality_fg.select([\"pm25\", \"pm25_nearby_avg\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "nearby_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_nearby_fv\",\n",
    "    description=\"Weather features, PM2.5 nearby average (1d lag, 3 sensors) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=nearby_features,\n",
    ")\n",
    "\n",
    "lagged_1d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_1d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_1d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_1d_features,\n",
    ")\n",
    "\n",
    "lagged_2d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_2d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_2d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d, 2d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_2d_features,\n",
    ")\n",
    "\n",
    "lagged_3d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"pm25_lag_3d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_3d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_3d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d, 2d, 3d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_3d_features,\n",
    ")\n",
    "\n",
    "complete_features = air_quality_fg.select([\"pm25\", \"pm25_rolling_3d\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"pm25_lag_3d\", \"pm25_nearby_avg\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "complete_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_complete_fv\",\n",
    "    description=\"Weather features, PM2.5 rolling window (3d), and PM2.5 lags (1d, 2d, 3d), and PM2.5 nearby average (1d lag, 3 sensors) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=complete_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b046b",
   "metadata": {},
   "source": [
    "## 3.6. Model Training Setup\n",
    "Set up test data split date, initialize containers for models and predictions, and define feature view dictionary for iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_test_data = \"2025-04-01\"\n",
    "# test_start = datetime.strptime(start_date_test_data, \"%Y-%m-%d\")\n",
    "\n",
    "models = defaultdict(dict)\n",
    "y_preds = defaultdict(dict)\n",
    "results = []\n",
    "\n",
    "feature_views = {\n",
    "    \"baseline\": baseline_feature_view,\n",
    "    \"rolling\": rolling_feature_view,\n",
    "    \"nearby\": nearby_feature_view,\n",
    "    \"lagged_1d\": lagged_1d_feature_view,\n",
    "    \"lagged_2d\": lagged_2d_feature_view,\n",
    "    \"lagged_3d\": lagged_3d_feature_view,\n",
    "    \"complete\": complete_feature_view,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105059a",
   "metadata": {},
   "source": [
    "## 3.7. Model Training Loop\n",
    "Train XGBoost models for each feature combination and sensor, run 5 iterations per configuration, select best model based on R2 score, and store results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name, feature_view in feature_views.items():\n",
    "    data = feature_view.query.read()\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.tz_localize(None)\n",
    "\n",
    "    for sensor_id in locations.keys():\n",
    "        df = data[data['sensor_id'] == sensor_id].copy()\n",
    "        \n",
    "        # Clean the data before splitting\n",
    "        df = df.dropna(subset=['pm25'])\n",
    "        features_for_cleaning = df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "        target_for_cleaning = df[\"pm25\"]\n",
    "        clean_mask = ~(features_for_cleaning.isna().any(axis=1) | target_for_cleaning.isna())\n",
    "        df_clean = df[clean_mask].copy()\n",
    "        if len(df_clean) < 10:\n",
    "            print(f\"⚠️  Skipping sensor {sensor_id}: insufficient data after cleaning ({len(df_clean)} rows)\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        train_size = int(0.8 * len(df_clean))\n",
    "        train_df = df_clean.iloc[:train_size]\n",
    "        test_df = df_clean.iloc[train_size:]\n",
    "        \n",
    "        if len(test_df) < 2:\n",
    "            print(f\"⚠️  Skipping sensor {sensor_id}: test set too small after split ({len(test_df)} rows)\")\n",
    "            continue\n",
    "\n",
    "        # Drop non-feature columns (pm25 is target, others are metadata)\n",
    "        X_train = train_df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "        y_train = train_df[\"pm25\"]\n",
    "        X_test = test_df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "        y_test = test_df[\"pm25\"]\n",
    "        \n",
    "        # run three times and take the best model, save the average of the three\n",
    "        best_r2 = -float('inf')\n",
    "        best_mse = float('inf')\n",
    "        best_model = None\n",
    "        \n",
    "        mse_list = []\n",
    "        r2_list = []\n",
    "        for i in range(5):\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=165439*i)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2_list.append(r2)\n",
    "            mse_list.append(mse)\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_mse = mse\n",
    "                best_model = model\n",
    "\n",
    "        models[feature_name][sensor_id] = best_model\n",
    "        \n",
    "        if best_model is not None:\n",
    "            y_preds[feature_name][sensor_id] = best_model.predict(X_test)\n",
    "            \n",
    "            results.append({\n",
    "                \"feature_name\": feature_name,\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"MSE\": sum(mse_list) / len(mse_list),\n",
    "                \"R2\": sum(r2_list) / len(r2_list),\n",
    "                \"train_size\": len(X_train),\n",
    "                \"test_size\": len(X_test)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"⚠️  No valid model trained for {feature_name} - {sensor_id}, R2 scores: {r2_list}, Best R2: {best_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cd11c",
   "metadata": {},
   "source": [
    "## 3.8. Create Model Directory\n",
    "To store trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = f\"{root_dir}/models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066be29",
   "metadata": {},
   "source": [
    "## 3.9. Model Selection and Saving\n",
    "Identify best performing model for each sensor, save models and feature importance plots, and prepare test data with predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee87500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model (highest R2) for each sensor\n",
    "results_df = pd.DataFrame(results)\n",
    "best_models = results_df.loc[results_df.groupby('sensor_id')['R2'].idxmax()]\n",
    "# print(\"Best models per sensor:\")\n",
    "# print(best_models[['sensor_id', 'feature_name', 'R2', 'MSE']])\n",
    "\n",
    "all_data = baseline_features.read()\n",
    "all_data['date'] = pd.to_datetime(all_data['date']).dt.tz_localize(None)\n",
    "\n",
    "all_test_data = []\n",
    "for _, row in best_models.iterrows():\n",
    "    sensor_id = row['sensor_id']\n",
    "    best_feature = row['feature_name']\n",
    "    \n",
    "    sensor_dir = f\"{model_dir}/{sensor_id}\"\n",
    "    if not os.path.exists(sensor_dir):\n",
    "        os.mkdir(sensor_dir)\n",
    "    images_dir = f\"{model_dir}/{sensor_id}/images\"\n",
    "    if not os.path.exists(images_dir):\n",
    "        os.mkdir(images_dir)\n",
    "\n",
    "    best_model = models[best_feature][sensor_id]\n",
    "    model_path = f\"{sensor_dir}/model.json\"\n",
    "    plot_importance(best_model)\n",
    "    importance_path = f\"{images_dir}/feature_importance.png\"\n",
    "    plt.savefig(importance_path)\n",
    "    plt.close()\n",
    "    \n",
    "    best_model.save_model(model_path)\n",
    "\n",
    "    # Use the same feature view and data processing logic that was used for training\n",
    "    best_feature_view = feature_views[best_feature]\n",
    "    sensor_data = best_feature_view.query.read()\n",
    "    sensor_data['date'] = pd.to_datetime(sensor_data['date']).dt.tz_localize(None)\n",
    "    \n",
    "    df = sensor_data[sensor_data['sensor_id'] == sensor_id].copy()\n",
    "    \n",
    "    # Apply EXACT same cleaning logic as in training loop\n",
    "    df = df.dropna(subset=['pm25'])\n",
    "    \n",
    "    # Create feature matrix for comprehensive NaN cleaning (same as training)\n",
    "    features_for_cleaning = df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "    target_for_cleaning = df[\"pm25\"]\n",
    "    \n",
    "    # Remove rows with NaN values in any feature or target (same as training)\n",
    "    clean_mask = ~(features_for_cleaning.isna().any(axis=1) | target_for_cleaning.isna())\n",
    "    df_clean = df[clean_mask].copy()\n",
    "    \n",
    "    if len(df_clean) < 10:\n",
    "        continue\n",
    "        \n",
    "    # Split the cleaned data (same as training)\n",
    "    train_size = int(0.8 * len(df_clean))\n",
    "    test_df = df_clean.iloc[train_size:].copy()\n",
    "    \n",
    "    if len(test_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Test data is already clean from the comprehensive cleaning above\n",
    "    clean_test_df = test_df.copy()\n",
    "    predictions = y_preds[best_feature][sensor_id]\n",
    "    \n",
    "    if len(clean_test_df) == len(predictions):\n",
    "        clean_test_df['predicted_pm25'] = predictions\n",
    "        clean_test_df['best_model'] = best_feature\n",
    "        all_test_data.append(clean_test_df[['date', 'pm25', 'predicted_pm25', 'latitude', 'longitude', 'best_model']])\n",
    "    else:\n",
    "        print(f\"⚠️  Skipping sensor {sensor_id}: prediction length mismatch ({len(predictions)} vs {len(clean_test_df)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e31b22",
   "metadata": {},
   "source": [
    "## 3.10. Model Registration & Visualization\n",
    "Create prediction plots for each sensor, register model in Hopsworks model registry with metrics and metadata, and save models with their configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "df = pd.concat(all_test_data, ignore_index=True) if all_test_data else pd.DataFrame()\n",
    "df = df.sort_values(by=[\"date\"])\n",
    "\n",
    "# Plot the best model for each sensor\n",
    "for sensor_id, location in locations.items():\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "    \n",
    "    df_subset = df[(df[\"latitude\"] == latitude) & (df[\"longitude\"] == longitude)].copy()\n",
    "    if len(df_subset) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get the best model name for display\n",
    "    best_model_name = df_subset['best_model'].iloc[0] if 'best_model' in df_subset.columns else 'unknown'\n",
    "    best_model_r2 = df_subset['R2'].iloc[0] if 'R2' in df_subset.columns else 0\n",
    "    best_model_mse = df_subset['MSE'].iloc[0] if 'MSE' in df_subset.columns else 0\n",
    "    best_model_feature_view = feature_views[best_model_name]\n",
    "    \n",
    "    df_subset = df_subset.sort_values(by=[\"date\"])\n",
    "    df_subset = df_subset.drop(columns=[\"latitude\", \"longitude\", \"best_model\"])\n",
    "    \n",
    "    images_dir = f\"{model_dir}/{sensor_id}/images\"\n",
    "    image_path = f\"{images_dir}/hindcast_training.png\"\n",
    "    \n",
    "    plt = airquality.plot_air_quality_forecast(\n",
    "        city, street, df_subset, image_path, hindcast=True\n",
    "    )\n",
    "    plt.title(f\"{city} {street} (Best Model: {best_model_name})\")\n",
    "\n",
    "    aq_model = mr.python.create_model(\n",
    "        name=f\"air_quality_xgboost_model_{sensor_id}\",\n",
    "        metrics={\n",
    "            \"R2\": best_model_r2,\n",
    "            \"MSE\": best_model_mse,\n",
    "        },\n",
    "        feature_view=best_model_feature_view,\n",
    "        description=f\"Air Quality (PM2.5) predictor for {city} {street} using {best_model_name} configuration\",\n",
    "    )\n",
    "\n",
    "    aq_model.save(f\"{model_dir}/{sensor_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
