{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e975c5",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    # Check if repository already exists\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "def fix_numpy_compatibility():\n",
    "    print(\"Fixing numpy compatibility for hopsworks/pandas...\")\n",
    "    try:\n",
    "        # Use precompiled wheels with compatible versions\n",
    "        !pip install --force-reinstall numpy==1.24.4 pandas==2.0.3\n",
    "        print(\"Numpy and pandas fixed. Please restart runtime and run again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fix attempt failed: {e}\")\n",
    "        print(\"Please manually restart runtime and try again.\")\n",
    "\n",
    "if is_google_colab():\n",
    "    try:\n",
    "        import numpy\n",
    "        numpy.array([1, 2, 3])\n",
    "        import pandas as pd\n",
    "        print(\"Basic packages working correctly\")\n",
    "\n",
    "        clone_repository()\n",
    "        install_dependencies()\n",
    "\n",
    "        import hopsworks\n",
    "        print(\"All packages working correctly\")\n",
    "\n",
    "        root_dir = str(Path().absolute())\n",
    "        print(\"Google Colab environment\")\n",
    "        \n",
    "    except (ValueError, ImportError) as e:\n",
    "        if \"numpy.dtype size changed\" in str(e) or \"numpy.strings\" in str(e) or \"numpy\" in str(e).lower():\n",
    "            fix_numpy_compatibility()\n",
    "            raise SystemExit(\"Please restart runtime (Runtime > Restart runtime) and run the notebook again.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    if root_dir.parts[-1:] == (\"src\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"airquality\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"notebooks\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "from utils import config\n",
    "\n",
    "if is_google_colab():\n",
    "    from google.colab import userdata\n",
    "    import hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=userdata.get('HOPSWORKS_API_KEY'),\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    AQICN_API_KEY = userdata.get('AQICN_API_KEY')\n",
    "    \n",
    "else:\n",
    "    # Local development - use .env file\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181ddad",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import hopsworks\n",
    "from utils import airquality\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63871bc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    fs = project.get_feature_store()\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "else:\n",
    "    HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "    if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "        HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "    project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d898071a",
   "metadata": {},
   "source": [
    "Set SENSOR_CSV_FILE in .env with the relative path to a sensor to process it, or leave it unset to process all sensors in the `data` foldertoday = datetime.today().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    sensor_csv_file = None\n",
    "else:\n",
    "    sensor_csv_file = getattr(settings, 'SENSOR_CSV_FILE', None)\n",
    "\n",
    "if sensor_csv_file:\n",
    "    # Read one secret for single sensor mode\n",
    "    _, _, _, _, _, sensor_id = airquality.read_sensor_data(sensor_csv_file)\n",
    "    secret_name = f\"SENSOR_LOCATION_JSON_{sensor_id}\"\n",
    "    location_str = secrets.get_secret(secret_name).value\n",
    "    locations = {sensor_id: json.loads(location_str)}\n",
    "else:\n",
    "    # Read all individual secrets in batch mode\n",
    "    all_secrets = secrets.get_secrets()\n",
    "    locations = {}\n",
    "    for secret in all_secrets:\n",
    "        if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "            sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "            location_str = secrets.get_secret(secret.name).value\n",
    "            if location_str:\n",
    "                locations[sensor_id] = json.loads(location_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dec32e",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "baseline_features = air_quality_fg.select([\"pm25\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "\n",
    "baseline_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_baseline_fv\",\n",
    "    description=\"Weather features for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=baseline_features,\n",
    ")\n",
    "\n",
    "rolling_features = air_quality_fg.select([\"pm25\", \"pm25_rolling_3d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "rolling_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_rolling_fv\",\n",
    "    description=\"Weather features, PM2.5 rolling window (3d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=rolling_features,\n",
    ")\n",
    "\n",
    "nearby_features = air_quality_fg.select([\"pm25\", \"pm25_nearby_avg\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "nearby_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_nearby_fv\",\n",
    "    description=\"Weather features, PM2.5 nearby average (1d lag, 3 sensors) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=nearby_features,\n",
    ")\n",
    "\n",
    "lagged_1d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_1d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_1d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_1d_features,\n",
    ")\n",
    "\n",
    "lagged_2d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_2d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_2d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d, 2d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_2d_features,\n",
    ")\n",
    "\n",
    "lagged_3d_features = air_quality_fg.select([\"pm25\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"pm25_lag_3d\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "lagged_3d_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_lagged_3d_fv\",\n",
    "    description=\"Weather features, PM2.5 lags (1d, 2d, 3d) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=lagged_3d_features,\n",
    ")\n",
    "\n",
    "complete_features = air_quality_fg.select([\"pm25\", \"pm25_rolling_3d\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"pm25_lag_3d\", \"pm25_nearby_avg\", \"date\", \"sensor_id\"]).join(\n",
    "    weather_fg.select_features(), on=[\"sensor_id\"]\n",
    ")\n",
    "complete_feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_complete_fv\",\n",
    "    description=\"Weather features, PM2.5 rolling window (3d), and PM2.5 lags (1d, 2d, 3d), and PM2.5 nearby average (1d lag, 3 sensors) for PM2.5 prediction\",\n",
    "    version=1,\n",
    "    labels=[\"pm25\"],\n",
    "    query=complete_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date_test_data = \"2025-05-01\"\n",
    "test_start = datetime.strptime(start_date_test_data, \"%Y-%m-%d\")\n",
    "\n",
    "models = defaultdict(dict)\n",
    "y_preds = defaultdict(dict)\n",
    "results = []\n",
    "\n",
    "feature_views = {\n",
    "    \"baseline\": baseline_feature_view,\n",
    "    \"rolling\": rolling_feature_view,\n",
    "    \"nearby\": nearby_feature_view,\n",
    "    \"lagged_1d\": lagged_1d_feature_view,\n",
    "    \"lagged_2d\": lagged_2d_feature_view,\n",
    "    \"lagged_3d\": lagged_3d_feature_view,\n",
    "    \"complete\": complete_feature_view,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name, feature_view in feature_views.items():\n",
    "    data = feature_view.query.read()\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.tz_localize(None)\n",
    "\n",
    "    for sensor_id in locations.keys():\n",
    "        df = data[data['sensor_id'] == sensor_id].copy()\n",
    "        train_df = df[df['date'] < test_start]\n",
    "        test_df = df[df['date'] >= test_start]\n",
    "\n",
    "        # Drop non-feature columns (pm25 is target, others are metadata)\n",
    "        X_train = train_df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "        y_train = train_df[\"pm25\"]\n",
    "        X_test = test_df.drop(columns=[\"pm25\", \"date\", \"city\", \"sensor_id\"])\n",
    "        y_test = test_df[\"pm25\"]\n",
    "        \n",
    "        # run three times and take the best model, save the average of the three\n",
    "        best_r2 = -float('inf')\n",
    "        best_mse = float('inf')\n",
    "        best_model = None\n",
    "        \n",
    "        mse_list = []\n",
    "        r2_list = []\n",
    "        for i in range(5):\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=165439*i)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2_list.append(r2)\n",
    "            mse_list.append(mse)\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_mse = mse\n",
    "                best_model = model\n",
    "\n",
    "        models[feature_name][sensor_id] = best_model\n",
    "        y_preds[feature_name][sensor_id] = best_model.predict(X_test)\n",
    "\n",
    "        results.append({\n",
    "            \"feature_name\": feature_name,\n",
    "            \"sensor_id\": sensor_id,\n",
    "            \"MSE\": sum(mse_list) / len(mse_list),\n",
    "            \"R2\": sum(r2_list) / len(r2_list),\n",
    "            \"train_size\": len(train_df),\n",
    "            \"test_size\": len(test_df)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = f\"{root_dir}/models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee87500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model (highest R2) for each sensor\n",
    "results_df = pd.DataFrame(results)\n",
    "best_models = results_df.loc[results_df.groupby('sensor_id')['R2'].idxmax()]\n",
    "print(\"Best models per sensor:\")\n",
    "print(best_models[['sensor_id', 'feature_name', 'R2', 'MSE']])\n",
    "\n",
    "all_data = baseline_features.read()\n",
    "all_data['date'] = pd.to_datetime(all_data['date']).dt.tz_localize(None)\n",
    "\n",
    "all_test_data = []\n",
    "for _, row in best_models.iterrows():\n",
    "    sensor_id = row['sensor_id']\n",
    "    best_feature = row['feature_name']\n",
    "    \n",
    "    sensor_dir = f\"{model_dir}/{sensor_id}\"\n",
    "    if not os.path.exists(sensor_dir):\n",
    "        os.mkdir(sensor_dir)\n",
    "    images_dir = f\"{model_dir}/{sensor_id}/images\"\n",
    "    if not os.path.exists(images_dir):\n",
    "        os.mkdir(images_dir)\n",
    "\n",
    "    best_model = models[best_feature][sensor_id]\n",
    "    model_path = f\"{sensor_dir}/model.json\"\n",
    "    plot_importance(best_model)\n",
    "    importance_path = f\"{images_dir}/feature_importance.png\"\n",
    "    plt.savefig(importance_path)\n",
    "    plt.close()\n",
    "    \n",
    "    best_model.save_model(model_path)\n",
    "\n",
    "    df = all_data[all_data['sensor_id'] == sensor_id].copy()\n",
    "    test_df = df[df['date'] >= test_start].copy()\n",
    "    \n",
    "    if len(test_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    test_df['predicted_pm25'] = y_preds[best_feature][sensor_id]\n",
    "    test_df['best_model'] = best_feature\n",
    "    all_test_data.append(test_df[['date', 'pm25', 'predicted_pm25', 'latitude', 'longitude', 'best_model']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57715d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table for the model performance for each sensor\n",
    "for sensor_id, location in locations.items():\n",
    "    print(f\"{sensor_id} with train/test size: {results_df[results_df['sensor_id'] == sensor_id]['train_size'].iloc[0]}/{results_df[results_df['sensor_id'] == sensor_id]['test_size'].iloc[0]}\")\n",
    "    print(results_df[results_df['sensor_id'] == sensor_id][['feature_name', 'R2', 'MSE']])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e83fbf",
   "metadata": {},
   "source": [
    "Train 5 models with different random seeds, evaluate each on the test set, and select the model with the highest R^2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "df = pd.concat(all_test_data, ignore_index=True) if all_test_data else pd.DataFrame()\n",
    "df = df.sort_values(by=[\"date\"])\n",
    "\n",
    "# Plot the best model for each sensor\n",
    "for sensor_id, location in locations.items():\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "    \n",
    "    df_subset = df[(df[\"latitude\"] == latitude) & (df[\"longitude\"] == longitude)].copy()\n",
    "    if len(df_subset) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get the best model name for display\n",
    "    best_model_name = df_subset['best_model'].iloc[0] if 'best_model' in df_subset.columns else 'unknown'\n",
    "    best_model_r2 = df_subset['R2'].iloc[0] if 'R2' in df_subset.columns else 0\n",
    "    best_model_mse = df_subset['MSE'].iloc[0] if 'MSE' in df_subset.columns else 0\n",
    "    best_model_feature_view = feature_views[best_model_name]\n",
    "    \n",
    "    df_subset = df_subset.sort_values(by=[\"date\"])\n",
    "    df_subset = df_subset.drop(columns=[\"latitude\", \"longitude\", \"best_model\"])\n",
    "    \n",
    "    images_dir = f\"{model_dir}/{sensor_id}/images\"\n",
    "    image_path = f\"{images_dir}/hindcast_training.png\"\n",
    "    \n",
    "    plt = airquality.plot_air_quality_forecast(\n",
    "        city, street, df_subset, image_path, hindcast=True\n",
    "    )\n",
    "    plt.title(f\"{city} {street} (Best Model: {best_model_name})\")\n",
    "    plt.show()\n",
    "\n",
    "    # airquality.delete_models(mr, f\"air_quality_xgboost_model_{sensor_id}\")\n",
    "    aq_model = mr.python.create_model(\n",
    "        name=f\"air_quality_xgboost_model_{sensor_id}\",\n",
    "        metrics={\n",
    "            \"R2\": best_model_r2,\n",
    "            \"MSE\": best_model_mse,\n",
    "        },\n",
    "        feature_view=best_model_feature_view,\n",
    "        description=f\"Air Quality (PM2.5) predictor for {city} {street} using {best_model_name} configuration\",\n",
    "    )\n",
    "\n",
    "    aq_model.save(f\"{model_dir}/{sensor_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
