{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0807c7e3",
   "metadata": {},
   "source": [
    "# 4. Batch Inference Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e540c",
   "metadata": {},
   "source": [
    "## 4.1. Environment Setup\n",
    "Detect if running in Google Colab or local environment, handle repository cloning, dependency installation, numpy compatibility fixes, and set up Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e036d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import hopsworks\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "for folder in (\"src\", \"airquality\", \"notebooks\"):\n",
    "    if root_dir.parts[-1:] == (folder,):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir)\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "from utils import config\n",
    "\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a9d05",
   "metadata": {},
   "source": [
    "## 4.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "import json\n",
    "from utils import airquality\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f1d0b",
   "metadata": {},
   "source": [
    "## 4.3. Hopsworks Configuration\n",
    "Establish connection to Hopsworks, retrieve API keys, connect to feature store, and get air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "    HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.datetime.today().date()\n",
    "past_date = today - datetime.timedelta(days=4)\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe79872",
   "metadata": {},
   "source": [
    "## 4.4. Sensor Location Loading \n",
    "Load sensor location metadata from Hopsworks secrets for all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_secrets = secrets.get_secrets()\n",
    "locations = {}\n",
    "for secret in all_secrets:\n",
    "    if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "        sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "        location_str = secrets.get_secret(secret.name).value\n",
    "        if location_str:\n",
    "            locations[sensor_id] = json.loads(location_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66556865",
   "metadata": {},
   "source": [
    "## 4.5. Weather Data Loading\n",
    "Fetch recent weather data from feature store and convert date formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dced6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    batch_weather = weather_fg.filter(weather_fg.date >= past_date).read()\n",
    "    # print(batch_weather.date.max())\n",
    "except Exception:\n",
    "    batch_weather = weather_fg.read()\n",
    "    batch_weather = batch_weather[batch_weather[\"date\"] >= past_date]\n",
    "batch_weather[\"date\"] = pd.to_datetime(batch_weather[\"date\"]).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca24aa",
   "metadata": {},
   "source": [
    "## 4.6. Air Quality Data Loading\n",
    "Fetch recent air quality with error handling for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    batch_airquality = air_quality_fg.filter(air_quality_fg.date >= past_date).read()\n",
    "    batch_airquality[\"date\"] = pd.to_datetime(batch_airquality[\"date\"]).dt.tz_localize(None)\n",
    "except Exception:\n",
    "    batch_airquality = pd.DataFrame()\n",
    "print(f\"Retrieved {len(batch_airquality)} air quality records from Hopsworks Feature Store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71f8fb",
   "metadata": {},
   "source": [
    "## 4.7. Model Retrieval\n",
    "Download trained XGBoost models from Hopsworks model registry for each sensor and extract feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c861de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "MODEL_NAME_TEMPLATE = \"air_quality_xgboost_model_{sensor_id}\"\n",
    "\n",
    "# model, model_dir, features\n",
    "retrieved_models = {}\n",
    "\n",
    "for sensor_id in locations.keys():\n",
    "    model_name = MODEL_NAME_TEMPLATE.format(sensor_id=sensor_id)\n",
    "    retrieved_model = None\n",
    "\n",
    "    available_models = mr.get_models(name=model_name)\n",
    "    if available_models:\n",
    "        retrieved_model = max(available_models, key=lambda model: model.version)\n",
    "\n",
    "    if retrieved_model is None:\n",
    "        print(f\"No model found for sensor {sensor_id}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    saved_model_dir = retrieved_model.download()\n",
    "    \n",
    "    import xgboost as xgb\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(saved_model_dir + \"/model.json\")\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model._Booster = booster\n",
    "\n",
    "    retrieved_models[sensor_id] = retrieved_model, xgb_model, booster.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71da993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Retrieved {len(retrieved_models)} models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88c6a6",
   "metadata": {},
   "source": [
    "## 4.8. Batch Prediction Loop\n",
    "Merge weather and air quality data, iteratively predict PM2.5 values for forecast days, update engineered features after each prediction, and store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40feb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"pm25_rolling_3d\",\n",
    "    \"pm25_lag_1d\",\n",
    "    \"pm25_lag_2d\",\n",
    "    \"pm25_lag_3d\",\n",
    "    \"pm25_nearby_avg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge historical data with weather data\n",
    "batch_data = pd.merge(batch_weather, batch_airquality, on=[\"date\", \"sensor_id\"], how=\"left\")\n",
    "batch_data = batch_data.sort_values([\"sensor_id\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data[\"predicted_pm25\"] = np.nan\n",
    "batch_data[\"days_before_forecast_day\"] = np.nan\n",
    "for col in feature_cols:\n",
    "    batch_data[f\"predicted_{col}\"] = np.nan\n",
    "\n",
    "forecast_days = (\n",
    "    batch_data.loc[batch_data[\"pm25\"].isna() & (batch_data[\"date\"] >= today.strftime(\"%Y-%m-%d\")), \"date\"]\n",
    "    .dropna()\n",
    "    .sort_values()\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_day in forecast_days:\n",
    "    # context with all sensors up to current day\n",
    "    window = batch_data.loc[batch_data[\"date\"] <= target_day].copy()\n",
    "    day_rows = window[(window[\"date\"] == target_day) & window[\"pm25\"].isna()]\n",
    "\n",
    "    for _, row in day_rows.iterrows():\n",
    "        sensor_id = row[\"sensor_id\"]\n",
    "\n",
    "        _, xgb_model, model_features = retrieved_models[sensor_id]\n",
    "        features = (row.reindex(model_features).to_frame().T.apply(pd.to_numeric, errors=\"coerce\"))\n",
    "        y_hat = xgb_model.predict(features)[0]\n",
    "\n",
    "        idx = batch_data.index[(batch_data[\"sensor_id\"] == sensor_id) & (batch_data[\"date\"] == target_day)][0]\n",
    "        batch_data.at[idx, \"pm25\"] = y_hat\n",
    "        batch_data.at[idx, \"predicted_pm25\"] = y_hat\n",
    "        batch_data.at[idx, \"days_before_forecast_day\"] = (target_day.date() - today).days + 1\n",
    "\n",
    "    temp_df = batch_data.loc[batch_data[\"date\"] <= target_day].copy()\n",
    "    temp_df = airquality.add_rolling_window_feature(\n",
    "        temp_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\"\n",
    "    )\n",
    "    temp_df = airquality.add_lagged_features(temp_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    temp_df = airquality.add_nearby_sensor_feature(\n",
    "        temp_df,\n",
    "        locations,\n",
    "        column=\"pm25\",\n",
    "        n_closest=3,\n",
    "        new_column=\"pm25_nearby_avg\",\n",
    "    )\n",
    "\n",
    "    current_rows = temp_df[temp_df[\"date\"] == target_day]\n",
    "    for _, row in current_rows.iterrows():\n",
    "        sensor_id = row[\"sensor_id\"]\n",
    "        mask = (batch_data[\"sensor_id\"] == sensor_id) & (batch_data[\"date\"] == target_day)\n",
    "        if mask.any():\n",
    "            for col in feature_cols:\n",
    "                batch_data.loc[mask, f\"predicted_{col}\"] = row[col]\n",
    "\n",
    "predictions = batch_data.loc[\n",
    "    batch_data[\"predicted_pm25\"].notna(),\n",
    "    [\"date\", \"sensor_id\", \"predicted_pm25\", \"days_before_forecast_day\"]\n",
    "    + [f\"predicted_{col}\" for col in feature_cols],\n",
    "].reset_index(drop=True)\n",
    "batch_data.loc[batch_data[\"date\"].dt.date > today, \"pm25\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308fdb6",
   "metadata": {},
   "source": [
    "## 4.9. Save Predictions\n",
    "Export prediction results to CSV file in models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data.to_csv(f\"{root_dir}/models/predictions.csv\", columns=batch_data.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574a8ec",
   "metadata": {},
   "source": [
    "## 4.10. Generate Forecast Plots\n",
    "Create forecast visualization plots for each sensor and upload them to Hopsworks dataset storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_paths = []\n",
    "\n",
    "for sensor_id, location in locations.items():\n",
    "    sensor_forecast = predictions[predictions[\"sensor_id\"] == sensor_id].copy()\n",
    "\n",
    "    city, street = location[\"city\"], location[\"street\"]\n",
    "    forecast_path = f\"{root_dir}/models/{sensor_id}/images/forecast.png\"\n",
    "    Path(forecast_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt = airquality.plot_air_quality_forecast(\n",
    "        location[\"city\"],\n",
    "        location[\"street\"],\n",
    "        sensor_forecast,\n",
    "        forecast_path,\n",
    "        hindcast=False,\n",
    "    )\n",
    "    plt.close()\n",
    "    forecast_paths.append((sensor_id, forecast_path))\n",
    "\n",
    "dataset_api = project.get_dataset_api()\n",
    "today_short = today.strftime(\"%Y-%m-%d\")\n",
    "if not dataset_api.exists(\"Resources/airquality\"):\n",
    "    dataset_api.mkdir(\"Resources/airquality\")\n",
    "\n",
    "for sensor_id, forecast_path in forecast_paths:\n",
    "    dataset_api.upload(\n",
    "        forecast_path,\n",
    "        f\"Resources/airquality/{sensor_id}_{today_short}_forecast.png\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "print(f\"Forecast plots available in Hopsworks under {project.get_url()}/settings/fb/path/Resources/airquality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce2d71",
   "metadata": {},
   "source": [
    "## 4.11. Insert Monitoring Data\n",
    "Save predictions to monitoring feature group in Hopsworks for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name=\"aq_predictions\",\n",
    "    description=\"Air Quality prediction monitoring\",\n",
    "    version=1,\n",
    "    primary_key=[\"sensor_id\", \"date\", \"days_before_forecast_day\"],\n",
    "    event_time=\"date\",\n",
    ")\n",
    "monitor_fg.insert(predictions, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf631c3b",
   "metadata": {},
   "source": [
    "## 4.12. Hindcast Analysis\n",
    "Compare predicted with forecasted values (1-day prior forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16099436",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_df = monitor_fg.filter(monitor_fg.days_before_forecast_day == 1).read()\n",
    "monitoring_df[\"date\"] = pd.to_datetime(monitoring_df[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "air_quality_df = air_quality_fg.read()[[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "air_quality_df[\"date\"] = pd.to_datetime(air_quality_df[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "for sensor_id, location in locations.items():\n",
    "    try:\n",
    "        sensor_preds = monitoring_df[monitoring_df[\"sensor_id\"] == sensor_id][[\"date\", \"predicted_pm25\"]]\n",
    "        merged = sensor_preds.merge(\n",
    "            air_quality_df[air_quality_df[\"sensor_id\"] == sensor_id][[\"date\", \"pm25\"]],\n",
    "            on=\"date\",\n",
    "            how=\"inner\",\n",
    "        ).sort_values(\"date\")\n",
    "\n",
    "        city, street = location[\"city\"], location[\"street\"]\n",
    "        hindcast_path = f\"{root_dir}/models/{sensor_id}/images/hindcast_prediction.png\"\n",
    "        Path(hindcast_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        plt = airquality.plot_air_quality_forecast(\n",
    "            city,\n",
    "            street,\n",
    "            merged if not merged.empty else sensor_preds.assign(pm25=np.nan),\n",
    "            hindcast_path,\n",
    "            hindcast=True,\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        dataset_api.upload(\n",
    "            hindcast_path,\n",
    "            f\"Resources/airquality/{sensor_id}_{today:%Y-%m-%d}_hindcast.png\",\n",
    "            overwrite=True,\n",
    "        )\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error processing hindcast for sensor {sensor_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a256c",
   "metadata": {},
   "source": [
    "## 4.13 IDW Heatmap\n",
    "IDW - Inverse Distance Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd9449",
   "metadata": {},
   "source": [
    "### 4.13.1 IDW interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idw_interpolation(points, values, grid_points, lon_mesh, power=2):\n",
    "    distances = cdist(grid_points, points)\n",
    "    distances = np.where(distances == 0, 1e-10, distances)\n",
    "    weights = 1.0 / (distances ** power)\n",
    "    weights_sum = np.sum(weights, axis=1)\n",
    "    interpolated = np.sum(weights * values, axis=1) / weights_sum\n",
    "    return interpolated.reshape(lon_mesh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pm25_idw_heatmap(\n",
    "    predictions: pd.DataFrame,\n",
    "    locations: dict,\n",
    "    forecast_date: datetime.datetime,\n",
    "    path: str,\n",
    "    grid_bounds=(-7.602536,50.862218,36.738284,69.923179),\n",
    "    grid_resolution=800,\n",
    "    power=2,\n",
    "):\n",
    "\n",
    "    df_day = predictions[predictions[\"date\"] == forecast_date].copy()\n",
    "\n",
    "    sensor_coords = np.array([[locations[sid][\"longitude\"], locations[sid][\"latitude\"]]\n",
    "                              for sid in df_day[\"sensor_id\"].unique() if sid in locations])\n",
    "\n",
    "    pm25_column = \"predicted_pm25\"\n",
    "    if df_day[\"predicted_pm25\"].isna().any():\n",
    "        pm25_column = \"pm25\"\n",
    "\n",
    "    pm25_values = np.array([df_day[df_day[\"sensor_id\"] == sid][pm25_column].iloc[0]\n",
    "                            for sid in df_day[\"sensor_id\"].unique() if sid in locations])\n",
    "    \n",
    "    # Cap extreme values to prevent unrealistic interpolation\n",
    "    pm25_values = np.clip(pm25_values, 0, 150)\n",
    "\n",
    "    min_lon, min_lat, max_lon, max_lat = grid_bounds\n",
    "\n",
    "    lon_grid = np.linspace(min_lon, max_lon, grid_resolution)\n",
    "    lat_grid = np.linspace(min_lat, max_lat, grid_resolution)\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)\n",
    "    grid_points = np.column_stack([lon_mesh.ravel(), lat_mesh.ravel()])\n",
    "\n",
    "    idw_result = idw_interpolation(sensor_coords, pm25_values, grid_points, lon_mesh, power=power)\n",
    "\n",
    "    default_levels = np.array([0, 12, 35, 55, 150, 250, 500])\n",
    "    category_colors = [\n",
    "            \"#00e400\", \"#7de400\", \"#ffff00\", \"#ffb000\",\n",
    "            \"#ff7e00\", \"#ff4000\", \"#ff0000\", \"#d00050\",\n",
    "            \"#8f3f97\", \"#7e0023\"\n",
    "        ]\n",
    "    vmin, vmax = default_levels[0], 150\n",
    "    \n",
    "    clipped = np.clip(idw_result, vmin, vmax)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(\n",
    "        clipped,\n",
    "        extent=(min_lon, max_lon, min_lat, max_lat),\n",
    "        origin=\"lower\",\n",
    "        cmap=mcolors.LinearSegmentedColormap.from_list(\"aqi\", category_colors, N=512),\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_xlim(min_lon, max_lon)\n",
    "    ax.set_ylim(min_lat, max_lat)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\", pad_inches=0, transparent=True)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_dir = f\"{root_dir}/models/interpolation\"\n",
    "if not os.path.exists(interpolation_dir):\n",
    "    os.mkdir(interpolation_dir)\n",
    "\n",
    "today_short = today.strftime(\"%Y-%m-%d\")\n",
    "interpolation_df = predictions.copy()\n",
    "for i, forecast_date in enumerate(sorted(interpolation_df[\"date\"].unique())):\n",
    "    forecast_date_short = forecast_date.strftime(\"%Y-%m-%d\")\n",
    "    output_png = f\"{interpolation_dir}/forecast_interpolation_{i}d.png\"\n",
    "    \n",
    "    plot_pm25_idw_heatmap(\n",
    "        interpolation_df,\n",
    "        locations,\n",
    "        forecast_date,\n",
    "        output_png,\n",
    "    )\n",
    "    dataset_api.upload(\n",
    "        output_png,\n",
    "        f\"Resources/airquality/interpolation_{today_short}_{forecast_date_short}.png\",\n",
    "        overwrite=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
