{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf10743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n",
      "2026-01-07 16:13:53,847 INFO: Initializing external client\n",
      "2026-01-07 16:13:53,856 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-07 16:13:54,580 WARNING: UserWarning: The installed hopsworks client version 4.1.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-07 16:13:55,626 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone, date\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "#  Establish project root directory\n",
    "def find_project_root(start: Path):\n",
    "    for parent in [start] + list(start.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return start\n",
    "\n",
    "root_dir = find_project_root(Path().absolute())\n",
    "print(\"Project root dir:\", root_dir)\n",
    "\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import os\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "#  Project imports\n",
    "from utils import config, metadata\n",
    "\n",
    "#  Load settings \n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "GITHUB_USERNAME = settings.GH_USERNAME.get_secret_value()\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b0ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date.today()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"AQICN_API_KEY missing.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f15f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"pm25-metadata-builder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef56161",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def geocode_cached(query):\n",
    "    if query in cache:\n",
    "        return cache[query]\n",
    "    loc = geolocator.geocode(query)\n",
    "    cache[query] = loc\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0625fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_field(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, float) and pd.isna(value):\n",
    "        return None\n",
    "    value = str(value).strip()\n",
    "    if value.lower() in (\"none\", \"nan\", \"\", \"unknown\"):\n",
    "        return None\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1a6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(city, street, country):\n",
    "    candidates = []\n",
    "\n",
    "    if street and city:\n",
    "        candidates.append(f\"{street}, {city}, {country}\")\n",
    "    if city:\n",
    "        candidates.append(f\"{city}, {country}\")\n",
    "    if street:\n",
    "        candidates.append(f\"{street}, {country}\")\n",
    "    candidates.append(country)\n",
    "\n",
    "    for query in candidates:\n",
    "        loc = geocode_cached(query)\n",
    "        time.sleep(1)\n",
    "        if loc:\n",
    "            return loc.latitude, loc.longitude\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb7d72",
   "metadata": {},
   "source": [
    "Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a68c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata_from_csvs(data_dir, aqicn_api_key):\n",
    "    rows = []\n",
    "\n",
    "    for file in os.listdir(data_dir):\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "\n",
    "        aq_df_raw, street, city, country, feed_url, sensor_id = metadata.read_sensor_data(\n",
    "            file_path, aqicn_api_key\n",
    "        )\n",
    "\n",
    "        street = clean_field(street)\n",
    "        city = clean_field(city)\n",
    "        country = clean_field(country)\n",
    "\n",
    "        lat, lon = get_coordinates(city, street, country)\n",
    "\n",
    "        if lat is None or lon is None:\n",
    "            print(f\"[SKIP] Sensor {sensor_id}: cannot geocode location\")\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"sensor_id\": sensor_id,\n",
    "            \"city\": city,\n",
    "            \"street\": street,\n",
    "            \"country\": country,\n",
    "            \"aqicn_url\": feed_url,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_meta = build_metadata_from_csvs(\"../data/\", AQICN_API_KEY)\n",
    "\n",
    "# Create a unique location_id for each unique (city, lat, lon)\n",
    "df_meta[\"location_key\"] = (\n",
    "    df_meta[\"city\"].astype(str) + \"_\" +\n",
    "    df_meta[\"latitude\"].astype(str) + \"_\" +\n",
    "    df_meta[\"longitude\"].astype(str)\n",
    ")\n",
    "\n",
    "# Map each unique location_key to an integer ID\n",
    "unique_keys = df_meta[\"location_key\"].unique()\n",
    "location_map = {key: idx + 1 for idx, key in enumerate(unique_keys)}\n",
    "\n",
    "df_meta[\"location_id\"] = df_meta[\"location_key\"].map(location_map)\n",
    "\n",
    "# Drop helper column\n",
    "df_meta = df_meta.drop(columns=[\"location_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c2f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1911213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 103/103 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sensor_metadata_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/sensor_metadata_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('sensor_metadata_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_meta = fs.get_or_create_feature_group(\n",
    "    name=\"sensor_metadata\",\n",
    "    version=1,\n",
    "    primary_key=[\"sensor_id\"],\n",
    "    description=\"Curated metadata extracted from AQICN CSVs\",\n",
    "    online_enabled=True\n",
    ")\n",
    "\n",
    "fg_meta.insert(df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2cdc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor metadata feature group created/updated successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensor metadata feature group created/updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
