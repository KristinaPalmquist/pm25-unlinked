{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0807c7e3",
   "metadata": {},
   "source": [
    "# 4. Batch Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e036d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    # Check if repository already exists\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "def fix_numpy_compatibility():\n",
    "    print(\"Fixing numpy compatibility for hopsworks/pandas...\")\n",
    "    try:\n",
    "        # Use precompiled wheels with compatible versions\n",
    "        !pip install --force-reinstall numpy==1.24.4 pandas==2.0.3\n",
    "        print(\"Numpy and pandas fixed. Please restart runtime and run again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fix attempt failed: {e}\")\n",
    "        print(\"Please manually restart runtime and try again.\")\n",
    "\n",
    "if is_google_colab():\n",
    "    try:\n",
    "        import numpy\n",
    "        numpy.array([1, 2, 3])\n",
    "        import pandas as pd\n",
    "        print(\"Basic packages working correctly\")\n",
    "\n",
    "        clone_repository()\n",
    "        install_dependencies()\n",
    "\n",
    "        import hopsworks\n",
    "        print(\"All packages working correctly\")\n",
    "\n",
    "        root_dir = str(Path().absolute())\n",
    "        print(\"Google Colab environment\")\n",
    "        \n",
    "    except (ValueError, ImportError) as e:\n",
    "        if \"numpy.dtype size changed\" in str(e) or \"numpy.strings\" in str(e) or \"numpy\" in str(e).lower():\n",
    "            fix_numpy_compatibility()\n",
    "            raise SystemExit(\"Please restart runtime (Runtime > Restart runtime) and run the notebook again.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    if root_dir.parts[-1:] == (\"src\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"airquality\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"notebooks\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "from utils import config\n",
    "\n",
    "if is_google_colab():\n",
    "    from google.colab import userdata\n",
    "    import hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=userdata.get('HOPSWORKS_API_KEY'),\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    AQICN_API_KEY = userdata.get('AQICN_API_KEY')\n",
    "    \n",
    "else:\n",
    "    # Local development - use .env file\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "import json\n",
    "from utils import airquality\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:54:17,739 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-27 09:54:17,742 INFO: Initializing external client\n",
      "2025-11-27 09:54:17,742 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:54:19,400 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "if is_google_colab():\n",
    "    fs = project.get_feature_store()\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "else:\n",
    "    HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "    if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "        HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "    project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.today().date()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe79872",
   "metadata": {},
   "source": [
    "Set SENSOR_CSV_FILE in .env with the relative path to a sensor to process it, or leave it unset to process all sensors in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    sensor_csv_file = None\n",
    "else:\n",
    "    sensor_csv_file = getattr(settings, 'SENSOR_CSV_FILE', None)\n",
    "\n",
    "if sensor_csv_file:\n",
    "    # Read one secret for single sensor mode\n",
    "    _, _, _, _, _, sensor_id = airquality.read_sensor_data(sensor_csv_file)\n",
    "    secret_name = f\"SENSOR_LOCATION_JSON_{sensor_id}\"\n",
    "    location_str = secrets.get_secret(secret_name).value\n",
    "    locations = {sensor_id: json.loads(location_str)}\n",
    "else:\n",
    "    # Read all individual secrets in batch mode\n",
    "    all_secrets = secrets.get_secrets()\n",
    "    locations = {}\n",
    "    for secret in all_secrets:\n",
    "        if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "            sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "            location_str = secrets.get_secret(secret.name).value\n",
    "            if location_str:\n",
    "                locations[sensor_id] = json.loads(location_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f6ec9",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c70c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m air_quality_fg = fs.get_feature_group(\n\u001b[32m      3\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mair_quality_all\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     version=\u001b[32m1\u001b[39m,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m weather_fg = fs.get_feature_group(\n\u001b[32m      7\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mweather_all\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     version=\u001b[32m1\u001b[39m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m today = \u001b[43mdatetime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatetime\u001b[49m.now().replace(tzinfo=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     12\u001b[39m past_date = today - datetime.timedelta(days=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "today = datetime.now().replace(tzinfo=None)\n",
    "past_date = today - timedelta(days=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dced6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_weather = weather_fg.filter(weather_fg.date >= past_date).read()\n",
    "batch_weather[\"date\"] = pd.to_datetime(batch_weather[\"date\"]).dt.tz_localize(None)\n",
    "print(batch_weather.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    batch_airquality = air_quality_fg.filter(air_quality_fg.date >= past_date).read()\n",
    "    batch_airquality[\"date\"] = pd.to_datetime(batch_airquality[\"date\"]).dt.tz_localize(None)\n",
    "except Exception:\n",
    "    batch_airquality = pd.DataFrame()\n",
    "print(batch_airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0f659",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c861de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "MODEL_NAME_TEMPLATE = \"air_quality_xgboost_model_{sensor_id}\"\n",
    "\n",
    "# model, model_dir, features\n",
    "retrieved_models = {}\n",
    "\n",
    "for sensor_id in locations.keys():\n",
    "    model_name = MODEL_NAME_TEMPLATE.format(sensor_id=sensor_id)\n",
    "    retrieved_model = None\n",
    "\n",
    "    available_models = mr.get_models(name=model_name)\n",
    "    if available_models:\n",
    "        retrieved_model = max(available_models, key=lambda model: model.version)\n",
    "\n",
    "    saved_model_dir = retrieved_model.download()\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.load_model(saved_model_dir + \"/model.json\")\n",
    "    booster = xgb_model.get_booster()\n",
    "\n",
    "    retrieved_models[sensor_id] = retrieved_model, xgb_model, booster.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88c6a6",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ef865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge historical data with weather data\n",
    "batch_data = pd.merge(batch_weather, batch_airquality, on=[\"date\", \"sensor_id\"], how=\"left\")\n",
    "batch_data = batch_data.sort_values([\"sensor_id\", \"date\"])\n",
    "\n",
    "feature_cols = [\n",
    "    \"pm25_rolling_3d\",\n",
    "    \"pm25_lag_1d\",\n",
    "    \"pm25_lag_2d\",\n",
    "    \"pm25_lag_3d\",\n",
    "    \"pm25_nearby_avg\",\n",
    "]\n",
    "\n",
    "batch_data[\"predicted_pm25\"] = np.nan\n",
    "batch_data[\"days_before_forecast_day\"] = np.nan\n",
    "for col in feature_cols:\n",
    "    batch_data[f\"predicted_{col}\"] = np.nan\n",
    "\n",
    "forecast_days = (\n",
    "    batch_data.loc[batch_data[\"pm25\"].isna() & (batch_data[\"date\"] >= today.strftime(\"%Y-%m-%d\")), \"date\"]\n",
    "    .dropna()\n",
    "    .sort_values()\n",
    "    .unique()\n",
    ")\n",
    "for target_day in forecast_days:\n",
    "    # context with all sensors up to current day\n",
    "    window = batch_data.loc[batch_data[\"date\"] <= target_day].copy()\n",
    "    day_rows = window[(window[\"date\"] == target_day) & window[\"pm25\"].isna()]\n",
    "\n",
    "    for _, row in day_rows.iterrows():\n",
    "        sensor_id = row[\"sensor_id\"]\n",
    "\n",
    "        _, xgb_model, model_features = retrieved_models[sensor_id]\n",
    "        features = (row.reindex(model_features).to_frame().T.apply(pd.to_numeric, errors=\"coerce\"))\n",
    "        y_hat = xgb_model.predict(features)[0]\n",
    "\n",
    "        idx = batch_data.index[(batch_data[\"sensor_id\"] == sensor_id) & (batch_data[\"date\"] == target_day)][0]\n",
    "        batch_data.at[idx, \"pm25\"] = y_hat\n",
    "        batch_data.at[idx, \"predicted_pm25\"] = y_hat\n",
    "        batch_data.at[idx, \"days_before_forecast_day\"] = (target_day - today).days + 1\n",
    "\n",
    "    # recompute features for all sensors now that this days values exist\n",
    "    temp_df = batch_data.loc[batch_data[\"date\"] <= target_day].copy()\n",
    "    temp_df = airquality.add_rolling_window_feature(\n",
    "        temp_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\"\n",
    "    )\n",
    "    temp_df = airquality.add_lagged_features(temp_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    temp_df = airquality.add_nearby_sensor_feature(\n",
    "        temp_df,\n",
    "        locations,\n",
    "        column=\"pm25\",\n",
    "        n_closest=3,\n",
    "        new_column=\"pm25_nearby_avg\",\n",
    "    )\n",
    "\n",
    "    current_rows = temp_df[temp_df[\"date\"] == target_day]\n",
    "    for _, row in current_rows.iterrows():\n",
    "        sensor_id = row[\"sensor_id\"]\n",
    "        mask = (batch_data[\"sensor_id\"] == sensor_id) & (batch_data[\"date\"] == target_day)\n",
    "        if mask.any():\n",
    "            for col in feature_cols:\n",
    "                batch_data.loc[mask, f\"predicted_{col}\"] = row[col]\n",
    "\n",
    "predictions = batch_data.loc[\n",
    "    batch_data[\"predicted_pm25\"].notna(),\n",
    "    [\"date\", \"sensor_id\", \"predicted_pm25\", \"days_before_forecast_day\"]\n",
    "    + [f\"predicted_{col}\" for col in feature_cols],\n",
    "].reset_index(drop=True)\n",
    "batch_data.loc[batch_data[\"date\"] > today, \"pm25\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a30387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to csv\n",
    "batch_data.to_csv(f\"{root_dir}/models/predictions.csv\", columns=batch_data.columns, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_paths = []\n",
    "\n",
    "for sensor_id, location in locations.items():\n",
    "    sensor_forecast = predictions[predictions[\"sensor_id\"] == sensor_id].copy()\n",
    "\n",
    "    city, street = location[\"city\"], location[\"street\"]\n",
    "    forecast_path = f\"{root_dir}/models/{sensor_id}/images/forecast.png\"\n",
    "    Path(forecast_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt = airquality.plot_air_quality_forecast(\n",
    "        location[\"city\"],\n",
    "        location[\"street\"],\n",
    "        sensor_forecast,\n",
    "        forecast_path,\n",
    "        hindcast=False,\n",
    "    )\n",
    "    plt.close()\n",
    "    forecast_paths.append((sensor_id, forecast_path))\n",
    "\n",
    "dataset_api = project.get_dataset_api()\n",
    "today_short = today.strftime(\"%Y-%m-%d\")\n",
    "if not dataset_api.exists(\"Resources/airquality\"):\n",
    "    dataset_api.mkdir(\"Resources/airquality\")\n",
    "\n",
    "for sensor_id, forecast_path in forecast_paths:\n",
    "    dataset_api.upload(\n",
    "        forecast_path,\n",
    "        f\"Resources/airquality/{sensor_id}_{today_short}_forecast.png\",\n",
    "        overwrite=True,\n",
    "    )\n",
    "print(f\"Forecast plots available in Hopsworks under {project.get_url()}/settings/fb/path/Resources/airquality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert predictions into monitoring feature group\n",
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name=\"aq_predictions\",\n",
    "    description=\"Air Quality prediction monitoring\",\n",
    "    version=1,\n",
    "    primary_key=[\"sensor_id\", \"date\", \"days_before_forecast_day\"],\n",
    "    event_time=\"date\",\n",
    ")\n",
    "monitor_fg.insert(predictions, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf631c3b",
   "metadata": {},
   "source": [
    "## Prediction Hindcast: Comparing predicted with forecasted values (1-day prior forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16099436",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_df = monitor_fg.filter(monitor_fg.days_before_forecast_day == 1).read()\n",
    "monitoring_df[\"date\"] = pd.to_datetime(monitoring_df[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "air_quality_df = air_quality_fg.read()[[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "air_quality_df[\"date\"] = pd.to_datetime(air_quality_df[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "for sensor_id, location in locations.items():\n",
    "    sensor_preds = monitoring_df[monitoring_df[\"sensor_id\"] == sensor_id][[\"date\", \"predicted_pm25\"]]\n",
    "    merged = sensor_preds.merge(\n",
    "        air_quality_df[air_quality_df[\"sensor_id\"] == sensor_id][[\"date\", \"pm25\"]],\n",
    "        on=\"date\",\n",
    "        how=\"inner\",\n",
    "    ).sort_values(\"date\")\n",
    "\n",
    "    city, street = location[\"city\"], location[\"street\"]\n",
    "    hindcast_path = f\"{root_dir}/models/{sensor_id}/images/hindcast_prediction.png\"\n",
    "    Path(hindcast_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt = airquality.plot_air_quality_forecast(\n",
    "        city,\n",
    "        street,\n",
    "        merged if not merged.empty else sensor_preds.assign(pm25=np.nan),\n",
    "        hindcast_path,\n",
    "        hindcast=True,\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    dataset_api.upload(\n",
    "        hindcast_path,\n",
    "        f\"Resources/airquality/{sensor_id}_{today:%Y-%m-%d}_hindcast.png\",\n",
    "        overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a256c",
   "metadata": {},
   "source": [
    "## IDW Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idw_interpolation(points, values, grid_points, lon_mesh, power=2):\n",
    "    distances = cdist(grid_points, points)\n",
    "    distances = np.where(distances == 0, 1e-10, distances)\n",
    "    weights = 1.0 / (distances ** power)\n",
    "    weights_sum = np.sum(weights, axis=1)\n",
    "    interpolated = np.sum(weights * values, axis=1) / weights_sum\n",
    "    return interpolated.reshape(lon_mesh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pm25_idw_heatmap(\n",
    "    predictions: pd.DataFrame,\n",
    "    locations: dict,\n",
    "    forecast_date: datetime.datetime,\n",
    "    path: str,\n",
    "    grid_bounds=(11.4, 57.15, 12.5, 58.25),\n",
    "    grid_resolution=800,\n",
    "    power=2,\n",
    "):\n",
    "\n",
    "    df_day = predictions[predictions[\"date\"] == forecast_date].copy()\n",
    "\n",
    "    sensor_coords = np.array([[locations[sid][\"longitude\"], locations[sid][\"latitude\"]]\n",
    "                              for sid in df_day[\"sensor_id\"].unique() if sid in locations])\n",
    "\n",
    "    pm25_column = \"predicted_pm25\"\n",
    "    if df_day[\"predicted_pm25\"].isna().any():\n",
    "        pm25_column = \"pm25\"\n",
    "\n",
    "    pm25_values = np.array([df_day[df_day[\"sensor_id\"] == sid][pm25_column].iloc[0]\n",
    "                            for sid in df_day[\"sensor_id\"].unique() if sid in locations])\n",
    "\n",
    "    min_lon, min_lat, max_lon, max_lat = grid_bounds\n",
    "\n",
    "    lon_grid = np.linspace(min_lon, max_lon, grid_resolution)\n",
    "    lat_grid = np.linspace(min_lat, max_lat, grid_resolution)\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)\n",
    "    grid_points = np.column_stack([lon_mesh.ravel(), lat_mesh.ravel()])\n",
    "\n",
    "    idw_result = idw_interpolation(sensor_coords, pm25_values, grid_points, lon_mesh, power=power)\n",
    "\n",
    "    default_levels = np.array([0, 12, 35, 55, 150, 250, 500])\n",
    "    category_colors = [\"#00e400\", \"#7de400\", \"#ffff00\", \"#ffb000\", \"#ff7e00\", \"#ff4000\", \"#ff0000\", \"#c0007f\", \"#8f3f97\", \"#7e0023\"]\n",
    "    vmin, vmax = default_levels[0], 150\n",
    "    \n",
    "    clipped = np.clip(idw_result, vmin, vmax)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(\n",
    "        clipped,\n",
    "        extent=(min_lon, max_lon, min_lat, max_lat),\n",
    "        origin=\"lower\",\n",
    "        cmap=mcolors.LinearSegmentedColormap.from_list(\"aqi\", category_colors, N=512),\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_xlim(min_lon, max_lon)\n",
    "    ax.set_ylim(min_lat, max_lat)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\", pad_inches=0, transparent=True)\n",
    "    plt.close(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_dir = f\"{root_dir}/models/interpolation\"\n",
    "if not os.path.exists(interpolation_dir):\n",
    "    os.mkdir(interpolation_dir)\n",
    "\n",
    "today_short = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "interpolation_df = batch_data[batch_data[\"date\"] >= today_short]\n",
    "for i, forecast_date in enumerate(sorted(interpolation_df[\"date\"].unique())):\n",
    "    forecast_date_short = forecast_date.strftime(\"%Y-%m-%d\")\n",
    "    output_png = f\"{interpolation_dir}/forecast_interpolation_{i}d.png\"\n",
    "    \n",
    "    plot_pm25_idw_heatmap(\n",
    "        interpolation_df,\n",
    "        locations,\n",
    "        forecast_date,\n",
    "        output_png,\n",
    "    )\n",
    "    dataset_api.upload(\n",
    "        output_png,\n",
    "        f\"Resources/airquality/interpolation_{today_short}_{forecast_date_short}.png\",\n",
    "        overwrite=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
