{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Environment Setup\n",
    "Handle repository cloning, dependency installation, and set up Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import hopsworks\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "for folder in (\"src\", \"airquality\", \"notebooks\"):\n",
    "    if root_dir.parts[-1:] == (folder,):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir)\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "from utils import config\n",
    "\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5952fc",
   "metadata": {},
   "source": [
    "## 2.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import json\n",
    "import warnings\n",
    "import requests\n",
    "from utils import airquality\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5660ca1",
   "metadata": {},
   "source": [
    "## 2.3. Setup\n",
    "Hopsworks and feature store setup - configure Hopsworks connection, retrieve API keys, and connect to existing air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = hopsworks.get_secrets_api()\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Sensor Location Loading\n",
    "Retrieve sensor location data from Hopsworks secrets for all sensors and parse JSON location metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all individual secrets for all sensors\n",
    "all_secrets = secrets.get_secrets()\n",
    "locations = {}\n",
    "for secret in all_secrets:\n",
    "    if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "        sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "        location_str = secrets.get_secret(secret.name).value\n",
    "        if location_str:\n",
    "            locations[sensor_id] = json.loads(location_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert @ URLs to A URLs for Swedish sensors (AQICN API change)\n",
    "fixed_count = 0\n",
    "for sensor_id, location in locations.items():\n",
    "    if \"@\" in location[\"aqicn_url\"]:\n",
    "        old_url = location[\"aqicn_url\"]\n",
    "        new_url = old_url.replace(\"/@\", \"/A\")\n",
    "        location[\"aqicn_url\"] = new_url\n",
    "        fixed_count += 1\n",
    "\n",
    "if fixed_count > 0:\n",
    "    print(f\"üîß Fixed {fixed_count} sensor URLs from @ to A format\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è All sensor URLs already in correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa567b0",
   "metadata": {},
   "source": [
    "## 2.5. Helper Methods\n",
    "Data processing functions - get daily weather forecasts and fetch current data, air quality and weather, for each sensor location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_weather_forecast(city, latitude, longitude):\n",
    "    hourly_df = airquality.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index(\"date\")\n",
    "    daily_df = hourly_df.between_time(\"11:59\", \"12:01\")\n",
    "    daily_df = daily_df.reset_index()\n",
    "\n",
    "\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"]).dt.date\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n",
    "    daily_df[\"city\"] = city\n",
    "    return daily_df\n",
    "\n",
    "\n",
    "def fetch_data_for_location(location):\n",
    "    country = location[\"country\"]\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    aqicn_url = location[\"aqicn_url\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "\n",
    "    aq_today_df = airquality.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    daily_df = get_daily_weather_forecast(city, latitude, longitude)\n",
    "    return aq_today_df, daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.6. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs = []\n",
    "weathers = []\n",
    "print(f\"üîç Processing {len(locations)} sensor locations...\")\n",
    "\n",
    "for sensor, location in locations.items():\n",
    "    try:\n",
    "        aq_today_df, weather_daily_forecast_df = fetch_data_for_location(location)\n",
    "\n",
    "        aq_today_df = aq_today_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            street=location[\"street\"],\n",
    "            city=location[\"city\"],\n",
    "            country=location[\"country\"],\n",
    "            feed_url=location[\"aqicn_url\"],\n",
    "        )\n",
    "        aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"])\n",
    "\n",
    "        # Weather FG shape\n",
    "        weather_daily_forecast_df = weather_daily_forecast_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            city=location[\"city\"],\n",
    "            latitude=location[\"latitude\"],\n",
    "            longitude=location[\"longitude\"],\n",
    "        )\n",
    "        weather_daily_forecast_df[\"date\"] = pd.to_datetime(\n",
    "            weather_daily_forecast_df[\"date\"]\n",
    "        )\n",
    "\n",
    "        aqs.append(aq_today_df)\n",
    "        weathers.append(weather_daily_forecast_df)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ö†Ô∏è  Skipping sensor {sensor}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Unexpected error with sensor {sensor}: {type(e).__name__}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weathers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_df = pd.concat(aqs) if aqs else pd.DataFrame()\n",
    "if not aq_df.empty:\n",
    "    aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "    aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "    aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "    # Data quality check 1: Remove rows with missing PM2.5 values\n",
    "    initial_count = len(aq_df)\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    if len(aq_df) < initial_count:\n",
    "        print(f\"üßπ Removed {initial_count - len(aq_df)} rows with missing PM2.5 values\")\n",
    "\n",
    "# Get historical data for rolling window and lagged features\n",
    "historical_start = today - datetime.timedelta(days=4)\n",
    "historical_df = pd.DataFrame()\n",
    "\n",
    "# Read historical data from feature group and filter for the last 4 days\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"].dt.date >= historical_start) & (historical_df[\"date\"].dt.date < today)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dde4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historical_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([historical_df, aq_df], ignore_index=True) if not historical_df.empty else aq_df\n",
    "if not combined_df.empty:\n",
    "    combined_df = airquality.add_rolling_window_feature(combined_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "    combined_df = airquality.add_lagged_features(combined_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    combined_df = airquality.add_nearby_sensor_feature(combined_df, locations, column=\"pm25_lag_1d\", n_closest=3)\n",
    "    \n",
    "    # Data quality check 2: Clean up NaNs created by feature engineering\n",
    "    before_cleaning = len(combined_df[combined_df[\"date\"].dt.date == today])\n",
    "    \n",
    "    # Only keep today's data and remove rows where essential features are NaN\n",
    "    aq_df = combined_df[combined_df[\"date\"].dt.date == today].copy()\n",
    "    \n",
    "    # Remove rows where pm25 is still NaN after all processing\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    \n",
    "    after_cleaning = len(aq_df)\n",
    "    if before_cleaning > after_cleaning:\n",
    "        print(f\"üßπ Removed {before_cleaning - after_cleaning} rows with NaN values after feature engineering\")\n",
    "    \n",
    "    print(f\"üìä Final data quality: {len(aq_df)} clean rows ready for feature store\")\n",
    "else:\n",
    "    aq_df = pd.DataFrame()\n",
    "    print(\"‚ö†Ô∏è  No data available for processing\")\n",
    "aq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat(weathers) if weathers else pd.DataFrame()\n",
    "if not weather_df.empty:\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    \n",
    "    # Data quality check 3: Remove rows with missing weather data\n",
    "    initial_weather_count = len(weather_df)\n",
    "    weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "    \n",
    "    # Convert to float32 to match Hopsworks feature group schema\n",
    "    weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float32\")\n",
    "    weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float32\")\n",
    "    weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float32\")\n",
    "    weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float32\")\n",
    "    \n",
    "    if len(weather_df) < initial_weather_count:\n",
    "        print(f\"üßπ Removed {initial_weather_count - len(weather_df)} rows with missing weather data\")\n",
    "    \n",
    "    print(f\"üå§Ô∏è  Weather data quality: {len(weather_df)} clean weather rows\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No weather data available\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_df['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation before inserting to feature store\n",
    "if not aq_df.empty and not weather_df.empty:\n",
    "    print(f\"‚úÖ Inserting {len(aq_df)} air quality rows and {len(weather_df)} weather rows to feature store\")\n",
    "    air_quality_fg.insert(aq_df)\n",
    "    weather_fg.insert(weather_df)\n",
    "    print(\"üìÅ Data successfully inserted to feature store\")\n",
    "else:\n",
    "    if aq_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean air quality data to insert\")\n",
    "    if weather_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean weather data to insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_df['date'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
