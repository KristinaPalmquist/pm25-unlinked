{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99042d38",
   "metadata": {},
   "source": [
    "## 2.1. Environment Setup\n",
    "Detect if running in Google Colab or local environment, handle repository cloning, dependency installation, numpy compatibility fixes, and set up Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    # Check if repository already exists\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    %pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "def fix_numpy_compatibility():\n",
    "    print(\"Fixing numpy compatibility for hopsworks/pandas...\")\n",
    "    try:\n",
    "        # Step 1: Clean uninstall\n",
    "        %pip uninstall -y numpy scipy pandas great-expectations --quiet\n",
    "        \n",
    "        # Step 2: Reinstall with proper dependencies\n",
    "        %pip install --no-cache-dir numpy==1.24.3 scipy==1.10.1 pandas==2.0.3\n",
    "        \n",
    "        # Step 3: Install great-expectations separately to avoid conflicts\n",
    "        %pip install --no-cache-dir great-expectations==0.18.19\n",
    "        \n",
    "        print(\"✓ Packages fixed. Please restart runtime and run again.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Fix failed: {e}\")\n",
    "        # Fallback approach\n",
    "        try:\n",
    "            %pip install --force-reinstall --no-cache-dir numpy==1.24.3 scipy==1.10.1 pandas==2.0.3\n",
    "            print(\"✓ Fallback fix applied. Please restart runtime and run again.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"✗ Fallback also failed: {e2}\")\n",
    "            print(\"Please manually restart runtime and try: !pip install numpy==1.24.3 scipy==1.10.1 pandas==2.0.3\")\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    try:\n",
    "        import numpy\n",
    "        numpy.array([1, 2, 3])\n",
    "        import pandas as pd\n",
    "        print(\"Basic packages working correctly\")\n",
    "\n",
    "        clone_repository()\n",
    "        install_dependencies()\n",
    "\n",
    "        import hopsworks\n",
    "        print(\"All packages working correctly\")\n",
    "\n",
    "        root_dir = str(Path().absolute())\n",
    "        print(\"Google Colab environment\")\n",
    "        \n",
    "    except (ValueError, ImportError) as e:\n",
    "        if \"numpy.dtype size changed\" in str(e):\n",
    "            fix_numpy_compatibility()\n",
    "            raise SystemExit(\"Please restart runtime (Runtime > Restart runtime) and run the notebook again.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    if root_dir.parts[-1:] == (\"src\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"airquality\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"notebooks\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "from utils import config\n",
    "\n",
    "if is_google_colab():\n",
    "    from google.colab import userdata\n",
    "    import hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=userdata.get('HOPSWORKS_API_KEY'),\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    AQICN_API_KEY = userdata.get('AQICN_API_KEY')\n",
    "    \n",
    "else:\n",
    "    # Local development - use .env file\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5952fc",
   "metadata": {},
   "source": [
    "## 2.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import json\n",
    "import warnings\n",
    "from utils import airquality\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd2dd2",
   "metadata": {},
   "source": [
    "## 2.3. Setup\n",
    "Hopsworks and feature store setup - configure Hopsworks connection, retrieve API keys, and connect to existing air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    fs = project.get_feature_store()\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "else:\n",
    "    HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "    if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "        HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "    project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Sensor Mode\n",
    "Set SENSOR_CSV_FILE in .env with the relative path to a sensor to process it, or leave it unset to process all sensors in the `data` folder.\n",
    "\n",
    "Retrieve sensor location data from Hopsworks secret, parse JSON location metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    sensor_csv_file = None\n",
    "else:\n",
    "    sensor_csv_file = getattr(settings, 'SENSOR_CSV_FILE', None)\n",
    "\n",
    "if sensor_csv_file:\n",
    "    # Read one secret for single sensor mode\n",
    "    _, _, _, _, _, sensor_id = airquality.read_sensor_data(sensor_csv_file)\n",
    "    secret_name = f\"SENSOR_LOCATION_JSON_{sensor_id}\"\n",
    "    location_str = secrets.get_secret(secret_name).value\n",
    "    locations = {sensor_id: json.loads(location_str)}\n",
    "else:\n",
    "    # Read all individual secrets in batch mode\n",
    "    all_secrets = secrets.get_secrets()\n",
    "    locations = {}\n",
    "    for secret in all_secrets:\n",
    "        if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "            sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "            location_str = secrets.get_secret(secret.name).value\n",
    "            if location_str:\n",
    "                locations[sensor_id] = json.loads(location_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa567b0",
   "metadata": {},
   "source": [
    "## 2.5. Helper Methods\n",
    "Data processing functions - get daily weather forecasts and fetch current data, air quality and weather, for each sensor location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_weather_forecast(city, latitude, longitude):\n",
    "    hourly_df = airquality.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index(\"date\")\n",
    "    daily_df = hourly_df.between_time(\"11:59\", \"12:01\")\n",
    "    daily_df = daily_df.reset_index()\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"]).dt.date\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n",
    "    daily_df[\"city\"] = city\n",
    "    return daily_df\n",
    "\n",
    "\n",
    "def fetch_data_for_location(location):\n",
    "    country = location[\"country\"]\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    aqicn_url = location[\"aqicn_url\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "\n",
    "    aq_today_df = airquality.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    daily_df = get_daily_weather_forecast(city, latitude, longitude)\n",
    "    return aq_today_df, daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.6. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs = []\n",
    "weathers = []\n",
    "for sensor, location in locations.items():\n",
    "    aq_today_df, weather_daily_forecast_df = fetch_data_for_location(location)\n",
    "\n",
    "    # Air quality FG shape\n",
    "    aq_today_df = aq_today_df.assign(\n",
    "        sensor_id=str(sensor),\n",
    "        street=location[\"street\"],\n",
    "        city=location[\"city\"],\n",
    "        country=location[\"country\"],\n",
    "        feed_url=location[\"aqicn_url\"],\n",
    "    )\n",
    "    aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"])\n",
    "\n",
    "    # Weather FG shape\n",
    "    weather_daily_forecast_df = weather_daily_forecast_df.assign(\n",
    "        sensor_id=str(sensor),\n",
    "        city=location[\"city\"],\n",
    "        latitude=location[\"latitude\"],\n",
    "        longitude=location[\"longitude\"],\n",
    "    )\n",
    "    weather_daily_forecast_df[\"date\"] = pd.to_datetime(\n",
    "        weather_daily_forecast_df[\"date\"]\n",
    "    )\n",
    "\n",
    "    aqs.append(aq_today_df)\n",
    "    weathers.append(weather_daily_forecast_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1409d2",
   "metadata": {},
   "source": [
    "## 2.7. Data Preparation\n",
    "Concatenate air quality data, retrieve historical data from feature store, and prepare datasets for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_df = pd.concat(aqs)\n",
    "aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "# Get historical data for rolling window and lagged features\n",
    "historical_start = today - datetime.timedelta(days=4)\n",
    "historical_df = pd.DataFrame()\n",
    "\n",
    "# Read historical data from feature group and filter for the last 4 days\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"].dt.date >= historical_start) & (historical_df[\"date\"].dt.date < today)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4c900",
   "metadata": {},
   "source": [
    "## 2.8. Feature Engineering\n",
    "Combine historical and current air quality data to calculate rolling averages, lagged features, and nearby sensor aggregations for today's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([historical_df, aq_df], ignore_index=True) if not historical_df.empty else aq_df\n",
    "combined_df = airquality.add_rolling_window_feature(combined_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "combined_df = airquality.add_lagged_features(combined_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "combined_df = airquality.add_nearby_sensor_feature(combined_df, locations, column=\"pm25_lag_1d\", n_closest=3)\n",
    "aq_df = combined_df[combined_df[\"date\"].dt.date == today].copy()\n",
    "aq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ed5ae",
   "metadata": {},
   "source": [
    "## 2.9. Weather Data Processing\n",
    "Concatenate weather forecast data and convert data types to match Hopsworks feature group schema (float32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat(weathers)\n",
    "weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "# Convert to float32 to match Hopsworks feature group schema\n",
    "weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float32\")\n",
    "weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float32\")\n",
    "weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float32\")\n",
    "weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float32\")\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef9c7d",
   "metadata": {},
   "source": [
    "## 2.10. Upload to Feature Store\n",
    "Insert today's processed air quality and weather data into the respective Hopsworks feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg.insert(aq_df)\n",
    "weather_fg.insert(weather_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
