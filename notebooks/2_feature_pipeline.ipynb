{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Environment Setup\n",
    "Detect if running in Google Colab or local environment, handle repository cloning, dependency installation, numpy compatibility fixes, and set up Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed990082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# if os.path.exists('/content/pm25-forecast-openmeteo-aqicn'):\n",
    "#     shutil.rmtree('/content/pm25-forecast-openmeteo-aqicn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "Added the following directory to the PYTHONPATH: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    # Check if repository already exists\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "def fix_numpy_compatibility():\n",
    "    print(\"Fixing numpy compatibility for hopsworks/pandas...\")\n",
    "    try:\n",
    "        # Use compatible versions that work with the installed packages\n",
    "        !pip install --force-reinstall numpy==1.26.4 pandas==2.0.3\n",
    "        print(\"Numpy and pandas fixed. Please restart runtime and run again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fix attempt failed: {e}\")\n",
    "        print(\"Please manually restart runtime and try again.\")\n",
    "\n",
    "if is_google_colab():\n",
    "    try:\n",
    "        import numpy\n",
    "        numpy.array([1, 2, 3])\n",
    "        import pandas as pd\n",
    "        print(\"Basic packages working correctly\")\n",
    "\n",
    "        clone_repository()\n",
    "        install_dependencies()\n",
    "\n",
    "        import hopsworks\n",
    "        print(\"All packages working correctly\")\n",
    "\n",
    "        root_dir = str(Path().absolute())\n",
    "        print(\"Google Colab environment\")\n",
    "        \n",
    "    except (ValueError, ImportError) as e:\n",
    "        if \"numpy.dtype size changed\" in str(e) or \"numpy.strings\" in str(e) or \"numpy\" in str(e).lower():\n",
    "            fix_numpy_compatibility()\n",
    "            raise SystemExit(\"Please restart runtime (Runtime > Restart runtime) and run the notebook again.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    if root_dir.parts[-1:] == (\"src\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"airquality\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"notebooks\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "if is_google_colab():\n",
    "    from google.colab import userdata\n",
    "    import hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=userdata.get('HOPSWORKS_API_KEY'),\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    AQICN_API_KEY = userdata.get('AQICN_API_KEY')\n",
    "    \n",
    "else:\n",
    "    # Local development - use .env file\n",
    "    from utils import config\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5952fc",
   "metadata": {},
   "source": [
    "## 2.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import json\n",
    "import warnings\n",
    "import requests\n",
    "from utils import airquality\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd2dd2",
   "metadata": {},
   "source": [
    "## 2.3. Setup\n",
    "Hopsworks and feature store setup - configure Hopsworks connection, retrieve API keys, and connect to existing air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010e645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 10:01:07,652 INFO: Initializing external client\n",
      "2025-12-12 10:01:07,655 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 10:01:09,798 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "if is_google_colab():\n",
    "    fs = project.get_feature_store()\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "else:\n",
    "    HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "    if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "        HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "    project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Sensor Location Loading\n",
    "Retrieve sensor location data from Hopsworks secrets for all sensors and parse JSON location metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all individual secrets for all sensors\n",
    "all_secrets = secrets.get_secrets()\n",
    "locations = {}\n",
    "for secret in all_secrets:\n",
    "    if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "        sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "        location_str = secrets.get_secret(secret.name).value\n",
    "        if location_str:\n",
    "            locations[sensor_id] = json.loads(location_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb50d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixed 105 sensor URLs from @ to A format\n"
     ]
    }
   ],
   "source": [
    "# Convert @ URLs to A URLs for Swedish sensors (AQICN API change)\n",
    "fixed_count = 0\n",
    "for sensor_id, location in locations.items():\n",
    "    if \"@\" in location[\"aqicn_url\"]:\n",
    "        old_url = location[\"aqicn_url\"]\n",
    "        new_url = old_url.replace(\"/@\", \"/A\")\n",
    "        location[\"aqicn_url\"] = new_url\n",
    "        fixed_count += 1\n",
    "\n",
    "if fixed_count > 0:\n",
    "    print(f\"üîß Fixed {fixed_count} sensor URLs from @ to A format\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è All sensor URLs already in correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa567b0",
   "metadata": {},
   "source": [
    "## 2.5. Helper Methods\n",
    "Data processing functions - get daily weather forecasts and fetch current data, air quality and weather, for each sensor location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137cb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_weather_forecast(city, latitude, longitude):\n",
    "    hourly_df = airquality.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index(\"date\")\n",
    "    daily_df = hourly_df.between_time(\"11:59\", \"12:01\")\n",
    "    daily_df = daily_df.reset_index()\n",
    "    # daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"]).dt.date\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n",
    "    daily_df[\"city\"] = city\n",
    "    return daily_df\n",
    "\n",
    "\n",
    "def fetch_data_for_location(location):\n",
    "    country = location[\"country\"]\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    aqicn_url = location[\"aqicn_url\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "\n",
    "    aq_today_df = airquality.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    daily_df = get_daily_weather_forecast(city, latitude, longitude)\n",
    "    return aq_today_df, daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.6. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e4e975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 105 sensor locations...\n",
      "Error: There may be an incorrect URL for your Sensor or it is not contactable right now. The API response does not contain data.  Error message: no such station\n",
      "‚ö†Ô∏è  Skipping sensor 362923: no such station\n",
      "Error: There may be an incorrect URL for your Sensor or it is not contactable right now. The API response does not contain data.  Error message: no such station\n",
      "‚ö†Ô∏è  Skipping sensor 472264: no such station\n",
      "‚ö†Ô∏è  Skipping sensor 474841: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "aqs = []\n",
    "weathers = []\n",
    "print(f\"üîç Processing {len(locations)} sensor locations...\")\n",
    "\n",
    "for sensor, location in locations.items():\n",
    "    try:\n",
    "        aq_today_df, weather_daily_forecast_df = fetch_data_for_location(location)\n",
    "\n",
    "        aq_today_df = aq_today_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            street=location[\"street\"],\n",
    "            city=location[\"city\"],\n",
    "            country=location[\"country\"],\n",
    "            feed_url=location[\"aqicn_url\"],\n",
    "        )\n",
    "        aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"])\n",
    "\n",
    "        # Weather FG shape\n",
    "        weather_daily_forecast_df = weather_daily_forecast_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            city=location[\"city\"],\n",
    "            latitude=location[\"latitude\"],\n",
    "            longitude=location[\"longitude\"],\n",
    "        )\n",
    "        weather_daily_forecast_df[\"date\"] = pd.to_datetime(\n",
    "            weather_daily_forecast_df[\"date\"]\n",
    "        )\n",
    "\n",
    "        aqs.append(aq_today_df)\n",
    "        weathers.append(weather_daily_forecast_df)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ö†Ô∏è  Skipping sensor {sensor}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Unexpected error with sensor {sensor}: {type(e).__name__}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6bd1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(weathers))\n",
    "# print(weathers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5e08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 10:09:17,974 ERROR: Flight returned timeout error, with message: Deadline Exceeded\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 209, in __init__\n",
      "    self._health_check()\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 55, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 289, in call\n",
      "    raise attempt.get()\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 326, in get\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 273, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 308, in _health_check\n",
      "    list(self._connection.do_action(action, options=options))\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 1631, in _do_action_response\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 60, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightTimedOutError: Flight returned timeout error, with message: Deadline Exceeded\n",
      "2025-12-12 10:09:23,105 ERROR: Flight returned timeout error, with message: Deadline Exceeded\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 395, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 460, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 55, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 279, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 326, in get\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 273, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 441, in _get_dataset\n",
      "    info = self.get_flight_info(descriptor)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 55, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 279, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 326, in get\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retrying.py\", line 273, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krist\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hsfs\\core\\arrow_flight_client.py\", line 428, in get_flight_info\n",
      "    return self._connection.get_flight_info(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 1675, in pyarrow._flight.FlightClient.get_flight_info\n",
      "  File \"pyarrow\\\\_flight.pyx\", line 60, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightTimedOutError: Flight returned timeout error, with message: Deadline Exceeded\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n"
     ]
    }
   ],
   "source": [
    "aq_df = pd.concat(aqs) if aqs else pd.DataFrame()\n",
    "if not aq_df.empty:\n",
    "    aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "    aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "    aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "    # Data quality check 1: Remove rows with missing PM2.5 values\n",
    "    initial_count = len(aq_df)\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    if len(aq_df) < initial_count:\n",
    "        print(f\"üßπ Removed {initial_count - len(aq_df)} rows with missing PM2.5 values\")\n",
    "\n",
    "# Get historical data for rolling window and lagged features\n",
    "historical_start = today - datetime.timedelta(days=4)\n",
    "historical_df = pd.DataFrame()\n",
    "\n",
    "# Read historical data from feature group and filter for the last 4 days\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"].dt.date >= historical_start) & (historical_df[\"date\"].dt.date < today)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca48edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final data quality: 102 clean rows ready for feature store\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>feed_url</th>\n",
       "      <th>pm25_rolling_3d</th>\n",
       "      <th>pm25_lag_1d</th>\n",
       "      <th>pm25_lag_2d</th>\n",
       "      <th>pm25_lag_3d</th>\n",
       "      <th>pm25_nearby_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>H√∂rnettv√§gen</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>105325</td>\n",
       "      <td>https://api.waqi.info/feed/A105325/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Uppsala</td>\n",
       "      <td>Kuggebro</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>107110</td>\n",
       "      <td>https://api.waqi.info/feed/A107110/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>B√•gskyttegatan</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>112672</td>\n",
       "      <td>https://api.waqi.info/feed/A112672/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>S√∂derby</td>\n",
       "      <td>Eker√∂v√§gen</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>112993</td>\n",
       "      <td>https://api.waqi.info/feed/A112993/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>St√§ket</td>\n",
       "      <td>Aron Lindgrens v√§g</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>113539</td>\n",
       "      <td>https://api.waqi.info/feed/A113539/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25 country          city              street       date sensor_id  \\\n",
       "0   4.0  Sweden  √ñrnsk√∂ldsvik        H√∂rnettv√§gen 2025-12-12    105325   \n",
       "0   2.0  Sweden       Uppsala            Kuggebro 2025-12-12    107110   \n",
       "0  22.0  Sweden    Gothenburg      B√•gskyttegatan 2025-12-12    112672   \n",
       "0   2.0  Sweden       S√∂derby          Eker√∂v√§gen 2025-12-12    112993   \n",
       "0   2.0  Sweden        St√§ket  Aron Lindgrens v√§g 2025-12-12    113539   \n",
       "\n",
       "                              feed_url  pm25_rolling_3d  pm25_lag_1d  \\\n",
       "0  https://api.waqi.info/feed/A105325/              NaN          NaN   \n",
       "0  https://api.waqi.info/feed/A107110/              NaN          NaN   \n",
       "0  https://api.waqi.info/feed/A112672/              NaN          NaN   \n",
       "0  https://api.waqi.info/feed/A112993/              NaN          NaN   \n",
       "0  https://api.waqi.info/feed/A113539/              NaN          NaN   \n",
       "\n",
       "   pm25_lag_2d  pm25_lag_3d  pm25_nearby_avg  \n",
       "0          NaN          NaN              NaN  \n",
       "0          NaN          NaN              NaN  \n",
       "0          NaN          NaN              NaN  \n",
       "0          NaN          NaN              NaN  \n",
       "0          NaN          NaN              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([historical_df, aq_df], ignore_index=True) if not historical_df.empty else aq_df\n",
    "if not combined_df.empty:\n",
    "    combined_df = airquality.add_rolling_window_feature(combined_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "    combined_df = airquality.add_lagged_features(combined_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    combined_df = airquality.add_nearby_sensor_feature(combined_df, locations, column=\"pm25_lag_1d\", n_closest=3)\n",
    "    \n",
    "    # Data quality check 2: Clean up NaNs created by feature engineering\n",
    "    before_cleaning = len(combined_df[combined_df[\"date\"].dt.date == today])\n",
    "    \n",
    "    # Only keep today's data and remove rows where essential features are NaN\n",
    "    aq_df = combined_df[combined_df[\"date\"].dt.date == today].copy()\n",
    "    \n",
    "    # Remove rows where pm25 is still NaN after all processing\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    \n",
    "    after_cleaning = len(aq_df)\n",
    "    if before_cleaning > after_cleaning:\n",
    "        print(f\"üßπ Removed {before_cleaning - after_cleaning} rows with NaN values after feature engineering\")\n",
    "    \n",
    "    print(f\"üìä Final data quality: {len(aq_df)} clean rows ready for feature store\")\n",
    "else:\n",
    "    aq_df = pd.DataFrame()\n",
    "    print(\"‚ö†Ô∏è  No data available for processing\")\n",
    "aq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebaf2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è  Weather data quality: 714 clean weather rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-12 12:00:00</td>\n",
       "      <td>-5.9195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>105325</td>\n",
       "      <td>63.274</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-13 12:00:00</td>\n",
       "      <td>2.4305</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.039999</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>105325</td>\n",
       "      <td>63.274</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-14 12:00:00</td>\n",
       "      <td>3.3805</td>\n",
       "      <td>0.5</td>\n",
       "      <td>23.039999</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>105325</td>\n",
       "      <td>63.274</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-15 12:00:00</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.170786</td>\n",
       "      <td>176.081833</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>105325</td>\n",
       "      <td>63.274</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-16 12:00:00</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.545584</td>\n",
       "      <td>81.869987</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>105325</td>\n",
       "      <td>63.274</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  temperature_2m_mean  precipitation_sum  \\\n",
       "0 2025-12-12 12:00:00              -5.9195                0.0   \n",
       "1 2025-12-13 12:00:00               2.4305                1.1   \n",
       "2 2025-12-14 12:00:00               3.3805                0.5   \n",
       "3 2025-12-15 12:00:00               3.3000                0.0   \n",
       "4 2025-12-16 12:00:00               1.6500                0.0   \n",
       "\n",
       "   wind_speed_10m_max  wind_direction_10m_dominant          city sensor_id  \\\n",
       "0            7.920000                    44.000000  √ñrnsk√∂ldsvik    105325   \n",
       "1           23.039999                   176.000000  √ñrnsk√∂ldsvik    105325   \n",
       "2           23.039999                   189.000000  √ñrnsk√∂ldsvik    105325   \n",
       "3           13.170786                   176.081833  √ñrnsk√∂ldsvik    105325   \n",
       "4            2.545584                    81.869987  √ñrnsk√∂ldsvik    105325   \n",
       "\n",
       "   latitude  longitude  \n",
       "0    63.274     18.684  \n",
       "1    63.274     18.684  \n",
       "2    63.274     18.684  \n",
       "3    63.274     18.684  \n",
       "4    63.274     18.684  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.concat(weathers) if weathers else pd.DataFrame()\n",
    "if not weather_df.empty:\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    \n",
    "    # Data quality check 3: Remove rows with missing weather data\n",
    "    initial_weather_count = len(weather_df)\n",
    "    weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "    \n",
    "    # Convert to float32 to match Hopsworks feature group schema\n",
    "    weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float32\")\n",
    "    weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float32\")\n",
    "    weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float32\")\n",
    "    weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float32\")\n",
    "    \n",
    "    if len(weather_df) < initial_weather_count:\n",
    "        print(f\"üßπ Removed {initial_weather_count - len(weather_df)} rows with missing weather data\")\n",
    "    \n",
    "    print(f\"üå§Ô∏è  Weather data quality: {len(weather_df)} clean weather rows\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No weather data available\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22a610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserting 102 air quality rows and 714 weather rows to feature store\n",
      "2025-12-12 10:09:25,376 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1774972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 102/102 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_all_1_offline_fg_materialization/executions\n",
      "2025-12-12 10:09:39,899 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1783130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 714/714 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/weather_all_1_offline_fg_materialization/executions\n",
      "üìÅ Data successfully inserted to feature store\n"
     ]
    }
   ],
   "source": [
    "# Final validation before inserting to feature store\n",
    "if not aq_df.empty and not weather_df.empty:\n",
    "    print(f\"‚úÖ Inserting {len(aq_df)} air quality rows and {len(weather_df)} weather rows to feature store\")\n",
    "    air_quality_fg.insert(aq_df)\n",
    "    weather_fg.insert(weather_df)\n",
    "    print(\"üìÅ Data successfully inserted to feature store\")\n",
    "else:\n",
    "    if aq_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean air quality data to insert\")\n",
    "    if weather_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean weather data to insert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
