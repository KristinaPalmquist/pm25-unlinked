{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n",
      "2026-01-09 16:01:22,969 INFO: Initializing external client\n",
      "2026-01-09 16:01:22,969 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "#  Establish project root directory\n",
    "def find_project_root(start: Path):\n",
    "    for parent in [start] + list(start.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return start\n",
    "\n",
    "root_dir = find_project_root(Path().absolute())\n",
    "print(\"Project root dir:\", root_dir)\n",
    "\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "import hopsworks\n",
    "\n",
    "#  Project imports\n",
    "from utils import cleaning, config, feature_engineering, fetchers, hopsworks_admin, incremental, metadata\n",
    "\n",
    "#  Load settings \n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "GITHUB_USERNAME = settings.GH_USERNAME.get_secret_value()\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e733e1",
   "metadata": {},
   "source": [
    "Repository management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = hopsworks_admin.clone_or_update_repo(GITHUB_USERNAME)\n",
    "os.chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"AQICN_API_KEY missing.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33477f76",
   "metadata": {},
   "source": [
    "## 2.3. Get Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg, sensor_metadata_fg, weather_fg = hopsworks_admin.create_feature_groups(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Load Metadata from Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = sensor_metadata_fg.read()\n",
    "if len(metadata_df) == 0:\n",
    "    print(\"‚ö†Ô∏è No sensor metadata found. Run pipeline 1 (backfill) first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"üìç Loaded metadata for {len(metadata_df)} sensors\")\n",
    "metadata_df = metadata_df.set_index(\"sensor_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.5. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata from feature group for nearby sensor calculations\n",
    "metadata_indexed = metadata_df.copy()\n",
    "metadata_indexed.index = metadata_indexed.index.astype(int)\n",
    "\n",
    "successful = 0\n",
    "failed = 0\n",
    "skipped = 0\n",
    "\n",
    "print(f\"üîç Processing {len(metadata_df)} sensor locations...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29f776",
   "metadata": {},
   "source": [
    "Load historical Air Quality data for all sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_start = today - timedelta(days=4)\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        today_dt = pd.to_datetime(today)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"] >= pd.to_datetime(historical_start)) & \n",
    "            (historical_df[\"date\"] < today_dt)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "        # Only keep sensors that exist in metadata\n",
    "        historical_df = historical_df[historical_df[\"sensor_id\"].isin(metadata_indexed.index)]\n",
    "    else:\n",
    "        historical_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error reading historical data: {e}\")\n",
    "    historical_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c824a",
   "metadata": {},
   "source": [
    "Initialize containers for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_list = []\n",
    "weather_dict = {}  # location_id -> weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc25fcc",
   "metadata": {},
   "source": [
    "Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor_id, meta in metadata_df.iterrows():\n",
    "    try:\n",
    "        # Fetch current air quality\n",
    "        aq_today_df = fetchers.get_pm25(meta[\"aqicn_url\"], meta[\"country\"], meta[\"city\"], \n",
    "                                       meta[\"street\"], today, AQICN_API_KEY)\n",
    "        \n",
    "        if aq_today_df.empty or aq_today_df['pm25'].isna().all():\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Format air quality data\n",
    "        aq_today_df[\"sensor_id\"] = int(sensor_id)\n",
    "        aq_today_df[\"location_id\"] = int(meta[\"location_id\"])\n",
    "        aq_today_df[\"pm25\"] = pd.to_numeric(aq_today_df[\"pm25\"], errors=\"coerce\")\n",
    "        aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"]).dt.tz_localize(None)\n",
    "        aq_today_df = aq_today_df.drop(columns=[\"url\", \"country\", \"city\", \"street\"], errors=\"ignore\")\n",
    "        \n",
    "        # Combine with historical data (last 4 days)\n",
    "        sensor_historical = historical_df[historical_df[\"sensor_id\"] == sensor_id] if not historical_df.empty else pd.DataFrame()\n",
    "        combined = pd.concat([sensor_historical, aq_today_df], ignore_index=True) if not sensor_historical.empty else aq_today_df\n",
    "        combined = combined.sort_values(\"date\").reset_index(drop=True)\n",
    "        \n",
    "        # Add features using ALL data (historical + today)\n",
    "        combined = feature_engineering.add_rolling_window_feature(combined, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "        combined = feature_engineering.add_lagged_features(combined, column=\"pm25\", lags=[1, 2, 3])\n",
    "        combined = feature_engineering.add_nearby_sensor_feature(combined, metadata_indexed, n_closest=3)\n",
    "        \n",
    "        # NOW filter to only today - but features are already calculated\n",
    "        aq_final = combined[combined[\"date\"].dt.date == today].copy()\n",
    "        \n",
    "        # Check if we actually have today's data with valid pm25\n",
    "        if aq_final.empty or aq_final['pm25'].isna().all():\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        aq_list.append(aq_final)\n",
    "        \n",
    "        # Fetch weather for location (once per location)\n",
    "        location_id = int(meta[\"location_id\"])\n",
    "        if location_id not in weather_dict:\n",
    "            end_date = today + timedelta(days=7)\n",
    "            weather_df = fetchers.get_weather_forecast(location_id, today, end_date, \n",
    "                                                      meta[\"latitude\"], meta[\"longitude\"])\n",
    "            if not weather_df.empty:\n",
    "                weather_df[\"location_id\"] = location_id\n",
    "                weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "                weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "                weather_dict[location_id] = weather_df\n",
    "        \n",
    "        successful += 1\n",
    "        if successful % 10 == 0:\n",
    "            print(f\"‚úÖ Processed {successful}/{len(metadata_df)} sensors\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(f\"‚ùå Sensor {sensor_id}: {type(e).__name__}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85a2ee",
   "metadata": {},
   "source": [
    "Batch insert Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "if aq_list:\n",
    "    all_aq = pd.concat(aq_list, ignore_index=True)\n",
    "    \n",
    "    # Convert types\n",
    "    all_aq = all_aq.astype({\n",
    "        \"sensor_id\": \"int32\",\n",
    "        \"location_id\": \"int32\",\n",
    "        \"pm25\": \"float64\",\n",
    "        \"pm25_lag_1d\": \"float64\",\n",
    "        \"pm25_lag_2d\": \"float64\",\n",
    "        \"pm25_lag_3d\": \"float64\",\n",
    "        \"pm25_rolling_3d\": \"float64\",\n",
    "        \"pm25_nearby_avg\": \"float64\",\n",
    "    })\n",
    "    \n",
    "    # Ensure correct column order\n",
    "    fg_columns = [f.name for f in air_quality_fg.features]\n",
    "    all_aq = all_aq[fg_columns]\n",
    "    \n",
    "    air_quality_fg.insert(all_aq)\n",
    "    print(f\"üìä Inserted {len(all_aq)} air quality records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1547f64",
   "metadata": {},
   "source": [
    "Batch insert Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if weather_dict:\n",
    "    all_weather = pd.concat(weather_dict.values(), ignore_index=True)\n",
    "    \n",
    "    # Convert types\n",
    "    all_weather = all_weather.astype({\n",
    "        \"location_id\": \"int32\",\n",
    "        \"temperature_2m_mean\": \"float64\",\n",
    "        \"precipitation_sum\": \"float64\",\n",
    "        \"wind_speed_10m_max\": \"float64\",\n",
    "        \"wind_direction_10m_dominant\": \"float64\",\n",
    "    })\n",
    "    \n",
    "    weather_fg.insert(all_weather)\n",
    "    print(f\"üå§Ô∏è Inserted {len(all_weather)} weather records for {len(weather_dict)} locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845de6",
   "metadata": {},
   "source": [
    "Print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74278aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìä Summary: ‚úÖ {successful} successful, ‚è≠Ô∏è {skipped} skipped, ‚ùå {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c9844",
   "metadata": {},
   "source": [
    "## 2.6. Inspect Inserted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1986667",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_aq' in locals() and not all_aq.empty:\n",
    "    print(f\"‚úÖ Air quality records inserted: {len(all_aq)}\")\n",
    "    print(\"\\nüìã Sample air quality data:\")\n",
    "    print(all_aq.head())\n",
    "    print(\"\\nüîß Air quality data types:\")\n",
    "    print(all_aq.dtypes)\n",
    "    print(\"\\nüìÖ Date range:\")\n",
    "    print(f\"From {all_aq['date'].min()} to {all_aq['date'].max()}\")\n",
    "\n",
    "if 'all_weather' in locals() and not all_weather.empty:\n",
    "    print(f\"\\nüå§Ô∏è Weather records inserted: {len(all_weather)}\")\n",
    "    print(\"\\nüìã Sample weather data:\")\n",
    "    print(all_weather.head())\n",
    "    print(\"\\nüîß Weather data types:\")\n",
    "    print(all_weather.dtypes)\n",
    "    print(\"\\nüìÖ Unique weather dates:\")\n",
    "    print(all_weather['date'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
