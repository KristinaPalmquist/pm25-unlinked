{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6c5b",
   "metadata": {},
   "source": [
    "### 2.1.1. Import Libraries and Initialize Hopsworks Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25\n",
      "HopsworksSettings initialized!\n",
      "2026-01-19 09:20:41,647 INFO: Initializing external client\n",
      "2026-01-19 09:20:41,649 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-19 09:20:43,886 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n",
      "2026-01-19 09:20:45,101 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2026-01-19 09:20:45,112 INFO: Initializing external client\n",
      "2026-01-19 09:20:45,116 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-19 09:20:46,583 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "#  Establish project root directory\n",
    "def find_project_root(start: Path):\n",
    "    for parent in [start] + list(start.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return start\n",
    "\n",
    "root_dir = find_project_root(Path().absolute())\n",
    "print(\"Project root dir:\", root_dir)\n",
    "\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "import hopsworks\n",
    "from urllib3.exceptions import ProtocolError  \n",
    "from requests.exceptions import ConnectionError, Timeout\n",
    "from confluent_kafka import KafkaException\n",
    "import numpy as np\n",
    "\n",
    "#  Project imports\n",
    "from utils import cleaning, config, feature_engineering, fetchers, hopsworks_admin, incremental, metadata\n",
    "\n",
    "#  Load settings \n",
    "settings = config.HopsworksSettings()\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "GITHUB_USERNAME = settings.GH_USERNAME.get_secret_value()\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e733e1",
   "metadata": {},
   "source": [
    "### 2.1.2. Repository management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository exists at c:\\Users\\krist\\Documents\\GitHub\\pm25\\notebooks\\pm25-forecast-openmeteo-aqicn\n"
     ]
    }
   ],
   "source": [
    "repo_dir = hopsworks_admin.clone_or_update_repo(GITHUB_USERNAME)\n",
    "os.chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fa04a",
   "metadata": {},
   "source": [
    "### 2.1.3. Configure API Keys and Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010e645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date.today()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"AQICN_API_KEY missing.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33477f76",
   "metadata": {},
   "source": [
    "## 2.2. Get Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2713f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg, weather_fg = hopsworks_admin.create_feature_groups(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.3. Load Metadata from Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (19.86s) \n",
      "ğŸ“ Loaded metadata for 103 sensors\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from air_quality feature group\n",
    "aq_data = air_quality_fg.read()\n",
    "\n",
    "if len(aq_data) == 0:\n",
    "    print(\"âš ï¸ No air quality data found. Run pipeline 1 (backfill) first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Extract unique sensor metadata\n",
    "metadata_df = aq_data[[\"sensor_id\", \"latitude\", \"longitude\", \"city\", \"street\", \"country\", \"aqicn_url\"]].drop_duplicates(subset=[\"sensor_id\"])\n",
    "print(f\"ğŸ“ Loaded metadata for {len(metadata_df)} sensors\")\n",
    "metadata_df = metadata_df.set_index(\"sensor_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.4. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d8e84",
   "metadata": {},
   "source": [
    "### 2.4.1. Initialize Processing Counters and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616e383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Processing 103 sensor locations.\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from feature group for nearby sensor calculations\n",
    "metadata_indexed = metadata_df.copy()\n",
    "metadata_indexed.index = metadata_indexed.index.astype(int)\n",
    "\n",
    "successful = 0\n",
    "failed = 0\n",
    "skipped = 0\n",
    "\n",
    "print(f\"ğŸ” Processing {len(metadata_indexed)} sensor locations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29f776",
   "metadata": {},
   "source": [
    "### 2.4.2. Load Historical Air Quality Data (Last 4 Days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba1a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (7.50s) \n"
     ]
    }
   ],
   "source": [
    "historical_start = today - timedelta(days=4)\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        today_dt = pd.to_datetime(today)\n",
    "        historical_start_dt = pd.to_datetime(historical_start)\n",
    "        \n",
    "        # Include TODAY in historical data (we'll filter it out later per sensor)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"] >= historical_start_dt) & \n",
    "            (historical_df[\"date\"] <= today_dt)  # Changed < to <=\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "        \n",
    "        historical_df = historical_df[historical_df[\"sensor_id\"].isin(metadata_indexed.index)]\n",
    "    else:\n",
    "        historical_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error reading historical data: {e}\")\n",
    "    historical_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c824a",
   "metadata": {},
   "source": [
    "### 2.4.3. Identify Missing Dates for Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize containers for results\n",
    "aq_list = []\n",
    "weather_dict = {}  # sensor_id -> weather_df\n",
    "\n",
    "# Determine missing dates\n",
    "existing_dates = air_quality_fg.read()[\"date\"].dt.date.unique()\n",
    "\n",
    "today = datetime.today().date()\n",
    "start_date = today - timedelta(days=7)  # or however far back you want to check\n",
    "\n",
    "expected_dates = pd.date_range(start=start_date, end=today, freq=\"D\").date\n",
    "missing_dates = [d for d in expected_dates if d not in existing_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e421b8",
   "metadata": {},
   "source": [
    "### 2.4.4. Prepare Historical Data Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdfe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (19.67s) \n"
     ]
    }
   ],
   "source": [
    "historical_cutoff = pd.to_datetime(min(missing_dates)) - pd.Timedelta(days=3)\n",
    "historical = air_quality_fg.read()\n",
    "historical[\"date\"] = pd.to_datetime(historical[\"date\"]).dt.tz_localize(None)\n",
    "historical = historical [historical[\"date\"] >= historical_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807bdec",
   "metadata": {},
   "source": [
    "### 2.4.5. Track Existing Sensor-Date Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5bafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = historical[[\"sensor_id\", \"date\"]].copy()\n",
    "existing[\"date_only\"] = existing[\"date\"].dt.date\n",
    "existing_keys = set(zip(existing[\"sensor_id\"], existing[\"date_only\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c2227",
   "metadata": {},
   "source": [
    "### 2.4.6. Initialize Data COntainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa013b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aq_rows = [historical]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ba174",
   "metadata": {},
   "source": [
    "### 2.4.7. Fetch Missing Air Quality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb52a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sensor 60853, 1/103\n",
      "Processing sensor 59497, 2/103\n",
      "Processing sensor 59650, 3/103\n",
      "Processing sensor 112672, 4/103\n",
      "Processing sensor 60889, 5/103\n",
      "Processing sensor 60076, 6/103\n",
      "Processing sensor 58921, 7/103\n",
      "Processing sensor 84085, 8/103\n",
      "Processing sensor 89584, 9/103\n",
      "Processing sensor 198559, 10/103\n",
      "Processing sensor 149242, 11/103\n",
      "Processing sensor 105325, 12/103\n",
      "Processing sensor 78529, 13/103\n",
      "Processing sensor 88876, 14/103\n",
      "Processing sensor 65272, 15/103\n",
      "Processing sensor 77488, 16/103\n",
      "Processing sensor 351115, 17/103\n",
      "Processing sensor 122302, 18/103\n",
      "Processing sensor 196735, 19/103\n",
      "Processing sensor 69724, 20/103\n",
      "Processing sensor 60859, 21/103\n",
      "Processing sensor 65146, 22/103\n",
      "Processing sensor 57421, 23/103\n",
      "Processing sensor 194215, 24/103\n",
      "Processing sensor 82384, 25/103\n",
      "Processing sensor 180187, 26/103\n",
      "Processing sensor 68167, 27/103\n",
      "Processing sensor 129124, 28/103\n",
      "Processing sensor 79999, 29/103\n",
      "Processing sensor 59593, 30/103\n",
      "Processing sensor 462457, 31/103\n",
      "Processing sensor 417595, 32/103\n",
      "Processing sensor 59410, 33/103\n",
      "Processing sensor 249862, 34/103\n",
      "Processing sensor 345007, 35/103\n",
      "Processing sensor 128095, 36/103\n",
      "Processing sensor 70564, 37/103\n",
      "Processing sensor 63637, 38/103\n",
      "Processing sensor 65104, 39/103\n",
      "Processing sensor 65290, 40/103\n",
      "Processing sensor 252352, 41/103\n",
      "Processing sensor 60535, 42/103\n",
      "Processing sensor 79750, 43/103\n",
      "Processing sensor 58912, 44/103\n",
      "Processing sensor 415030, 45/103\n",
      "Processing sensor 65284, 46/103\n",
      "Processing sensor 107110, 47/103\n",
      "Processing sensor 90676, 48/103\n",
      "Processing sensor 163156, 49/103\n",
      "Processing sensor 59893, 50/103\n",
      "Processing sensor 121810, 51/103\n",
      "Processing sensor 60541, 52/103\n",
      "Processing sensor 60886, 53/103\n",
      "Processing sensor 77446, 54/103\n",
      "Processing sensor 59095, 55/103\n",
      "Processing sensor 88372, 56/103\n",
      "Processing sensor 62566, 57/103\n",
      "Processing sensor 494275, 58/103\n",
      "Processing sensor 61867, 59/103\n",
      "Processing sensor 376954, 60/103\n",
      "Processing sensor 191047, 61/103\n",
      "Processing sensor 59656, 62/103\n",
      "Processing sensor 62848, 63/103\n",
      "Processing sensor 407335, 64/103\n",
      "Processing sensor 87319, 65/103\n",
      "Processing sensor 420664, 66/103\n",
      "Processing sensor 409513, 67/103\n",
      "Processing sensor 78532, 68/103\n",
      "Processing sensor 80773, 69/103\n",
      "Processing sensor 250030, 70/103\n",
      "Processing sensor 76915, 71/103\n",
      "Processing sensor 61714, 72/103\n",
      "Processing sensor 69628, 73/103\n",
      "Processing sensor 476353, 74/103\n",
      "Processing sensor 92683, 75/103\n",
      "Processing sensor 112993, 76/103\n",
      "Processing sensor 82942, 77/103\n",
      "Processing sensor 58909, 78/103\n",
      "Processing sensor 60838, 79/103\n",
      "Processing sensor 192520, 80/103\n",
      "Processing sensor 81505, 81/103\n",
      "Processing sensor 65707, 82/103\n",
      "Processing sensor 59887, 83/103\n",
      "Processing sensor 63646, 84/103\n",
      "Processing sensor 59356, 85/103\n",
      "Processing sensor 60073, 86/103\n",
      "Processing sensor 61045, 87/103\n",
      "Processing sensor 61861, 88/103\n",
      "Processing sensor 154549, 89/103\n",
      "Processing sensor 61420, 90/103\n",
      "Processing sensor 404209, 91/103\n",
      "Processing sensor 59899, 92/103\n",
      "Processing sensor 533086, 93/103\n",
      "Processing sensor 113542, 94/103\n",
      "Processing sensor 208483, 95/103\n",
      "Processing sensor 62968, 96/103\n",
      "Processing sensor 474841, 97/103\n",
      "Processing sensor 113539, 98/103\n",
      "Processing sensor 497266, 99/103\n",
      "Processing sensor 58666, 100/103\n",
      "Processing sensor 401314, 101/103\n",
      "Processing sensor 562600, 102/103\n",
      "Processing sensor 556792, 103/103\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for sensor_id, meta in metadata_df.iterrows():\n",
    "    print(f\"Processing sensor {sensor_id}, {count}/{len(metadata_df)}\")\n",
    "    count += 1\n",
    "    for day in missing_dates:\n",
    "        # Skip any sensor date combination that already exists\n",
    "        if (sensor_id, day) in existing_keys:\n",
    "            continue\n",
    "        try:\n",
    "            aq_df = fetchers.get_pm25(\n",
    "                meta[\"aqicn_url\"], meta[\"country\"], meta[\"city\"],\n",
    "                meta[\"street\"], day, AQICN_API_KEY\n",
    "            )\n",
    "            if aq_df.empty or aq_df[\"pm25\"].isna().all():\n",
    "                continue\n",
    "\n",
    "            aq_df[\"sensor_id\"] = int(sensor_id)\n",
    "            aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\")\n",
    "            aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "            \n",
    "            # Add metadata columns\n",
    "            aq_df[\"city\"] = meta[\"city\"]\n",
    "            aq_df[\"street\"] = meta[\"street\"]\n",
    "            aq_df[\"country\"] = meta[\"country\"]\n",
    "            aq_df[\"aqicn_url\"] = meta[\"aqicn_url\"]\n",
    "            aq_df[\"latitude\"] = meta[\"latitude\"]\n",
    "            aq_df[\"longitude\"] = meta[\"longitude\"]\n",
    "            \n",
    "            aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "            all_aq_rows.append(aq_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Sensor {sensor_id} on {day}: {type(e).__name__}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ca1fa",
   "metadata": {},
   "source": [
    "### 2.4.8. Clean and Align Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… historical shape: (3, 14)\n",
      "âœ… cleaned_aq_rows[0] shape: (3, 14)\n",
      "âœ… cleaned_aq_rows[1] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[2] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[3] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[4] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[5] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[6] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[7] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[8] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[9] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[10] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[11] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[12] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[13] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[14] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[15] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[16] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[17] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[18] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[19] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[20] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[21] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[22] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[23] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[24] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[25] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[26] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[27] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[28] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[29] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[30] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[31] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[32] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[33] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[34] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[35] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[36] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[37] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[38] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[39] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[40] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[41] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[42] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[43] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[44] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[45] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[46] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[47] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[48] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[49] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[50] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[51] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[52] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[53] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[54] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[55] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[56] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[57] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[58] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[59] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[60] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[61] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[62] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[63] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[64] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[65] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[66] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[67] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[68] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[69] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[70] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[71] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[72] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[73] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[74] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[75] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[76] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[77] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[78] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[79] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[80] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[81] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[82] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[83] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[84] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[85] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[86] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[87] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[88] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[89] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[90] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[91] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[92] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[93] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[94] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[95] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[96] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[97] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[98] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[99] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[100] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[101] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[102] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[103] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[104] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[105] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[106] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[107] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[108] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[109] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[110] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[111] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[112] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[113] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[114] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[115] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[116] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[117] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[118] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[119] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[120] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[121] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[122] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[123] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[124] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[125] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[126] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[127] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[128] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[129] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[130] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[131] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[132] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[133] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[134] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[135] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[136] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[137] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[138] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[139] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[140] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[141] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[142] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[143] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[144] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[145] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[146] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[147] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[148] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[149] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[150] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[151] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[152] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[153] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[154] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[155] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[156] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[157] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[158] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[159] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[160] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[161] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[162] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[163] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[164] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[165] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[166] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[167] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[168] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[169] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[170] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[171] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[172] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[173] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[174] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[175] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[176] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[177] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[178] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[179] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[180] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[181] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[182] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[183] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[184] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[185] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[186] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[187] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[188] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[189] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[190] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[191] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[192] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[193] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[194] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[195] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[196] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[197] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[198] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[199] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[200] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[201] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[202] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[203] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[204] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[205] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[206] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[207] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[208] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[209] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[210] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[211] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[212] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[213] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[214] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[215] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[216] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[217] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[218] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[219] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[220] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[221] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[222] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[223] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[224] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[225] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[226] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[227] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[228] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[229] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[230] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[231] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[232] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[233] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[234] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[235] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[236] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[237] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[238] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[239] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[240] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[241] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[242] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[243] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[244] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[245] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[246] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[247] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[248] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[249] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[250] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[251] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[252] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[253] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[254] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[255] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[256] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[257] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[258] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[259] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[260] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[261] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[262] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[263] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[264] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[265] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[266] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[267] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[268] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[269] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[270] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[271] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[272] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[273] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[274] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[275] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[276] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[277] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[278] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[279] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[280] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[281] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[282] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[283] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[284] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[285] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[286] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[287] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[288] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[289] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[290] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[291] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[292] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[293] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[294] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[295] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[296] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[297] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[298] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[299] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[300] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[301] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[302] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[303] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[304] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[305] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[306] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[307] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[308] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[309] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[310] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[311] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[312] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[313] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[314] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[315] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[316] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[317] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[318] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[319] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[320] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[321] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[322] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[323] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[324] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[325] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[326] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[327] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[328] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[329] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[330] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[331] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[332] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[333] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[334] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[335] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[336] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[337] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[338] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[339] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[340] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[341] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[342] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[343] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[344] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[345] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[346] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[347] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[348] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[349] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[350] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[351] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[352] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[353] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[354] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[355] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[356] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[357] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[358] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[359] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[360] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[361] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[362] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[363] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[364] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[365] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[366] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[367] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[368] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[369] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[370] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[371] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[372] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[373] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[374] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[375] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[376] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[377] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[378] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[379] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[380] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[381] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[382] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[383] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[384] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[385] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[386] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[387] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[388] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[389] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[390] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[391] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[392] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[393] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[394] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[395] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[396] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[397] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[398] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[399] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[400] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[401] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[402] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[403] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[404] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[405] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[406] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[407] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[408] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[409] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[410] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[411] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[412] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[413] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[414] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[415] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[416] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[417] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[418] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[419] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[420] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[421] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[422] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[423] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[424] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[425] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[426] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[427] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[428] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[429] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[430] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[431] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[432] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[433] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[434] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[435] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[436] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[437] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[438] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[439] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[440] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[441] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[442] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[443] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[444] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[445] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[446] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[447] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[448] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[449] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[450] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[451] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[452] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[453] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[454] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[455] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[456] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[457] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[458] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[459] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[460] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[461] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[462] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[463] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[464] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[465] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[466] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[467] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[468] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[469] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[470] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[471] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[472] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[473] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[474] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[475] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[476] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[477] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[478] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[479] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[480] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[481] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[482] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[483] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[484] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[485] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[486] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[487] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[488] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[489] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[490] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[491] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[492] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[493] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[494] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[495] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[496] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[497] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[498] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[499] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[500] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[501] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[502] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[503] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[504] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[505] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[506] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[507] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[508] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[509] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[510] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[511] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[512] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[513] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[514] shape: (1, 14)\n",
      "âœ… cleaned_aq_rows[515] shape: (1, 14)\n",
      "ğŸ“‹ Column names match: True\n"
     ]
    }
   ],
   "source": [
    "cleaned_aq_rows = []\n",
    "expected_cols = historical.columns.tolist()\n",
    "\n",
    "for i, df in enumerate(all_aq_rows):\n",
    "    if df.empty or \"pm25\" not in df.columns or df[\"pm25\"].isna().all():\n",
    "        print(f\"âš ï¸ Skipping empty or invalid df[{i}]\")\n",
    "        continue\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "    # Skip if too few expected columns are present\n",
    "    if len(set(df.columns) & set(expected_cols)) < 3:\n",
    "        print(f\"âš ï¸ Skipping malformed df[{i}] with columns: {list(df.columns)}\")\n",
    "        continue\n",
    "\n",
    "    # Align columns\n",
    "    aligned = df.reindex(columns=expected_cols, fill_value=np.nan)\n",
    "\n",
    "    # Final sanity check\n",
    "    if aligned.shape[1] != len(expected_cols):\n",
    "        print(f\"âŒ Still malformed after alignment: df[{i}] shape={aligned.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Force dtype alignment to match historical\n",
    "    for col in expected_cols:\n",
    "        if col in historical.columns:\n",
    "            try:\n",
    "                aligned[col] = aligned[col].astype(historical[col].dtype, errors=\"raise\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not cast column '{col}' in df[{i}]: {e}\")\n",
    "                continue\n",
    "\n",
    "    cleaned_aq_rows.append(aligned)\n",
    "\n",
    "# Verify that column names and dtypes match\n",
    "print(\"ğŸ“‹ Column names match:\", all(df.columns.equals(historical.columns) for df in cleaned_aq_rows))\n",
    "\n",
    "for i, df in enumerate(cleaned_aq_rows):\n",
    "    mismatched = [(col, df[col].dtype, historical[col].dtype)\n",
    "                  for col in df.columns if col in historical.columns and df[col].dtype != historical[col].dtype]\n",
    "    if mismatched:\n",
    "        print(\"ğŸ“‹ Dtype mismatch:\")\n",
    "        print(f\"  df[{i}] mismatches: {mismatched}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565af2a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa784d",
   "metadata": {},
   "source": [
    "### 2.5.1. Combine Data and Add Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea612675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "all_aq = pd.concat([historical, *cleaned_aq_rows], ignore_index=True)\n",
    "all_aq = all_aq.sort_values([\"sensor_id\", \"date\"]).reset_index(drop=True)\n",
    "all_aq[\"date\"] = pd.to_datetime(all_aq[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "# Add engineered features\n",
    "all_aq = feature_engineering.add_rolling_window_feature(all_aq, window_days=3)\n",
    "all_aq = feature_engineering.add_lagged_features(all_aq, lags=[1, 2, 3])\n",
    "metadata_indexed = metadata_indexed.reset_index()\n",
    "all_aq = feature_engineering.add_nearby_sensor_feature(all_aq, metadata_indexed, n_closest=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e780ad9",
   "metadata": {},
   "source": [
    "## 2.6. Insert Data to Feature Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e42e56",
   "metadata": {},
   "source": [
    "### 2.6.1. Batch Insert Air Quality Data by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f589c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No valid rows for 2026-01-15\n",
      "2026-01-19 09:34:27,545 INFO: \t8 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1952082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-19 09:34:36,092 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1768459798660) to trigger the materialization job again.\n",
      "\n",
      "âœ… Inserted 1 rows for 2026-01-16\n",
      "2026-01-19 09:34:36,282 INFO: \t8 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1952082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-19 09:34:45,078 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1768459798660) to trigger the materialization job again.\n",
      "\n",
      "âœ… Inserted 1 rows for 2026-01-17\n",
      "2026-01-19 09:34:45,279 INFO: \t8 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1952082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-19 09:34:54,465 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1768459798660) to trigger the materialization job again.\n",
      "\n",
      "âœ… Inserted 1 rows for 2026-01-18\n",
      "2026-01-19 09:34:54,687 INFO: \t8 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1952082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-19 09:35:03,502 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1768459798660) to trigger the materialization job again.\n",
      "\n",
      "âœ… Inserted 1 rows for 2026-01-19\n"
     ]
    }
   ],
   "source": [
    "for day in missing_dates:\n",
    "    day_rows = all_aq[all_aq[\"date\"].dt.date == day].copy()\n",
    "    day_rows = day_rows.dropna(subset=[\"pm25\"])\n",
    "\n",
    "    engineered_cols = [c for c in day_rows.columns if \"lag\" in c or \"rolling\" in c or \"nearby\" in c]\n",
    "    day_rows = day_rows.dropna(subset=engineered_cols, how=\"any\")\n",
    "\n",
    "    if not day_rows.empty:\n",
    "        # Convert types to match feature group schema\n",
    "        day_rows = day_rows.astype({\n",
    "            \"sensor_id\": \"int32\",\n",
    "            \"pm25\": \"float64\",\n",
    "            \"pm25_lag_1d\": \"float64\",\n",
    "            \"pm25_lag_2d\": \"float64\",\n",
    "            \"pm25_lag_3d\": \"float64\",\n",
    "            \"pm25_rolling_3d\": \"float64\",\n",
    "            \"pm25_nearby_avg\": \"float64\",\n",
    "            \"city\": \"string\",\n",
    "            \"street\": \"string\",\n",
    "            \"country\": \"string\",\n",
    "            \"aqicn_url\": \"string\",\n",
    "            \"latitude\": \"float64\",\n",
    "            \"longitude\": \"float64\",\n",
    "        })\n",
    "        \n",
    "        # Ensure correct column order\n",
    "        fg_columns = [f.name for f in air_quality_fg.features]\n",
    "        day_rows = day_rows[fg_columns]\n",
    "        \n",
    "        air_quality_fg.insert(day_rows)\n",
    "        print(f\"âœ… Inserted {len(day_rows)} rows for {day}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No valid rows for {day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8d054",
   "metadata": {},
   "source": [
    "Build a unified dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50efa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_aq_rows = []   # raw air quality rows for all sensors\n",
    "# weather_dict = {}  # weather per sensor\n",
    "\n",
    "# for sensor_id, meta in metadata_df.iterrows():\n",
    "#     try:\n",
    "#         # Fetch today's PM2.5\n",
    "#         aq_today_df = fetchers.get_pm25(\n",
    "#             meta[\"aqicn_url\"], meta[\"country\"], meta[\"city\"],\n",
    "#             meta[\"street\"], today, AQICN_API_KEY\n",
    "#         )\n",
    "\n",
    "#         if aq_today_df.empty or aq_today_df[\"pm25\"].isna().all():\n",
    "#             continue\n",
    "\n",
    "#         # Format\n",
    "#         aq_today_df[\"sensor_id\"] = int(sensor_id)\n",
    "#         aq_today_df[\"pm25\"] = pd.to_numeric(aq_today_df[\"pm25\"], errors=\"coerce\")\n",
    "#         aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"]).dt.tz_localize(None)\n",
    "#         aq_today_df = aq_today_df.drop(columns=[\"url\", \"country\", \"city\", \"street\"], errors=\"ignore\")\n",
    "\n",
    "#         # Add historical rows for this sensor\n",
    "#         if not historical_df.empty:\n",
    "#             hist = historical_df[\n",
    "#                 (historical_df[\"sensor_id\"] == sensor_id) &\n",
    "#                 (historical_df[\"date\"].dt.date < today)\n",
    "#             ]\n",
    "#             if not hist.empty:\n",
    "#                 all_aq_rows.append(hist)\n",
    "\n",
    "#         # Add today's row\n",
    "#         all_aq_rows.append(aq_today_df)\n",
    "\n",
    "#         # Fetch weather once per sensor\n",
    "#         if sensor_id not in weather_dict:\n",
    "#             end_date = today + timedelta(days=7)\n",
    "#             wdf = fetchers.get_weather_forecast(\n",
    "#                 sensor_id, today, end_date, meta[\"latitude\"], meta[\"longitude\"]\n",
    "#             )\n",
    "#             if not wdf.empty:\n",
    "#                 wdf[\"sensor_id\"] = sensor_id\n",
    "#                 wdf[\"date\"] = pd.to_datetime(wdf[\"date\"]).dt.tz_localize(None)\n",
    "#                 weather_dict[sensor_id] = wdf\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Sensor {sensor_id}: {type(e).__name__}\")\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16417252",
   "metadata": {},
   "source": [
    "Combine all sensors into one datafram and add engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b66b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine all sensors into one dataframe\n",
    "# all_aq = pd.concat(all_aq_rows, ignore_index=True)\n",
    "# all_aq = all_aq.sort_values([\"sensor_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# # Ensure datetime is clean\n",
    "# all_aq[\"date\"] = pd.to_datetime(all_aq[\"date\"]).dt.tz_localize(None)\n",
    "\n",
    "# min_date = today - timedelta(days=4)\n",
    "# all_aq = all_aq[all_aq[\"date\"].dt.date >= min_date]\n",
    "\n",
    "# # Apply feature engineering across all sensors\n",
    "# all_aq = feature_engineering.add_rolling_window_feature(all_aq, window_days=3)\n",
    "# all_aq = feature_engineering.add_lagged_features(all_aq, lags=[1, 2, 3])\n",
    "# all_aq = feature_engineering.add_nearby_sensor_feature(all_aq, metadata_indexed, n_closest=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78444036",
   "metadata": {},
   "source": [
    "### 2.6.2. Verify Air Quality Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c2a0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sensor_id       date  pm25  pm25_lag_1d  pm25_rolling_3d  pm25_nearby_avg\n",
      "10       57421 2026-01-19  28.0         28.0             28.0        45.333333\n",
      "15       58666 2026-01-19   7.0          7.0              7.0              NaN\n",
      "20       58909 2026-01-19  44.0         44.0             44.0              NaN\n",
      "25       58912 2026-01-19  37.0         37.0             37.0              NaN\n",
      "30       58921 2026-01-19  16.0         16.0             16.0              NaN\n",
      "..         ...        ...   ...          ...              ...              ...\n",
      "500     494275 2026-01-19   5.0          5.0              5.0              NaN\n",
      "505     497266 2026-01-19   4.0          4.0              4.0              NaN\n",
      "510     533086 2026-01-19  50.0         50.0             50.0              NaN\n",
      "515     556792 2026-01-19  55.0         55.0             55.0              NaN\n",
      "520     562600 2026-01-19  50.0         50.0             50.0              NaN\n",
      "\n",
      "[103 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_aq[all_aq[\"date\"].dt.date == today][[\"sensor_id\", \"date\", \"pm25\", \"pm25_lag_1d\", \"pm25_rolling_3d\", \"pm25_nearby_avg\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea2437cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sensor_id       date  pm25  pm25_lag_1d  pm25_lag_2d  pm25_lag_3d  \\\n",
      "9        57421 2026-01-18  28.0         28.0         28.0         28.0   \n",
      "14       58666 2026-01-18   7.0          7.0          7.0          7.0   \n",
      "19       58909 2026-01-18  44.0         44.0         44.0         44.0   \n",
      "24       58912 2026-01-18  37.0         37.0         37.0         37.0   \n",
      "29       58921 2026-01-18  16.0         16.0         16.0         16.0   \n",
      "..         ...        ...   ...          ...          ...          ...   \n",
      "499     494275 2026-01-18   5.0          5.0          5.0          5.0   \n",
      "504     497266 2026-01-18   4.0          4.0          4.0          4.0   \n",
      "509     533086 2026-01-18  50.0         50.0         50.0         50.0   \n",
      "514     556792 2026-01-18  55.0         55.0         55.0         55.0   \n",
      "519     562600 2026-01-18  50.0         50.0         50.0         50.0   \n",
      "\n",
      "     pm25_rolling_3d  pm25_nearby_avg                        city  \\\n",
      "9               28.0        45.333333                 Johannehill   \n",
      "14               7.0              NaN                      Ã„ngeby   \n",
      "19              44.0              NaN                       Slaka   \n",
      "24              37.0              NaN                    HÃ¤gernÃ¤s   \n",
      "29              16.0              NaN  SkarpnÃ¤cks stadsdelsomrÃ¥de   \n",
      "..               ...              ...                         ...   \n",
      "499              5.0              NaN                      Stavre   \n",
      "504              4.0              NaN                  SkellefteÃ¥   \n",
      "509             50.0              NaN                        Berg   \n",
      "514             55.0              NaN                  NorrkÃ¶ping   \n",
      "519             50.0              NaN                       Solna   \n",
      "\n",
      "                 street country                            aqicn_url  \\\n",
      "9                  Ubby  Sweden   https://api.waqi.info/feed/A57421/   \n",
      "14        JupitersvÃ¤gen  Sweden   https://api.waqi.info/feed/A58666/   \n",
      "19        TrÃ¶skaregatan  Sweden   https://api.waqi.info/feed/A58909/   \n",
      "24           RadarvÃ¤gen  Sweden   https://api.waqi.info/feed/A58912/   \n",
      "29   Karin Larssons vÃ¤g  Sweden   https://api.waqi.info/feed/A58921/   \n",
      "..                  ...     ...                                  ...   \n",
      "499               Z 565  Sweden  https://api.waqi.info/feed/A494275/   \n",
      "504        MobackavÃ¤gen  Sweden  https://api.waqi.info/feed/A497266/   \n",
      "509        BjÃ¶rnsbacken  Sweden  https://api.waqi.info/feed/A533086/   \n",
      "514        EnebymovÃ¤gen  Sweden  https://api.waqi.info/feed/A556792/   \n",
      "519      EnkÃ¶pingsvÃ¤gen  Sweden  https://api.waqi.info/feed/A562600/   \n",
      "\n",
      "     latitude  longitude  \n",
      "9    62.00000   15.00000  \n",
      "14   59.98333   17.73333  \n",
      "19   58.36667   15.55000  \n",
      "24   59.75000   15.43333  \n",
      "29   62.00000   15.00000  \n",
      "..        ...        ...  \n",
      "499  63.41667   14.13333  \n",
      "504  64.75067   20.95279  \n",
      "509  62.00000   15.00000  \n",
      "514  58.59419   16.18260  \n",
      "519  59.36004   18.00086  \n",
      "\n",
      "[103 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_aq[all_aq[\"date\"].dt.date == today - timedelta(days=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f6457",
   "metadata": {},
   "source": [
    "Extract todays engineered rows for insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d515eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered rows for today: 1\n"
     ]
    }
   ],
   "source": [
    "today_rows = all_aq[all_aq[\"date\"].dt.date == today].copy()\n",
    "\n",
    "# Drop rows with missing target\n",
    "today_rows = today_rows.dropna(subset=[\"pm25\"])\n",
    "\n",
    "# Optional: drop rows missing engineered features\n",
    "engineered_cols = [c for c in today_rows.columns if \"lag\" in c or \"rolling\" in c or \"nearby\" in c]\n",
    "today_rows = today_rows.dropna(subset=engineered_cols, how=\"any\")\n",
    "\n",
    "print(f\"Engineered rows for today: {len(today_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95d50926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sensor_id, meta in metadata_df.iterrows():\n",
    "#     try:\n",
    "#         # Fetch current air quality\n",
    "#         aq_today_df = fetchers.get_pm25(meta[\"aqicn_url\"], meta[\"country\"], meta[\"city\"], \n",
    "#                                        meta[\"street\"], today, AQICN_API_KEY)\n",
    "        \n",
    "#         if aq_today_df.empty or aq_today_df['pm25'].isna().all():\n",
    "#             skipped += 1\n",
    "#             continue\n",
    "        \n",
    "#         # Format air quality data\n",
    "#         aq_today_df[\"sensor_id\"] = int(sensor_id)\n",
    "#         aq_today_df[\"pm25\"] = pd.to_numeric(aq_today_df[\"pm25\"], errors=\"coerce\")\n",
    "#         aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"]).dt.tz_localize(None)\n",
    "#         aq_today_df = aq_today_df.drop(columns=[\"url\", \"country\", \"city\", \"street\"], errors=\"ignore\")\n",
    "        \n",
    "#         # Combine with historical data (last 4 days)\n",
    "#         if not historical_df.empty:\n",
    "#             sensor_historical = historical_df[\n",
    "#                 (historical_df[\"sensor_id\"] == sensor_id) & \n",
    "#                 (historical_df[\"date\"].dt.date < today)\n",
    "#             ]\n",
    "#         else:\n",
    "#             sensor_historical = pd.DataFrame()\n",
    "        \n",
    "#         combined = pd.concat([sensor_historical, aq_today_df], ignore_index=True) if not sensor_historical.empty else aq_today_df\n",
    "#         combined = combined.sort_values(\"date\").reset_index(drop=True)\n",
    "        \n",
    "#         # Add features using historical + todays data\n",
    "#         combined = feature_engineering.add_rolling_window_feature(combined, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "#         combined = feature_engineering.add_lagged_features(combined, column=\"pm25\", lags=[1, 2, 3])\n",
    "#         combined = feature_engineering.add_nearby_sensor_feature(combined, metadata_indexed, n_closest=3)\n",
    "        \n",
    "#         # Only filter out future dates if any exist\n",
    "#         combined = combined[combined[\"date\"].dt.date <= today].copy()\n",
    "        \n",
    "#         if combined.empty or combined['pm25'].isna().all():\n",
    "#             skipped += 1\n",
    "#             continue\n",
    "        \n",
    "#         aq_list.append(combined)\n",
    "\n",
    "        \n",
    "#         # Fetch weather for each sensor\n",
    "#         if sensor_id not in weather_dict:\n",
    "#             end_date = today + timedelta(days=7)\n",
    "#             weather_df = fetchers.get_weather_forecast(sensor_id, today, end_date, \n",
    "#                                                       meta[\"latitude\"], meta[\"longitude\"])\n",
    "#             if not weather_df.empty:\n",
    "#                 weather_df[\"sensor_id\"] = sensor_id\n",
    "#                 weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "#                 weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "#                 weather_dict[sensor_id] = weather_df\n",
    "        \n",
    "#         successful += 1\n",
    "#         if successful % 10 == 0:\n",
    "#             print(f\"âœ… Processed {successful}/{len(metadata_df)} sensors\")\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         failed += 1\n",
    "#         print(f\"âŒ Sensor {sensor_id}: {type(e).__name__}\")\n",
    "#         continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85a2ee",
   "metadata": {},
   "source": [
    "Batch insert Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dea3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if aq_list:\n",
    "    all_aq = pd.concat(aq_list, ignore_index=True)\n",
    "    \n",
    "    # Convert types\n",
    "    all_aq = all_aq.astype({\n",
    "        \"sensor_id\": \"int32\",\n",
    "        \"pm25\": \"float64\",\n",
    "        \"pm25_lag_1d\": \"float64\",\n",
    "        \"pm25_lag_2d\": \"float64\",\n",
    "        \"pm25_lag_3d\": \"float64\",\n",
    "        \"pm25_rolling_3d\": \"float64\",\n",
    "        \"pm25_nearby_avg\": \"float64\",\n",
    "        \"city\": \"string\",\n",
    "        \"street\": \"string\",\n",
    "        \"country\": \"string\",\n",
    "        \"aqicn_url\": \"string\",\n",
    "        \"latitude\": \"float64\",\n",
    "        \"longitude\": \"float64\",\n",
    "    })\n",
    "    \n",
    "    # Ensure correct column order\n",
    "    fg_columns = [f.name for f in air_quality_fg.features]\n",
    "    all_aq = all_aq[fg_columns]\n",
    "    \n",
    "    air_quality_fg.insert(all_aq)\n",
    "    print(f\"ğŸ“Š Inserted {len(all_aq)} air quality records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e41ac3",
   "metadata": {},
   "source": [
    "### 2.6.3. Batch Insert Weather Forecast Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a667f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "if weather_dict:\n",
    "    all_weather = pd.concat(weather_dict.values(), ignore_index=True)\n",
    "    \n",
    "    # Convert types\n",
    "    all_weather = all_weather.astype({\n",
    "        \"sensor_id\": \"int32\",\n",
    "        \"temperature_2m_mean\": \"float64\",\n",
    "        \"precipitation_sum\": \"float64\",\n",
    "        \"wind_speed_10m_max\": \"float64\",\n",
    "        \"wind_direction_10m_dominant\": \"float64\",\n",
    "    })\n",
    "    \n",
    "    # Insert in smaller batches\n",
    "    batch_size = 100\n",
    "    total_inserted = 0\n",
    "    \n",
    "    for i in range(0, len(all_weather), batch_size):\n",
    "        batch = all_weather.iloc[i:i+batch_size]\n",
    "        max_retries = 3\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                weather_fg.insert(batch)\n",
    "                total_inserted += len(batch)\n",
    "                print(f\"âœ… Weather batch {i//batch_size + 1}: {len(batch)} records (total: {total_inserted}/{len(all_weather)})\")\n",
    "                break\n",
    "            except (ProtocolError, ConnectionError, TimeoutError, KafkaException) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\"âš ï¸  Connection error on weather batch {i//batch_size + 1}, retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"âŒ Failed weather batch {i//batch_size + 1}\")\n",
    "                    failed_file = f\"{root_dir}/failed_weather_batch_{today}_{i}.csv\"\n",
    "                    batch.to_csv(failed_file, index=False)\n",
    "                    print(f\"ğŸ’¾ Saved to {failed_file}\")\n",
    "    \n",
    "    print(f\"ğŸŒ¤ï¸ Total inserted: {total_inserted}/{len(all_weather)} weather records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845de6",
   "metadata": {},
   "source": [
    "### 2.6.4. Print Processing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74278aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Summary: âœ… 0 successful, â­ï¸ 0 skipped, âŒ 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nğŸ“Š Summary: âœ… {successful} successful, â­ï¸ {skipped} skipped, âŒ {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c9844",
   "metadata": {},
   "source": [
    "## 2.7. Inspect Inserted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1986667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Air quality records inserted: 521\n",
      "\n",
      "ğŸ“‹ Sample air quality data:\n",
      "   sensor_id       date  pm25  pm25_lag_1d  pm25_lag_2d  pm25_lag_3d  \\\n",
      "0      57421 2026-01-12   4.0          NaN          NaN          NaN   \n",
      "1      57421 2026-01-12   4.0          4.0          NaN          NaN   \n",
      "2      57421 2026-01-13   4.0          4.0          4.0          NaN   \n",
      "3      57421 2026-01-13   4.0          4.0          4.0          4.0   \n",
      "4      57421 2026-01-14   4.0          4.0          4.0          4.0   \n",
      "\n",
      "   pm25_rolling_3d  pm25_nearby_avg         city street country  \\\n",
      "0              NaN              NaN  Johannehill   Ubby  Sweden   \n",
      "1              4.0              NaN  Johannehill   Ubby  Sweden   \n",
      "2              4.0              NaN  Johannehill   Ubby  Sweden   \n",
      "3              4.0              NaN  Johannehill   Ubby  Sweden   \n",
      "4              4.0              NaN  Johannehill   Ubby  Sweden   \n",
      "\n",
      "                            aqicn_url  latitude  longitude  \n",
      "0  https://api.waqi.info/feed/A57421/      62.0       15.0  \n",
      "1  https://api.waqi.info/feed/A57421/      62.0       15.0  \n",
      "2  https://api.waqi.info/feed/A57421/      62.0       15.0  \n",
      "3  https://api.waqi.info/feed/A57421/      62.0       15.0  \n",
      "4  https://api.waqi.info/feed/A57421/      62.0       15.0  \n",
      "\n",
      "ğŸ”§ Air quality data types:\n",
      "sensor_id                   int32\n",
      "date               datetime64[us]\n",
      "pm25                      float64\n",
      "pm25_lag_1d               float64\n",
      "pm25_lag_2d               float64\n",
      "pm25_lag_3d               float64\n",
      "pm25_rolling_3d           float64\n",
      "pm25_nearby_avg           float64\n",
      "city                       object\n",
      "street                     object\n",
      "country                    object\n",
      "aqicn_url                  object\n",
      "latitude                  float64\n",
      "longitude                 float64\n",
      "dtype: object\n",
      "\n",
      "ğŸ“… Date range:\n",
      "From 2026-01-12 00:00:00 to 2026-01-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "if 'all_aq' in locals() and not all_aq.empty:\n",
    "    print(f\"âœ… Air quality records inserted: {len(all_aq)}\")\n",
    "    print(\"\\nğŸ“‹ Sample air quality data:\")\n",
    "    print(all_aq.head())\n",
    "    print(\"\\nğŸ”§ Air quality data types:\")\n",
    "    print(all_aq.dtypes)\n",
    "    print(\"\\nğŸ“… Date range:\")\n",
    "    print(f\"From {all_aq['date'].min()} to {all_aq['date'].max()}\")\n",
    "\n",
    "if 'all_weather' in locals() and not all_weather.empty:\n",
    "    print(f\"\\nğŸŒ¤ï¸ Weather records inserted: {len(all_weather)}\")\n",
    "    print(\"\\nğŸ“‹ Sample weather data:\")\n",
    "    print(all_weather.head())\n",
    "    print(\"\\nğŸ”§ Weather data types:\")\n",
    "    print(all_weather.dtypes)\n",
    "    print(\"\\nğŸ“… Unique weather dates:\")\n",
    "    print(all_weather['date'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
