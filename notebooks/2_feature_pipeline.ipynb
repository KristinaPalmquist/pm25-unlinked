{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Environment Setup\n",
    "Detect if running in Google Colab or local environment, handle repository cloning, dependency installation, numpy compatibility fixes, and set up Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed990082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# if os.path.exists('/content/pm25-forecast-openmeteo-aqicn'):\n",
    "#     shutil.rmtree('/content/pm25-forecast-openmeteo-aqicn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    try:\n",
    "        if \"google.colab\" in str(get_ipython()):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    # Check if repository already exists\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "def fix_numpy_compatibility():\n",
    "    print(\"Fixing numpy compatibility for hopsworks/pandas...\")\n",
    "    try:\n",
    "        # Use compatible versions that work with the installed packages\n",
    "        !pip install --force-reinstall numpy==1.26.4 pandas==2.0.3\n",
    "        print(\"Numpy and pandas fixed. Please restart runtime and run again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fix attempt failed: {e}\")\n",
    "        print(\"Please manually restart runtime and try again.\")\n",
    "\n",
    "if is_google_colab():\n",
    "    try:\n",
    "        import numpy\n",
    "        numpy.array([1, 2, 3])\n",
    "        import pandas as pd\n",
    "        print(\"Basic packages working correctly\")\n",
    "\n",
    "        clone_repository()\n",
    "        install_dependencies()\n",
    "\n",
    "        import hopsworks\n",
    "        print(\"All packages working correctly\")\n",
    "\n",
    "        root_dir = str(Path().absolute())\n",
    "        print(\"Google Colab environment\")\n",
    "        \n",
    "    except (ValueError, ImportError) as e:\n",
    "        if \"numpy.dtype size changed\" in str(e) or \"numpy.strings\" in str(e) or \"numpy\" in str(e).lower():\n",
    "            fix_numpy_compatibility()\n",
    "            raise SystemExit(\"Please restart runtime (Runtime > Restart runtime) and run the notebook again.\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    if root_dir.parts[-1:] == (\"src\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"airquality\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == (\"notebooks\",):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir)\n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "if is_google_colab():\n",
    "    from google.colab import userdata\n",
    "    import hopsworks\n",
    "    project = hopsworks.login(\n",
    "        api_key_value=userdata.get('HOPSWORKS_API_KEY'),\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    AQICN_API_KEY = userdata.get('AQICN_API_KEY')\n",
    "    \n",
    "else:\n",
    "    # Local development - use .env file\n",
    "    from utils import config\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5952fc",
   "metadata": {},
   "source": [
    "## 2.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import json\n",
    "import warnings\n",
    "import requests\n",
    "from utils import airquality\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd2dd2",
   "metadata": {},
   "source": [
    "## 2.3. Setup\n",
    "Hopsworks and feature store setup - configure Hopsworks connection, retrieve API keys, and connect to existing air quality and weather feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "010e645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-08 11:01:49,256 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-12-08 11:01:49,262 INFO: Initializing external client\n",
      "2025-12-08 11:01:49,264 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "Connection closed.\n",
      "2025-12-08 11:01:49,262 INFO: Initializing external client\n",
      "2025-12-08 11:01:49,264 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-08 11:01:50,783 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "if is_google_colab():\n",
    "    fs = project.get_feature_store()\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "else:\n",
    "    HOPSWORKS_API_KEY = getattr(settings, 'HOPSWORKS_API_KEY', None)\n",
    "\n",
    "    if HOPSWORKS_API_KEY is not None and hasattr(HOPSWORKS_API_KEY, 'get_secret_value'):\n",
    "        HOPSWORKS_API_KEY = HOPSWORKS_API_KEY.get_secret_value()\n",
    "\n",
    "    project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=\"weather_all\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Sensor Mode\n",
    "Set SENSOR_CSV_FILE in .env with the relative path to a sensor to process it, or leave it unset to process all sensors in the `data` folder.\n",
    "\n",
    "Retrieve sensor location data from Hopsworks secret, parse JSON location metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_google_colab():\n",
    "    sensor_csv_file = None\n",
    "else:\n",
    "    sensor_csv_file = getattr(settings, 'SENSOR_CSV_FILE', None)\n",
    "\n",
    "if sensor_csv_file:\n",
    "    # Read one secret for single sensor mode\n",
    "    _, _, _, _, _, sensor_id = airquality.read_sensor_data(sensor_csv_file)\n",
    "    secret_name = f\"SENSOR_LOCATION_JSON_{sensor_id}\"\n",
    "    location_str = secrets.get_secret(secret_name).value\n",
    "    locations = {sensor_id: json.loads(location_str)}\n",
    "else:\n",
    "    # Read all individual secrets in batch mode\n",
    "    all_secrets = secrets.get_secrets()\n",
    "    locations = {}\n",
    "    for secret in all_secrets:\n",
    "        if secret.name.startswith(\"SENSOR_LOCATION_JSON_\"):\n",
    "            sensor_id = secret.name.replace(\"SENSOR_LOCATION_JSON_\", \"\")\n",
    "            location_str = secrets.get_secret(secret.name).value\n",
    "            if location_str:\n",
    "                locations[sensor_id] = json.loads(location_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb50d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixed 105 sensor URLs from @ to A format\n"
     ]
    }
   ],
   "source": [
    "# Convert @ URLs to A URLs for Swedish sensors (AQICN API change)\n",
    "fixed_count = 0\n",
    "for sensor_id, location in locations.items():\n",
    "    if \"@\" in location[\"aqicn_url\"]:\n",
    "        old_url = location[\"aqicn_url\"]\n",
    "        new_url = old_url.replace(\"/@\", \"/A\")\n",
    "        location[\"aqicn_url\"] = new_url\n",
    "        fixed_count += 1\n",
    "\n",
    "if fixed_count > 0:\n",
    "    print(f\"üîß Fixed {fixed_count} sensor URLs from @ to A format\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è All sensor URLs already in correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa567b0",
   "metadata": {},
   "source": [
    "## 2.5. Helper Methods\n",
    "Data processing functions - get daily weather forecasts and fetch current data, air quality and weather, for each sensor location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137cb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_weather_forecast(city, latitude, longitude):\n",
    "    hourly_df = airquality.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index(\"date\")\n",
    "    daily_df = hourly_df.between_time(\"11:59\", \"12:01\")\n",
    "    daily_df = daily_df.reset_index()\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"]).dt.date\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n",
    "    daily_df[\"city\"] = city\n",
    "    return daily_df\n",
    "\n",
    "\n",
    "def fetch_data_for_location(location):\n",
    "    country = location[\"country\"]\n",
    "    city = location[\"city\"]\n",
    "    street = location[\"street\"]\n",
    "    aqicn_url = location[\"aqicn_url\"]\n",
    "    latitude = location[\"latitude\"]\n",
    "    longitude = location[\"longitude\"]\n",
    "\n",
    "    aq_today_df = airquality.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    daily_df = get_daily_weather_forecast(city, latitude, longitude)\n",
    "    return aq_today_df, daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.6. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e4e975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 105 sensor locations...\n",
      "Error: There may be an incorrect URL for your Sensor or it is not contactable right now. The API response does not contain data.  Error message: no such station\n",
      "‚ö†Ô∏è  Skipping sensor 362923: no such station\n",
      "Error: There may be an incorrect URL for your Sensor or it is not contactable right now. The API response does not contain data.  Error message: no such station\n",
      "‚ö†Ô∏è  Skipping sensor 362923: no such station\n"
     ]
    }
   ],
   "source": [
    "aqs = []\n",
    "weathers = []\n",
    "print(f\"üîç Processing {len(locations)} sensor locations...\")\n",
    "\n",
    "for sensor, location in locations.items():\n",
    "    try:\n",
    "        aq_today_df, weather_daily_forecast_df = fetch_data_for_location(location)\n",
    "\n",
    "        aq_today_df = aq_today_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            street=location[\"street\"],\n",
    "            city=location[\"city\"],\n",
    "            country=location[\"country\"],\n",
    "            feed_url=location[\"aqicn_url\"],\n",
    "        )\n",
    "        aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"])\n",
    "\n",
    "        # Weather FG shape\n",
    "        weather_daily_forecast_df = weather_daily_forecast_df.assign(\n",
    "            sensor_id=str(sensor),\n",
    "            city=location[\"city\"],\n",
    "            latitude=location[\"latitude\"],\n",
    "            longitude=location[\"longitude\"],\n",
    "        )\n",
    "        weather_daily_forecast_df[\"date\"] = pd.to_datetime(\n",
    "            weather_daily_forecast_df[\"date\"]\n",
    "        )\n",
    "\n",
    "        aqs.append(aq_today_df)\n",
    "        weathers.append(weather_daily_forecast_df)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ö†Ô∏è  Skipping sensor {sensor}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Unexpected error with sensor {sensor}: {type(e).__name__}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5e08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.83s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.83s) \n"
     ]
    }
   ],
   "source": [
    "aq_df = pd.concat(aqs) if aqs else pd.DataFrame()\n",
    "if not aq_df.empty:\n",
    "    aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "    aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "    aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "    # Data quality check 1: Remove rows with missing PM2.5 values\n",
    "    initial_count = len(aq_df)\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    if len(aq_df) < initial_count:\n",
    "        print(f\"üßπ Removed {initial_count - len(aq_df)} rows with missing PM2.5 values\")\n",
    "\n",
    "# Get historical data for rolling window and lagged features\n",
    "historical_start = today - datetime.timedelta(days=4)\n",
    "historical_df = pd.DataFrame()\n",
    "\n",
    "# Read historical data from feature group and filter for the last 4 days\n",
    "try:\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"].dt.date >= historical_start) & (historical_df[\"date\"].dt.date < today)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca48edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final data quality: 104 clean rows ready for feature store\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>feed_url</th>\n",
       "      <th>pm25_rolling_3d</th>\n",
       "      <th>pm25_lag_1d</th>\n",
       "      <th>pm25_lag_2d</th>\n",
       "      <th>pm25_lag_3d</th>\n",
       "      <th>pm25_nearby_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>105325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>√ñrnsk√∂ldsvik</td>\n",
       "      <td>H√∂rnettv√§gen</td>\n",
       "      <td>https://api.waqi.info/feed/A105325/</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>107110</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Uppsala</td>\n",
       "      <td>Kuggebro</td>\n",
       "      <td>https://api.waqi.info/feed/A107110/</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>112672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>B√•gskyttegatan</td>\n",
       "      <td>https://api.waqi.info/feed/A112672/</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>112993</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>S√∂derby</td>\n",
       "      <td>Eker√∂v√§gen</td>\n",
       "      <td>https://api.waqi.info/feed/A112993/</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>113539</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>St√§ket</td>\n",
       "      <td>Aron Lindgrens v√§g</td>\n",
       "      <td>https://api.waqi.info/feed/A113539/</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>88372</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gothenburg</td>\n",
       "      <td>Ridl√§rargatan</td>\n",
       "      <td>https://api.waqi.info/feed/A88372/</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>88876</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>L√∂tk√§rr</td>\n",
       "      <td>Myggv√§gen</td>\n",
       "      <td>https://api.waqi.info/feed/A88876/</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>89584</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>T√§by kommun</td>\n",
       "      <td>Vallatorpsv√§gen</td>\n",
       "      <td>https://api.waqi.info/feed/A89584/</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>90676</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Upph√§rad</td>\n",
       "      <td>Upph√§rad</td>\n",
       "      <td>https://api.waqi.info/feed/A90676/</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>92683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>√∂bben</td>\n",
       "      <td>https://api.waqi.info/feed/A92683/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date sensor_id  pm25 country          city              street  \\\n",
       "265 2025-12-08    105325   4.0  Sweden  √ñrnsk√∂ldsvik        H√∂rnettv√§gen   \n",
       "280 2025-12-08    107110  34.0  Sweden       Uppsala            Kuggebro   \n",
       "229 2025-12-08    112672  32.0  Sweden    Gothenburg      B√•gskyttegatan   \n",
       "230 2025-12-08    112993  22.0  Sweden       S√∂derby          Eker√∂v√§gen   \n",
       "281 2025-12-08    113539  24.0  Sweden        St√§ket  Aron Lindgrens v√§g   \n",
       "..         ...       ...   ...     ...           ...                 ...   \n",
       "278 2025-12-08     88372  24.0  Sweden    Gothenburg       Ridl√§rargatan   \n",
       "227 2025-12-08     88876  47.0  Sweden       L√∂tk√§rr           Myggv√§gen   \n",
       "279 2025-12-08     89584  40.0  Sweden   T√§by kommun     Vallatorpsv√§gen   \n",
       "228 2025-12-08     90676  15.0  Sweden      Upph√§rad            Upph√§rad   \n",
       "312 2025-12-08     92683   0.0  Sweden         Hen√•n               √∂bben   \n",
       "\n",
       "                                feed_url  pm25_rolling_3d  pm25_lag_1d  \\\n",
       "265  https://api.waqi.info/feed/A105325/             54.0         54.0   \n",
       "280  https://api.waqi.info/feed/A107110/             57.0         57.0   \n",
       "229  https://api.waqi.info/feed/A112672/             39.0         39.0   \n",
       "230  https://api.waqi.info/feed/A112993/             37.0         37.0   \n",
       "281  https://api.waqi.info/feed/A113539/             15.0         15.0   \n",
       "..                                   ...              ...          ...   \n",
       "278   https://api.waqi.info/feed/A88372/             26.0         26.0   \n",
       "227   https://api.waqi.info/feed/A88876/             13.0         13.0   \n",
       "279   https://api.waqi.info/feed/A89584/             22.0         22.0   \n",
       "228   https://api.waqi.info/feed/A90676/             26.0         26.0   \n",
       "312   https://api.waqi.info/feed/A92683/              0.0          0.0   \n",
       "\n",
       "     pm25_lag_2d  pm25_lag_3d  pm25_nearby_avg  \n",
       "265         9.00          NaN         8.666667  \n",
       "280         6.60          NaN        23.666667  \n",
       "229        29.00          NaN        20.666667  \n",
       "230         1.90          NaN        13.000000  \n",
       "281         2.97          NaN        14.000000  \n",
       "..           ...          ...              ...  \n",
       "278        17.00          NaN        25.000000  \n",
       "227        31.00          NaN         9.000000  \n",
       "279         3.15          NaN        38.000000  \n",
       "228         5.17          NaN         3.333333  \n",
       "312         0.00          NaN        20.000000  \n",
       "\n",
       "[104 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([historical_df, aq_df], ignore_index=True) if not historical_df.empty else aq_df\n",
    "if not combined_df.empty:\n",
    "    combined_df = airquality.add_rolling_window_feature(combined_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "    combined_df = airquality.add_lagged_features(combined_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    combined_df = airquality.add_nearby_sensor_feature(combined_df, locations, column=\"pm25_lag_1d\", n_closest=3)\n",
    "    \n",
    "    # Data quality check 2: Clean up NaNs created by feature engineering\n",
    "    before_cleaning = len(combined_df[combined_df[\"date\"].dt.date == today])\n",
    "    \n",
    "    # Only keep today's data and remove rows where essential features are NaN\n",
    "    aq_df = combined_df[combined_df[\"date\"].dt.date == today].copy()\n",
    "    \n",
    "    # Remove rows where pm25 is still NaN after all processing\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    \n",
    "    after_cleaning = len(aq_df)\n",
    "    if before_cleaning > after_cleaning:\n",
    "        print(f\"üßπ Removed {before_cleaning - after_cleaning} rows with NaN values after feature engineering\")\n",
    "    \n",
    "    print(f\"üìä Final data quality: {len(aq_df)} clean rows ready for feature store\")\n",
    "else:\n",
    "    aq_df = pd.DataFrame()\n",
    "    print(\"‚ö†Ô∏è  No data available for processing\")\n",
    "aq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebaf2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå§Ô∏è  Weather data quality: 728 clean weather rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>5.776000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16.199999</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>Acksj√∂n</td>\n",
       "      <td>121810</td>\n",
       "      <td>59.648101</td>\n",
       "      <td>13.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-09</td>\n",
       "      <td>2.576000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.040000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>Acksj√∂n</td>\n",
       "      <td>121810</td>\n",
       "      <td>59.648101</td>\n",
       "      <td>13.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-10</td>\n",
       "      <td>8.026000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.799999</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>Acksj√∂n</td>\n",
       "      <td>121810</td>\n",
       "      <td>59.648101</td>\n",
       "      <td>13.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>8.068500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.627172</td>\n",
       "      <td>264.454773</td>\n",
       "      <td>Acksj√∂n</td>\n",
       "      <td>121810</td>\n",
       "      <td>59.648101</td>\n",
       "      <td>13.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>5.518500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.849528</td>\n",
       "      <td>191.309891</td>\n",
       "      <td>Acksj√∂n</td>\n",
       "      <td>121810</td>\n",
       "      <td>59.648101</td>\n",
       "      <td>13.752426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-10</td>\n",
       "      <td>9.446000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.680000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>92683</td>\n",
       "      <td>58.272055</td>\n",
       "      <td>11.688522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>9.821500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.183659</td>\n",
       "      <td>251.564957</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>92683</td>\n",
       "      <td>58.272055</td>\n",
       "      <td>11.688522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>8.021500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.020235</td>\n",
       "      <td>197.860184</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>92683</td>\n",
       "      <td>58.272055</td>\n",
       "      <td>11.688522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-13</td>\n",
       "      <td>7.821500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.224979</td>\n",
       "      <td>213.690094</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>92683</td>\n",
       "      <td>58.272055</td>\n",
       "      <td>11.688522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-14</td>\n",
       "      <td>8.721499</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27.041965</td>\n",
       "      <td>210.832870</td>\n",
       "      <td>Hen√•n</td>\n",
       "      <td>92683</td>\n",
       "      <td>58.272055</td>\n",
       "      <td>11.688522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0  2025-12-08             5.776000                0.8           16.199999   \n",
       "1  2025-12-09             2.576000                0.0            5.040000   \n",
       "2  2025-12-10             8.026000                0.0           10.799999   \n",
       "3  2025-12-11             8.068500                0.0           18.627172   \n",
       "4  2025-12-12             5.518500                0.0           12.849528   \n",
       "..        ...                  ...                ...                 ...   \n",
       "2  2025-12-10             9.446000                0.0           22.680000   \n",
       "3  2025-12-11             9.821500                0.0           26.183659   \n",
       "4  2025-12-12             8.021500                0.0           17.020235   \n",
       "5  2025-12-13             7.821500                0.0           16.224979   \n",
       "6  2025-12-14             8.721499                0.8           27.041965   \n",
       "\n",
       "    wind_direction_10m_dominant     city sensor_id   latitude  longitude  \n",
       "0                    110.000000  Acksj√∂n    121810  59.648101  13.752426  \n",
       "1                    273.000000  Acksj√∂n    121810  59.648101  13.752426  \n",
       "2                    229.000000  Acksj√∂n    121810  59.648101  13.752426  \n",
       "3                    264.454773  Acksj√∂n    121810  59.648101  13.752426  \n",
       "4                    191.309891  Acksj√∂n    121810  59.648101  13.752426  \n",
       "..                          ...      ...       ...        ...        ...  \n",
       "2                    232.000000    Hen√•n     92683  58.272055  11.688522  \n",
       "3                    251.564957    Hen√•n     92683  58.272055  11.688522  \n",
       "4                    197.860184    Hen√•n     92683  58.272055  11.688522  \n",
       "5                    213.690094    Hen√•n     92683  58.272055  11.688522  \n",
       "6                    210.832870    Hen√•n     92683  58.272055  11.688522  \n",
       "\n",
       "[728 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.concat(weathers) if weathers else pd.DataFrame()\n",
    "if not weather_df.empty:\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    \n",
    "    # Data quality check 3: Remove rows with missing weather data\n",
    "    initial_weather_count = len(weather_df)\n",
    "    weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "    \n",
    "    # Convert to float32 to match Hopsworks feature group schema\n",
    "    weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float32\")\n",
    "    weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float32\")\n",
    "    weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float32\")\n",
    "    weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float32\")\n",
    "    \n",
    "    if len(weather_df) < initial_weather_count:\n",
    "        print(f\"üßπ Removed {initial_weather_count - len(weather_df)} rows with missing weather data\")\n",
    "    \n",
    "    print(f\"üå§Ô∏è  Weather data quality: {len(weather_df)} clean weather rows\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No weather data available\")\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22a610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserting 104 air quality rows and 728 weather rows to feature store\n",
      "2025-12-08 11:04:43,608 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "2025-12-08 11:04:43,608 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1774972\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1774972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 104/104 | Elapsed Time: 00:01 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_all_1_offline_fg_materialization/executions\n",
      "2025-12-08 11:04:57,677 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_all_1_offline_fg_materialization/executions\n",
      "2025-12-08 11:04:57,677 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1783130\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1783130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 728/728 | Elapsed Time: 00:01 | Remaining Time: 00:00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/weather_all_1_offline_fg_materialization/executions\n",
      "üìÅ Data successfully inserted to feature store\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/weather_all_1_offline_fg_materialization/executions\n",
      "üìÅ Data successfully inserted to feature store\n"
     ]
    }
   ],
   "source": [
    "# Final validation before inserting to feature store\n",
    "if not aq_df.empty and not weather_df.empty:\n",
    "    print(f\"‚úÖ Inserting {len(aq_df)} air quality rows and {len(weather_df)} weather rows to feature store\")\n",
    "    air_quality_fg.insert(aq_df)\n",
    "    weather_fg.insert(weather_df)\n",
    "    print(\"üìÅ Data successfully inserted to feature store\")\n",
    "else:\n",
    "    if aq_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean air quality data to insert\")\n",
    "    if weather_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean weather data to insert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
