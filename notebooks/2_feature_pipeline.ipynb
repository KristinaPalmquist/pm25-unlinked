{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc803b",
   "metadata": {},
   "source": [
    "# 2. Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f00db",
   "metadata": {},
   "source": [
    "## 2.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335ace5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n",
      "2026-01-09 10:58:27,827 INFO: Initializing external client\n",
      "2026-01-09 10:58:27,827 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-09 10:58:28,667 WARNING: UserWarning: The installed hopsworks client version 4.1.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-09 10:58:29,746 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "#  Establish project root directory\n",
    "def find_project_root(start: Path):\n",
    "    for parent in [start] + list(start.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return start\n",
    "\n",
    "root_dir = find_project_root(Path().absolute())\n",
    "print(\"Project root dir:\", root_dir)\n",
    "\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "import hopsworks\n",
    "\n",
    "#  Project imports\n",
    "from utils import cleaning, config, feature_engineering, fetchers, hopsworks_admin, incremental, metadata\n",
    "\n",
    "#  Load settings \n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "GITHUB_USERNAME = settings.GH_USERNAME.get_secret_value()\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e733e1",
   "metadata": {},
   "source": [
    "Repository management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7280cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already in repo at c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n"
     ]
    }
   ],
   "source": [
    "repo_dir = hopsworks_admin.clone_or_update_repo(GITHUB_USERNAME)\n",
    "os.chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010e645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date.today()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"AQICN_API_KEY missing.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33477f76",
   "metadata": {},
   "source": [
    "## 2.3. Get Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2713f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg, sensor_metadata_fg, weather_fg = hopsworks_admin.create_feature_groups(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e656",
   "metadata": {},
   "source": [
    "## 2.4. Sensor Location Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0bfe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.57s) \n",
      "üìç Loaded metadata for 103 sensors\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from feature group\n",
    "metadata_df = sensor_metadata_fg.read()\n",
    "if len(metadata_df) == 0:\n",
    "    print(\"‚ö†Ô∏è No sensor metadata found. Run pipeline 1 (backfill) first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"üìç Loaded metadata for {len(metadata_df)} sensors\")\n",
    "metadata_df = metadata_df.set_index(\"sensor_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb50d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert @ URLs to A URLs for Swedish sensors (AQICN API change)\n",
    "# fixed_count = 0\n",
    "# for sensor_id, location in locations.items():\n",
    "#     if \"@\" in location[\"aqicn_url\"]:\n",
    "#         old_url = location[\"aqicn_url\"]\n",
    "#         new_url = old_url.replace(\"/@\", \"/A\")\n",
    "#         location[\"aqicn_url\"] = new_url\n",
    "#         fixed_count += 1\n",
    "\n",
    "# if fixed_count > 0:\n",
    "#     print(f\"üîß Fixed {fixed_count} sensor URLs from @ to A format\")\n",
    "# else:\n",
    "#     print(\"‚ÑπÔ∏è All sensor URLs already in correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeca83",
   "metadata": {},
   "source": [
    "## 2.5. Data Collection\n",
    "Loop through all sensors to fetch today's air quality data and weather forecasts, format data to match feature group schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 103 sensor locations...\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (24.61s) \n",
      "2026-01-09 11:24:35,161 INFO: \t7 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1911228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization/executions\n",
      "‚ùå Sensor 191047: Unexpected error - FeatureStoreException: Features are not compatible with Feature Group schema: \n",
      " - temperature_2m_mean (expected type: 'doub\n",
      "   Traceback (most recent call last):\n",
      "  File \"C:\\Users\\krist\\AppData\\Local\\Temp\\ipykernel_20376\\1599027981.py\", line 114, in <module>\n",
      "    weather_fg.insert(weather_df)\n",
      "  File \"c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py\", line 2940, in ins\n",
      "2026-01-09 11:25:22,242 INFO: \t7 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1911228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-09 11:25:31,160 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1767871095641) to trigger the materialization job again.\n",
      "\n",
      "‚ùå Sensor 59410: Unexpected error - FeatureStoreException: Features are not compatible with Feature Group schema: \n",
      " - temperature_2m_mean (expected type: 'doub\n",
      "   Traceback (most recent call last):\n",
      "  File \"C:\\Users\\krist\\AppData\\Local\\Temp\\ipykernel_20376\\1599027981.py\", line 114, in <module>\n",
      "    weather_fg.insert(weather_df)\n",
      "  File \"c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py\", line 2940, in ins\n",
      "2026-01-09 11:25:33,563 INFO: \t7 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1911228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-09 11:25:42,732 WARNING: UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/kristina_titanic/Resources/jobs/air_quality_1_offline_fg_materialization/config_1767871095641) to trigger the materialization job again.\n",
      "\n",
      "‚ùå Sensor 113542: Unexpected error - FeatureStoreException: Features are not compatible with Feature Group schema: \n",
      " - temperature_2m_mean (expected type: 'doub\n",
      "   Traceback (most recent call last):\n",
      "  File \"C:\\Users\\krist\\AppData\\Local\\Temp\\ipykernel_20376\\1599027981.py\", line 114, in <module>\n",
      "    weather_fg.insert(weather_df)\n",
      "  File \"c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py\", line 2940, in ins\n",
      "2026-01-09 11:25:45,072 INFO: \t7 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1911228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m aq_final = aq_final[fg_columns]\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Insert air quality data immediately\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mair_quality_fg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43maq_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Fetch and upload weather for this location (if not already done)\u001b[39;00m\n\u001b[32m     96\u001b[39m location_id = \u001b[38;5;28mint\u001b[39m(meta[\u001b[33m\"\u001b[39m\u001b[33mlocation_id\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py:2940\u001b[39m, in \u001b[36mFeatureGroup.insert\u001b[39m\u001b[34m(self, features, overwrite, operation, storage, write_options, validation_options, wait)\u001b[39m\n\u001b[32m   2937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2938\u001b[39m     write_options[\u001b[33m\"\u001b[39m\u001b[33moffline_backfill_every_hr\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr\n\u001b[32m-> \u001b[39m\u001b[32m2940\u001b[39m job, ge_report = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2941\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2943\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2944\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2946\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2948\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine.get_type().startswith(\u001b[33m\"\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m   2951\u001b[39m     \u001b[38;5;66;03m# Also, only compute statistics if stream is False.\u001b[39;00m\n\u001b[32m   2952\u001b[39m     \u001b[38;5;66;03m# if True, the backfill job has not been triggered and the data has not been inserted (it's in Kafka)\u001b[39;00m\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28mself\u001b[39m.compute_statistics()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\core\\feature_group_engine.py:212\u001b[39m, in \u001b[36mFeatureGroupEngine.insert\u001b[39m\u001b[34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m._feature_group_api.delete_content(feature_group)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbulk_insert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43monline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    221\u001b[39m     ge_report,\n\u001b[32m    222\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\engine\\python.py:815\u001b[39m, in \u001b[36mEngine.save_dataframe\u001b[39m\u001b[34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_dataframe\u001b[39m(\n\u001b[32m    801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    802\u001b[39m     feature_group: FeatureGroup,\n\u001b[32m   (...)\u001b[39m\u001b[32m    809\u001b[39m     validation_id: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    810\u001b[39m ) -> Optional[job.Job]:\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    812\u001b[39m         \u001b[38;5;28mhasattr\u001b[39m(feature_group, \u001b[33m\"\u001b[39m\u001b[33mEXTERNAL_FEATURE_GROUP\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    813\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m feature_group.online_enabled\n\u001b[32m    814\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m feature_group.stream:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_dataframe_kafka\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffline_write_options\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    819\u001b[39m         \u001b[38;5;66;03m# for backwards compatibility\u001b[39;00m\n\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.legacy_save_dataframe(\n\u001b[32m    821\u001b[39m             feature_group,\n\u001b[32m    822\u001b[39m             dataframe,\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m             validation_id,\n\u001b[32m    829\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\engine\\python.py:1496\u001b[39m, in \u001b[36mEngine._write_dataframe_kafka\u001b[39m\u001b[34m(self, feature_group, dataframe, offline_write_options)\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;66;03m# make sure producer blocks and everything is delivered\u001b[39;00m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group._multi_part_insert:\n\u001b[32m-> \u001b[39m\u001b[32m1496\u001b[39m     \u001b[43mproducer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1497\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m producer\n\u001b[32m   1498\u001b[39m     progress_bar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\core\\kafka_engine.py:261\u001b[39m, in \u001b[36mbuild_ack_callback_and_optional_progress_bar.<locals>.acked\u001b[39m\u001b[34m(err, msg)\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    259\u001b[39m     progress_bar = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macked\u001b[39m(err: \u001b[38;5;167;01mException\u001b[39;00m, msg: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    263\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m offline_write_options.get(\u001b[33m\"\u001b[39m\u001b[33mdebug_kafka\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load metadata from feature group for nearby sensor calculations\n",
    "metadata_indexed = metadata_df.copy()\n",
    "# Ensure index is int type to match sensor_id values in data\n",
    "metadata_indexed.index = metadata_indexed.index.astype(int)\n",
    "\n",
    "successful_sensors = 0\n",
    "failed_sensors = 0\n",
    "skipped_sensors = 0\n",
    "location_weather_uploaded = set()  # Track which location weather we've already uploaded\n",
    "\n",
    "print(f\"üîç Processing {len(metadata_df)} sensor locations...\")\n",
    "\n",
    "# Get historical data once for all sensors (for rolling/lag features)\n",
    "historical_start = today - timedelta(days=4)\n",
    "try:\n",
    "    # Read all data (Python env doesn't support column selection)\n",
    "    historical_df = air_quality_fg.read()\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        # Convert today to datetime for comparison\n",
    "        today_dt = pd.to_datetime(today)\n",
    "        historical_start_dt = pd.to_datetime(historical_start)\n",
    "        # Filter in pandas instead\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"] >= historical_start_dt) & (historical_df[\"date\"] < today_dt)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "        # IMPORTANT: Only keep historical data for sensors that exist in metadata\n",
    "        existing_sensor_ids = metadata_indexed.index.tolist()\n",
    "        historical_df = historical_df[historical_df[\"sensor_id\"].isin(existing_sensor_ids)]\n",
    "    else:\n",
    "        historical_df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error reading historical data: {e}\")\n",
    "    historical_df = pd.DataFrame()\n",
    "\n",
    "for sensor_id, meta in metadata_df.iterrows():\n",
    "    max_retries = 3\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Fetch current air quality\n",
    "            aq_today_df = fetchers.get_pm25(meta[\"aqicn_url\"], meta[\"country\"], meta[\"city\"], \n",
    "                                           meta[\"street\"], today, AQICN_API_KEY)\n",
    "            \n",
    "            # Check if we got data\n",
    "            if aq_today_df.empty or aq_today_df['pm25'].isna().all():\n",
    "                print(f\"‚è≠Ô∏è Sensor {sensor_id}: No AQ data available\")\n",
    "                skipped_sensors += 1\n",
    "                break\n",
    "            \n",
    "            # Format air quality data\n",
    "            aq_today_df = aq_today_df.assign(\n",
    "                sensor_id=int(sensor_id),\n",
    "                location_id=int(meta[\"location_id\"])\n",
    "            )\n",
    "            aq_today_df[\"pm25\"] = pd.to_numeric(aq_today_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "            aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"]).dt.tz_localize(None)\n",
    "            aq_today_df = aq_today_df.drop(columns=[\"url\", \"country\", \"city\", \"street\"], errors=\"ignore\")\n",
    "            \n",
    "            # Combine with historical data for this sensor\n",
    "            sensor_historical = historical_df[historical_df[\"sensor_id\"] == sensor_id] if not historical_df.empty else pd.DataFrame()\n",
    "            combined = pd.concat([sensor_historical, aq_today_df], ignore_index=True) if not sensor_historical.empty else aq_today_df\n",
    "            \n",
    "            # Sort by date for proper lag/rolling calculations\n",
    "            combined = combined.sort_values(\"date\").reset_index(drop=True)\n",
    "            \n",
    "            # Add features\n",
    "            combined = feature_engineering.add_rolling_window_feature(combined, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "            combined = feature_engineering.add_lagged_features(combined, column=\"pm25\", lags=[1, 2, 3])\n",
    "            \n",
    "            # Add nearby sensor feature - only for this sensor's data\n",
    "            combined = feature_engineering.add_nearby_sensor_feature(combined, metadata_indexed, n_closest=3)\n",
    "            \n",
    "            # Keep only today's data\n",
    "            today_dt = pd.to_datetime(today)\n",
    "            aq_final = combined[combined[\"date\"].dt.date == today].copy()\n",
    "            aq_final = aq_final.dropna(subset=['pm25'])\n",
    "            \n",
    "            if aq_final.empty:\n",
    "                print(f\"‚è≠Ô∏è Sensor {sensor_id}: No valid data after processing\")\n",
    "                skipped_sensors += 1\n",
    "                break\n",
    "            \n",
    "            # Ensure correct data types and column order\n",
    "            aq_final[\"sensor_id\"] = aq_final[\"sensor_id\"].astype(\"int32\")\n",
    "            aq_final[\"location_id\"] = aq_final[\"location_id\"].astype(\"int32\")\n",
    "            \n",
    "            # Get expected columns from feature group\n",
    "            fg_columns = [f.name for f in air_quality_fg.features]\n",
    "            aq_final = aq_final[fg_columns]\n",
    "            \n",
    "            # Insert air quality data immediately\n",
    "            air_quality_fg.insert(aq_final)\n",
    "            \n",
    "            # Fetch and upload weather for this location (if not already done)\n",
    "            location_id = int(meta[\"location_id\"])\n",
    "            if location_id not in location_weather_uploaded:\n",
    "                end_date = today + timedelta(days=7)\n",
    "                weather_df = fetchers.get_weather_forecast(location_id, today, end_date, \n",
    "                                                          meta[\"latitude\"], meta[\"longitude\"])\n",
    "                \n",
    "                if not weather_df.empty:\n",
    "                    weather_df[\"location_id\"] = int(location_id)\n",
    "                    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "                    weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "                    \n",
    "                    # Convert to correct types to match schema\n",
    "                    weather_df[\"location_id\"] = weather_df[\"location_id\"].astype(\"int32\")\n",
    "                    weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float64\")\n",
    "                    weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float64\")\n",
    "                    weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float64\")\n",
    "                    weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float64\")\n",
    "                    \n",
    "                    weather_fg.insert(weather_df)\n",
    "                    location_weather_uploaded.add(location_id)\n",
    "            \n",
    "            successful_sensors += 1\n",
    "            print(f\"‚úÖ Uploaded sensor {sensor_id} (location {location_id})\")\n",
    "            break  # Success, exit retry loop\n",
    "            \n",
    "        except requests.exceptions.Timeout as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (attempt + 1) * 5\n",
    "                print(f\"‚ö†Ô∏è  Sensor {sensor_id}: Timeout, retrying in {wait_time}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                failed_sensors += 1\n",
    "                print(f\"‚ùå Sensor {sensor_id}: Failed after {max_retries} timeout attempts\")\n",
    "                break\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (attempt + 1) * 5\n",
    "                print(f\"‚ö†Ô∏è  Sensor {sensor_id}: {type(e).__name__}, retrying in {wait_time}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                failed_sensors += 1\n",
    "                print(f\"‚ùå Sensor {sensor_id}: Failed after {max_retries} attempts - {type(e).__name__}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_sensors += 1\n",
    "            print(f\"‚ùå Sensor {sensor_id}: Unexpected error - {type(e).__name__}: {str(e)[:100]}\")\n",
    "            import traceback\n",
    "            print(f\"   {traceback.format_exc()[:300]}\")\n",
    "            break\n",
    "    \n",
    "    # Brief pause between sensors\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\nüìä Collection Summary:\")\n",
    "print(f\"   ‚úÖ Successful: {successful_sensors}\")\n",
    "print(f\"   ‚è≠Ô∏è Skipped (no data): {skipped_sensors}\")\n",
    "print(f\"   ‚ùå Failed: {failed_sensors}\")\n",
    "print(f\"   üå§Ô∏è Weather locations uploaded: {len(location_weather_uploaded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4e975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 103 sensor locations...\n",
      "‚úÖ Processed sensor 191047 (location 15)\n",
      "‚úÖ Processed sensor 59410 (location 49)\n",
      "‚úÖ Processed sensor 113542 (location 6)\n",
      "‚úÖ Processed sensor 59497 (location 50)\n",
      "‚úÖ Processed sensor 420664 (location 33)\n",
      "‚úÖ Processed sensor 60076 (location 58)\n",
      "‚úÖ Processed sensor 61714 (location 68)\n",
      "‚úÖ Processed sensor 198559 (location 19)\n",
      "‚úÖ Processed sensor 60535 (location 59)\n",
      "‚úÖ Processed sensor 81505 (location 94)\n",
      "‚úÖ Processed sensor 57421 (location 42)\n",
      "‚úÖ Processed sensor 59893 (location 55)\n",
      "‚úÖ Processed sensor 89584 (location 100)\n",
      "‚úÖ Processed sensor 409513 (location 30)\n",
      "‚úÖ Processed sensor 407335 (location 29)\n",
      "‚úÖ Processed sensor 194215 (location 17)\n",
      "‚úÖ Processed sensor 105325 (location 1)\n",
      "‚úÖ Processed sensor 77488 (location 88)\n",
      "‚úÖ Processed sensor 63646 (location 75)\n",
      "‚úÖ Processed sensor 149242 (location 11)\n",
      "‚úÖ Processed sensor 58912 (location 45)\n",
      "‚úÖ Processed sensor 80773 (location 93)\n",
      "‚úÖ Processed sensor 113539 (location 5)\n",
      "‚úÖ Processed sensor 84085 (location 97)\n",
      "‚úÖ Processed sensor 82384 (location 95)\n",
      "‚úÖ Processed sensor 78532 (location 90)\n",
      "‚úÖ Processed sensor 65284 (location 79)\n",
      "‚úÖ Processed sensor 82942 (location 96)\n",
      "‚úÖ Processed sensor 415030 (location 31)\n",
      "‚úÖ Processed sensor 65707 (location 81)\n",
      "‚úÖ Processed sensor 63637 (location 74)\n",
      "‚úÖ Processed sensor 62566 (location 71)\n",
      "‚úÖ Processed sensor 60838 (location 61)\n",
      "‚úÖ Processed sensor 59650 (location 52)\n",
      "‚úÖ Processed sensor 401314 (location 27)\n",
      "‚úÖ Processed sensor 163156 (location 13)\n",
      "‚úÖ Processed sensor 58921 (location 46)\n",
      "2026-01-09 11:00:11,383 WARNING: Retrying (Retry(total=4, connect=5, read=4, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='api.open-meteo.com', port=443): Read timed out. (read timeout=None)\")': /v1/forecast?latitude=56.422444&longitude=15.539563&start_date=2026-01-09&end_date=2026-01-16&daily=temperature_2m_mean&daily=precipitation_sum&daily=wind_speed_10m_max&daily=wind_direction_10m_dominant&timezone=UTC&format=flatbuffers\n",
      "‚úÖ Processed sensor 59899 (location 56)\n",
      "‚úÖ Processed sensor 462457 (location 34)\n",
      "‚úÖ Processed sensor 474841 (location 35)\n",
      "‚úÖ Processed sensor 476353 (location 36)\n",
      "‚úÖ Processed sensor 556792 (location 40)\n",
      "‚úÖ Processed sensor 78529 (location 89)\n",
      "‚úÖ Processed sensor 154549 (location 12)\n",
      "‚úÖ Processed sensor 69628 (location 83)\n",
      "‚úÖ Processed sensor 62968 (location 73)\n",
      "‚úÖ Processed sensor 59656 (location 53)\n",
      "‚úÖ Processed sensor 58909 (location 44)\n",
      "‚úÖ Processed sensor 497266 (location 38)\n",
      "‚úÖ Processed sensor 60073 (location 57)\n",
      "‚úÖ Processed sensor 59593 (location 51)\n",
      "‚úÖ Processed sensor 404209 (location 28)\n",
      "‚úÖ Processed sensor 60889 (location 65)\n",
      "‚úÖ Processed sensor 192520 (location 16)\n",
      "‚úÖ Processed sensor 252352 (location 23)\n",
      "‚úÖ Processed sensor 65104 (location 76)\n",
      "‚úÖ Processed sensor 345007 (location 24)\n",
      "‚úÖ Processed sensor 61045 (location 66)\n",
      "‚úÖ Processed sensor 121810 (location 7)\n",
      "‚úÖ Processed sensor 60541 (location 60)\n",
      "‚úÖ Processed sensor 376954 (location 26)\n",
      "‚úÖ Processed sensor 58666 (location 43)\n",
      "‚úÖ Processed sensor 562600 (location 41)\n",
      "‚úÖ Processed sensor 59887 (location 54)\n",
      "‚úÖ Processed sensor 208483 (location 20)\n",
      "‚úÖ Processed sensor 65290 (location 80)\n",
      "‚úÖ Processed sensor 250030 (location 22)\n",
      "‚úÖ Processed sensor 65272 (location 78)\n",
      "‚úÖ Processed sensor 533086 (location 39)\n",
      "‚úÖ Processed sensor 129124 (location 10)\n",
      "2026-01-09 11:01:42,094 WARNING: Retrying (Retry(total=4, connect=5, read=4, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='api.open-meteo.com', port=443): Read timed out. (read timeout=None)\")': /v1/forecast?latitude=57.7072326&longitude=11.9670171&start_date=2026-01-09&end_date=2026-01-16&daily=temperature_2m_mean&daily=precipitation_sum&daily=wind_speed_10m_max&daily=wind_direction_10m_dominant&timezone=UTC&format=flatbuffers\n",
      "‚úÖ Processed sensor 112672 (location 3)\n",
      "‚úÖ Processed sensor 61861 (location 69)\n",
      "‚úÖ Processed sensor 88876 (location 99)\n",
      "‚úÖ Processed sensor 65146 (location 77)\n",
      "‚úÖ Processed sensor 60853 (location 62)\n",
      "‚úÖ Processed sensor 180187 (location 14)\n",
      "‚úÖ Processed sensor 70564 (location 85)\n",
      "‚úÖ Processed sensor 60886 (location 64)\n",
      "‚úÖ Processed sensor 494275 (location 37)\n",
      "‚úÖ Processed sensor 92683 (location 102)\n",
      "‚úÖ Processed sensor 87319 (location 98)\n",
      "‚úÖ Processed sensor 60859 (location 63)\n",
      "‚úÖ Processed sensor 351115 (location 25)\n",
      "‚úÖ Processed sensor 88372 (location 3)\n",
      "‚úÖ Processed sensor 417595 (location 32)\n",
      "‚úÖ Processed sensor 62848 (location 72)\n",
      "‚úÖ Processed sensor 69724 (location 84)\n",
      "‚úÖ Processed sensor 196735 (location 18)\n",
      "‚úÖ Processed sensor 59356 (location 48)\n",
      "‚úÖ Processed sensor 77446 (location 87)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         aq_today_df, weather_df, location_id = \u001b[43mfetchers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_data_for_sensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAQICN_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m         \u001b[38;5;66;03m# Format air quality data\u001b[39;00m\n\u001b[32m     33\u001b[39m         aq_today_df = aq_today_df.assign(\n\u001b[32m     34\u001b[39m             sensor_id=\u001b[38;5;28mint\u001b[39m(sensor_id),\n\u001b[32m     35\u001b[39m             street=meta[\u001b[33m\"\u001b[39m\u001b[33mstreet\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m             feed_url=meta[\u001b[33m\"\u001b[39m\u001b[33maqicn_url\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     39\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\utils\\fetchers.py:268\u001b[39m, in \u001b[36mfetch_data_for_sensor\u001b[39m\u001b[34m(sensor_id, meta, today, AQICN_API_KEY)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Fetch weather forecast (7 days forward)\u001b[39;00m\n\u001b[32m    267\u001b[39m end_date = today + timedelta(days=\u001b[32m7\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m weather_df = \u001b[43mget_weather_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m aq_today_df, weather_df, location_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\utils\\fetchers.py:232\u001b[39m, in \u001b[36mget_weather_forecast\u001b[39m\u001b[34m(location_id, start_date, end_date, latitude, longitude)\u001b[39m\n\u001b[32m    217\u001b[39m params = {\n\u001b[32m    218\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m\"\u001b[39m: latitude,\n\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m\"\u001b[39m: longitude,\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimezone\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mUTC\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m }\n\u001b[32m    231\u001b[39m rate_limited_request()\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m responses = \u001b[43mopenmeteo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweather_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m response = responses[\u001b[32m0\u001b[39m]\n\u001b[32m    235\u001b[39m daily = response.Daily()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\openmeteo_requests\\Client.py:88\u001b[39m, in \u001b[36mClient.weather_api\u001b[39m\u001b[34m(self, url, params, method, verify, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get and decode as weather api\"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed to request \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\openmeteo_requests\\Client.py:68\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, url, method, params, verify, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._session.post(url, data=params, verify=verify, **kwargs)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m400\u001b[39m, \u001b[32m429\u001b[39m]:\n\u001b[32m     71\u001b[39m     response_body = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests_cache\\session.py:126\u001b[39m, in \u001b[36mCacheMixin.get\u001b[39m\u001b[34m(self, url, params, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs) -> AnyResponse:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    125\u001b[39m     kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests_cache\\session.py:182\u001b[39m, in \u001b[36mCacheMixin.request\u001b[39m\u001b[34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m headers = set_request_headers(headers, expire_after, only_if_cached, refresh, force_refresh)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch_form_boundary() \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mfiles\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests_cache\\session.py:229\u001b[39m, in \u001b[36mCacheMixin.send\u001b[39m\u001b[34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._resend(request, actions, cached_response, **kwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m actions.send_request:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m     response = cached_response  \u001b[38;5;66;03m# type: ignore  # Guaranteed to be non-None by this point\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests_cache\\session.py:253\u001b[39m, in \u001b[36mCacheMixin._send_and_cache\u001b[39m\u001b[34m(self, request, actions, cached_response, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a request and cache the response, unless disabled by settings or headers.\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03mIf applicable, also handle conditional requests.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m request = actions.update_request(request)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m actions.update_from_response(response)\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions.skip_write:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1733\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, on_post_connection, on_upload_body, on_early_response, extension, multiplexed, **response_kw)\u001b[39m\n\u001b[32m   1730\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1732\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1733\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload,misc]\u001b[39;49;00m\n\u001b[32m   1734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_post_connection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_post_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_upload_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_upload_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_early_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_early_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiplexed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiplexed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1751\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m \u001b[38;5;66;03m# it was established a non-multiplexed connection. fallback to original behavior.\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ResponsePromise):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1232\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length, on_post_connection, on_upload_body, on_early_response, extension, multiplexed)\u001b[39m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1230\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m   1231\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1234\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:2322\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   2318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_conn\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn: HTTPConnection) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2319\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2320\u001b[39m \u001b[33;03m    Called right before a request is made, after the socket is created.\u001b[39;00m\n\u001b[32m   2321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2322\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2324\u001b[39m     \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    784\u001b[39m \u001b[33;03mCalled right before a request is made, after the socket is created.\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connection.py:833\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.server_hostname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    831\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.server_hostname\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpn_protocols\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpn_protocols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43mciphers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mciphers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# we want the http3 upgrade to behave\u001b[39;00m\n\u001b[32m    857\u001b[39m \u001b[38;5;66;03m# exactly as http1/http2 ssl handshake\u001b[39;00m\n\u001b[32m    858\u001b[39m \u001b[38;5;66;03m# configuration CAstore wise for example\u001b[39;00m\n\u001b[32m    859\u001b[39m \u001b[38;5;66;03m# only if not using tls in tls\u001b[39;00m\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sock_and_verified.socket, \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\connection.py:995\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls, alpn_protocols, cert_data, key_data, ciphers)\u001b[39m\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    993\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpn_protocols\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpn_protocols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeydata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mciphers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mciphers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_cert_reqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_ssl_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmitigate_tls_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m context = ssl_sock.context\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:791\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls, alpn_protocols, certdata, keydata, check_hostname, ssl_minimum_version, ssl_maximum_version)\u001b[39m\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    789\u001b[39m         context = cached_ctx\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:835\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    832\u001b[39m     SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:517\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    512\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    513\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    514\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1101\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m:\n\u001b[32m   1102\u001b[39m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[32m   1103\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1382\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28mself\u001b[39m._sslobj.do_handshake()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28mself\u001b[39m.settimeout(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # latest_per_sensor = (\n",
    "# #     historical_df.groupby(\"sensor_id\")[\"date\"]\n",
    "# #     .max()\n",
    "# #     .to_dict()\n",
    "# # )\n",
    "\n",
    "# # incremental.run_incremental_update(\n",
    "# #     sensor_metadata_fg,\n",
    "# #     air_quality_fg,\n",
    "# #     weather_fg,\n",
    "# #     latest_per_sensor,\n",
    "# #     AQICN_API_KEY\n",
    "# # )\n",
    "\n",
    "# aqs = []\n",
    "# weathers = []\n",
    "# location_weather_cache = {}  # Cache weather by location_id to avoid duplicate API calls\n",
    "\n",
    "# successful_sensors = 0\n",
    "# failed_sensors = 0\n",
    "# skipped_sensors = 0\n",
    "\n",
    "# print(f\"üîç Processing {len(metadata_df)} sensor locations...\")\n",
    "\n",
    "# for sensor_id, meta in metadata_df.iterrows():\n",
    "#     max_retries = 3\n",
    "    \n",
    "#     for attempt in range(max_retries):\n",
    "#         try:\n",
    "#             aq_today_df, weather_df, location_id = fetchers.fetch_data_for_sensor(sensor_id, meta, today, AQICN_API_KEY)\n",
    "\n",
    "#             # Format air quality data\n",
    "#             aq_today_df = aq_today_df.assign(\n",
    "#                 sensor_id=int(sensor_id),\n",
    "#                 street=meta[\"street\"],\n",
    "#                 city=meta[\"city\"],\n",
    "#                 country=meta[\"country\"],\n",
    "#                 feed_url=meta[\"aqicn_url\"],\n",
    "#             )\n",
    "#             aq_today_df[\"date\"] = pd.to_datetime(aq_today_df[\"date\"])\n",
    "            \n",
    "#             # Check if we actually got data\n",
    "#             if aq_today_df.empty:\n",
    "#                 print(f\"‚è≠Ô∏è Sensor {sensor_id}: No AQ data available\")\n",
    "#                 skipped_sensors += 1\n",
    "#                 break\n",
    "            \n",
    "#             aqs.append(aq_today_df)\n",
    "\n",
    "#             # Weather is per location_id, not per sensor - cache it\n",
    "#             if location_id not in location_weather_cache:\n",
    "#                 weather_df[\"location_id\"] = int(location_id)\n",
    "#                 weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "#                 location_weather_cache[location_id] = weather_df\n",
    "#                 weathers.append(weather_df)\n",
    "            \n",
    "#             successful_sensors += 1\n",
    "#             print(f\"‚úÖ Processed sensor {sensor_id} (location {location_id})\")\n",
    "#             break  # Success, exit retry loop\n",
    "            \n",
    "#         except requests.exceptions.Timeout as e:\n",
    "#             if attempt < max_retries - 1:\n",
    "#                 wait_time = (attempt + 1) * 5  # 5s, 10s, 15s\n",
    "#                 print(f\"‚ö†Ô∏è  Sensor {sensor_id}: Timeout, retrying in {wait_time}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "#                 time.sleep(wait_time)\n",
    "#             else:\n",
    "#                 failed_sensors += 1\n",
    "#                 print(f\"‚ùå Sensor {sensor_id}: Failed after {max_retries} timeout attempts\")\n",
    "#                 break\n",
    "                \n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             if attempt < max_retries - 1:\n",
    "#                 wait_time = (attempt + 1) * 5\n",
    "#                 print(f\"‚ö†Ô∏è  Sensor {sensor_id}: {type(e).__name__}, retrying in {wait_time}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "#                 time.sleep(wait_time)\n",
    "#             else:\n",
    "#                 failed_sensors += 1\n",
    "#                 print(f\"‚ùå Sensor {sensor_id}: Failed after {max_retries} attempts - {type(e).__name__}\")\n",
    "#                 break\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             failed_sensors += 1\n",
    "#             print(f\"‚ùå Sensor {sensor_id}: Unexpected error - {type(e).__name__}: {str(e)[:100]}\")\n",
    "#             break\n",
    "    \n",
    "#     # Brief pause between sensors to avoid rate limiting\n",
    "#     time.sleep(0.5)\n",
    "\n",
    "# print(f\"\\nüìä Collection Summary:\")\n",
    "# print(f\"   ‚úÖ Successful: {successful_sensors}\")\n",
    "# print(f\"   ‚è≠Ô∏è Skipped (no data): {skipped_sensors}\")\n",
    "# print(f\"   ‚ùå Failed: {failed_sensors}\")\n",
    "# print(f\"   üå§Ô∏è Unique locations: {len(location_weather_cache)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_df = pd.concat(aqs)\n",
    "aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_df = pd.concat(aqs) if aqs else pd.DataFrame()\n",
    "if not aq_df.empty:\n",
    "    aq_df[\"pm25\"] = pd.to_numeric(aq_df[\"pm25\"], errors=\"coerce\").astype(\"float64\")\n",
    "    aq_df[\"date\"] = pd.to_datetime(aq_df[\"date\"]).dt.tz_localize(None)\n",
    "    aq_df = aq_df.drop(columns=[\"url\"], errors=\"ignore\")\n",
    "\n",
    "    # Data quality check 1: Remove rows with missing PM2.5 values\n",
    "    initial_count = len(aq_df)\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    if len(aq_df) < initial_count:\n",
    "        print(f\"üßπ Removed {initial_count - len(aq_df)} rows with missing PM2.5 values\")\n",
    "\n",
    "# Get historical data for rolling window and lagged features\n",
    "historical_start = today - datetime.timedelta(days=4)\n",
    "historical_df = pd.DataFrame()\n",
    "\n",
    "# Read historical data from feature group and filter for the last 4 days\n",
    "try:\n",
    "    cols = [f.name for f in air_quality_fg.features] \n",
    "    historical_df = air_quality_fg.read(cols)\n",
    "    if not historical_df.empty:\n",
    "        historical_df[\"date\"] = pd.to_datetime(historical_df[\"date\"]).dt.tz_localize(None)\n",
    "        historical_df = historical_df[\n",
    "            (historical_df[\"date\"] >= historical_start) & (historical_df[\"date\"] < today)\n",
    "        ][[\"date\", \"sensor_id\", \"pm25\"]]\n",
    "except Exception as e:\n",
    "    print(f\"Error reading historical data: {e}\")\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([historical_df, aq_df], ignore_index=True) if not historical_df.empty else aq_df\n",
    "if not combined_df.empty:\n",
    "    combined_df = feature_engineering.add_rolling_window_feature(combined_df, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "    combined_df = feature_engineering.add_lagged_features(combined_df, column=\"pm25\", lags=[1, 2, 3])\n",
    "    combined_df = feature_engineering.add_nearby_sensor_feature(combined_df, metadata_df.to_dict('index'), column=\"pm25_lag_1d\", n_closest=3)\n",
    "    \n",
    "    # Data quality check 2: Clean up NaNs created by feature engineering\n",
    "    before_cleaning = len(combined_df[combined_df[\"date\"].dt.date == today])\n",
    "    \n",
    "    # Only keep today's data and remove rows where essential features are NaN\n",
    "    aq_df = combined_df[combined_df[\"date\"].dt.date == today].copy()\n",
    "    \n",
    "    # Remove rows where pm25 is still NaN after all processing\n",
    "    aq_df = aq_df.dropna(subset=['pm25'])\n",
    "    \n",
    "    after_cleaning = len(aq_df)\n",
    "    if before_cleaning > after_cleaning:\n",
    "        print(f\"üßπ Removed {before_cleaning - after_cleaning} rows with NaN values after feature engineering\")\n",
    "    \n",
    "    print(f\"üìä Final data quality: {len(aq_df)} clean rows ready for feature store\")\n",
    "else:\n",
    "    aq_df = pd.DataFrame()\n",
    "    print(\"‚ö†Ô∏è  No data available for processing\")\n",
    "aq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat(weathers) if weathers else pd.DataFrame()\n",
    "if not weather_df.empty:\n",
    "    weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "    \n",
    "    # Data quality check 3: Remove rows with missing weather data\n",
    "    initial_weather_count = len(weather_df)\n",
    "    weather_df = weather_df.dropna(subset=['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max'])\n",
    "    \n",
    "    # Convert to float32 to match Hopsworks feature group schema\n",
    "    weather_df[\"temperature_2m_mean\"] = weather_df[\"temperature_2m_mean\"].astype(\"float32\")\n",
    "    weather_df[\"precipitation_sum\"] = weather_df[\"precipitation_sum\"].astype(\"float32\")\n",
    "    weather_df[\"wind_speed_10m_max\"] = weather_df[\"wind_speed_10m_max\"].astype(\"float32\")\n",
    "    weather_df[\"wind_direction_10m_dominant\"] = weather_df[\"wind_direction_10m_dominant\"].astype(\"float32\")\n",
    "    \n",
    "    if len(weather_df) < initial_weather_count:\n",
    "        print(f\"üßπ Removed {initial_weather_count - len(weather_df)} rows with missing weather data\")\n",
    "    \n",
    "    print(f\"üå§Ô∏è  Weather data quality: {len(weather_df)} clean weather rows\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No weather data available\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_df['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation before inserting to feature store\n",
    "if not aq_df.empty and not weather_df.empty:\n",
    "    print(f\"‚úÖ Inserting {len(aq_df)} air quality rows and {len(weather_df)} weather rows to feature store\")\n",
    "    air_quality_fg.insert(aq_df)\n",
    "    weather_fg.insert(weather_df)\n",
    "    print(\"üìÅ Data successfully inserted to feature store\")\n",
    "else:\n",
    "    if aq_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean air quality data to insert\")\n",
    "    if weather_df.empty:\n",
    "        print(\"‚ö†Ô∏è  No clean weather data to insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_df['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae941b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aq_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(air_quality_fg.read().dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
