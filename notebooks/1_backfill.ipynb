{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a14877f",
   "metadata": {},
   "source": [
    "# 1. Backfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e716b",
   "metadata": {},
   "source": [
    "## 1.1. Imports and environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee74632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root dir: c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n",
      "HopsworksSettings initialized!\n",
      "2026-01-02 16:57:50,805 INFO: Initializing external client\n",
      "2026-01-02 16:57:50,806 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-02 16:57:51,623 WARNING: UserWarning: The installed hopsworks client version 4.1.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-02 16:57:52,655 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone, date\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "#  Establish project root directory\n",
    "def find_project_root(start: Path):\n",
    "    for parent in [start] + list(start.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return start\n",
    "\n",
    "root_dir = find_project_root(Path().absolute())\n",
    "print(\"Project root dir:\", root_dir)\n",
    "\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Third-party imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "import hopsworks\n",
    "\n",
    "#  Project imports\n",
    "from utils import config, airquality, metadata\n",
    "\n",
    "#  Load settings \n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "GITHUB_USERNAME = settings.GH_USERNAME.get_secret_value()\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5d0ef",
   "metadata": {},
   "source": [
    "## 1.2. Repository management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc6c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already inside repo at c:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\n"
     ]
    }
   ],
   "source": [
    "def clone_or_update_repo(username: str):\n",
    "    repo_name = \"pm25-forecast-openmeteo-aqicn\"\n",
    "\n",
    "    # 1. Detect if already inside the repo\n",
    "    cwd = Path().absolute()\n",
    "    for parent in [cwd] + list(cwd.parents):\n",
    "        if (parent / \".git\").exists() and parent.name == repo_name:\n",
    "            print(f\"Already inside repo at {parent}\")\n",
    "            return parent\n",
    "\n",
    "    # 2. Detect if the repo exists in the current directory\n",
    "    repo_dir = Path(repo_name)\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository exists at {repo_dir.absolute()}\")\n",
    "        os.system(f\"git -C {repo_dir} pull\")\n",
    "        return repo_dir\n",
    "\n",
    "    # 3. Otherwise clone it\n",
    "    print(\"Cloning repository...\")\n",
    "    url = f\"https://github.com/{username}/{repo_name}.git\"\n",
    "    exit_code = os.system(f\"git clone {url}\")\n",
    "\n",
    "    if exit_code != 0:\n",
    "        raise RuntimeError(\"Git clone failed.\")\n",
    "\n",
    "    print(\"Clone successful.\")\n",
    "    return repo_dir\n",
    "\n",
    "repo_dir = clone_or_update_repo(GITHUB_USERNAME)\n",
    "os.chdir(repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b37afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def install_dependencies(): \n",
    "#         subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
    "# install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61d9d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date.today()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"AQICN_API_KEY missing.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1641ed",
   "metadata": {},
   "source": [
    "## 1.5. Data Validation Setup\n",
    "Creates Great Expectations validation suites for air quality and weather data with column value constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef87eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_values_to_be_between\", \"kwargs\": {\"column\": \"longitude\", \"min_value\": -180, \"max_value\": 180}, \"meta\": {}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq_expectation_suite = gx.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"pm25\",\n",
    "            \"min_value\": -0.1,\n",
    "            \"max_value\": 500.0,\n",
    "            \"strict_min\": True,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_columns_to_match_set\",\n",
    "        kwargs={\n",
    "            \"column_set\": [\n",
    "                \"date\", \"pm25\", \"sensor_id\", \"street\", \"city\", \"country\",\n",
    "                \"feed_url\", \"pm25_rolling_3d\", \"pm25_lag_1d\",\n",
    "                \"pm25_lag_2d\", \"pm25_lag_3d\", \"pm25_nearby_avg\"\n",
    "            ],\n",
    "            \"exact_match\": True,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"pm25\", \"type_\": \"float\"},\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"pm25\"},\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_dateutil_parseable\",\n",
    "        kwargs={\"column\": \"date\"},\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_compound_columns_to_be_unique\",\n",
    "        kwargs={\"column_list\": [\"sensor_id\", \"date\"]},\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"sensor_id\", \"type_\": \"str\"},\n",
    "    )\n",
    ")\n",
    "aq_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"date\"},\n",
    "    )\n",
    ")\n",
    "for col in [\"pm25_rolling_3d\", \"pm25_lag_1d\", \"pm25_lag_2d\", \"pm25_lag_3d\", \"pm25_nearby_avg\"]:\n",
    "    aq_expectation_suite.add_expectation(\n",
    "        gx.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "            kwargs={\"column\": col, \"type_\": \"float\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "weather_expectation_suite = gx.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        gx.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\": col,\n",
    "                \"min_value\": -0.1,\n",
    "                \"max_value\": 1000.0,\n",
    "                \"strict_min\": True,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")\n",
    "\n",
    "weather_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_columns_to_match_set\",\n",
    "        kwargs={\n",
    "            \"column_set\": [\n",
    "                \"date\", \"temperature_2m_mean\", \"precipitation_sum\",\n",
    "                \"wind_speed_10m_max\", \"wind_direction_10m_dominant\",\n",
    "                \"city\", \"sensor_id\", \"latitude\", \"longitude\"\n",
    "            ],\n",
    "            \"exact_match\": True,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "for col in [\"temperature_2m_mean\", \"precipitation_sum\", \"wind_speed_10m_max\"]:\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        gx.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "            kwargs={\"column\": col},\n",
    "        )\n",
    "    )\n",
    "weather_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"temperature_2m_mean\", \"min_value\": -60, \"max_value\": 60},\n",
    "    )\n",
    ")\n",
    "weather_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_dateutil_parseable\",\n",
    "        kwargs={\"column\": \"date\"},\n",
    "    )\n",
    ")\n",
    "weather_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"latitude\", \"min_value\": -90, \"max_value\": 90},\n",
    "    )\n",
    ")\n",
    "weather_expectation_suite.add_expectation(\n",
    "    gx.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"longitude\", \"min_value\": -180, \"max_value\": 180},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68ea8b",
   "metadata": {},
   "source": [
    "## 1.6. Helper Methods\n",
    "Data processing functions - clean air quality data and fetch historical weather data with API rate limiting and retry logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcc2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_append_data(df, street, city, country, feed_url, sensor_id):\n",
    "    \"\"\"\n",
    "    Remove any unused columns, set the daily median value to pm25. Remove NaN's and append the metadata.\n",
    "    \"\"\"\n",
    "    clean_df = pd.DataFrame()\n",
    "    clean_df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    clean_df[\"pm25\"] = df[\"median\"]\n",
    "    clean_df = clean_df.dropna(subset=[\"pm25\"])\n",
    "    clean_df[\"sensor_id\"] = sensor_id\n",
    "    clean_df[\"street\"] = street\n",
    "    clean_df[\"city\"] = city\n",
    "    clean_df[\"country\"] = country\n",
    "    clean_df[\"feed_url\"] = feed_url\n",
    "    return clean_df\n",
    "\n",
    "def get_historical_weather(city, df, today, feed_url, sensor_id):\n",
    "    earliest_aq_date = pd.Series.min(df[\"date\"])\n",
    "    earliest_aq_date = earliest_aq_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    response = requests.get(f\"{feed_url}/?token={AQICN_API_KEY}\")\n",
    "    data = response.json()\n",
    "\n",
    "    # Handle AQICN API error status or missing city\n",
    "    if (\"status\" in data.get(\"data\", {}) and data[\"data\"][\"status\"] == \"error\") or \"city\" not in data.get(\"data\", {}):\n",
    "        print(f\"Skipping sensor {sensor_id}: AQICN API error or unknown ID. Response: {data}\")\n",
    "        return None, None, None \n",
    "    try:\n",
    "        latitude, longitude = airquality.get_sensor_coordinates(feed_url, sensor_id, AQICN_API_KEY)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to get coordinates for sensor {sensor_id}: {e}\")\n",
    "    \n",
    "    max_retries = 5\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            weather_df = airquality.get_historical_weather(\n",
    "                city, earliest_aq_date, str(today), latitude, longitude\n",
    "            )\n",
    "            weather_df[\"sensor_id\"] = sensor_id\n",
    "            weather_df[\"city\"] = city\n",
    "            weather_df[\"latitude\"] = latitude\n",
    "            weather_df[\"longitude\"] = longitude\n",
    "            return weather_df, latitude, longitude\n",
    "        except Exception as e:\n",
    "            if hasattr(e, \"args\") and any(\n",
    "                \"Minutely API request limit exceeded\" in str(a) for a in e.args\n",
    "            ):\n",
    "                wait_time = 70\n",
    "                print(\n",
    "                    f\"OpenMeteo API limit exceeded, retrying in {wait_time} seconds... (Attempt {attempt + 1} of {max_retries})\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            elif \"Minutely API request limit exceeded\" in str(e):\n",
    "                wait_time = 70\n",
    "                print(\n",
    "                    f\"OpenMeteo API limit exceeded, retrying in {wait_time} seconds... (Attempt {attempt + 1} of {max_retries})\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                raise\n",
    "    raise RuntimeError(\n",
    "        \"Failed to obtain historical weather after multiple retries due to API rate limits.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1310d",
   "metadata": {},
   "source": [
    "## 1.7. Hopsworks\n",
    "Feature Group Management - functions to create and manage air quality and weather feature groups in Hopsworks, including schema descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30e342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_air_quality_feature_group():\n",
    "    air_quality_fg = fs.get_or_create_feature_group(\n",
    "        name=\"air_quality\",\n",
    "        description=\"Air Quality characteristics of each day for all sensors\",\n",
    "        version=1,\n",
    "        primary_key=[\"sensor_id\"],\n",
    "        event_time=\"date\",\n",
    "        expectation_suite=aq_expectation_suite,\n",
    "    )\n",
    "    return air_quality_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ea6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_duplicates(new_df=None):\n",
    "#     \"\"\"\n",
    "#     Remove duplicate entries from the Hopsworks feature group, keeping only the latest for each (sensor_id, date).\n",
    "#     If new_df is provided, also remove any rows from new_df that would duplicate (sensor_id, date) already present in the feature group.\n",
    "#     Returns a deduplicated DataFrame for upload (if new_df is provided), else None.\n",
    "#     \"\"\"\n",
    "#     # Try to read from the feature group, handle empty case\n",
    "#     try:\n",
    "#         df = air_quality_fg.read()\n",
    "#         feature_group_empty = df.empty\n",
    "#     except Exception as e:\n",
    "#         print(\"Feature group is empty or cannot be read. Skipping FG deduplication.\")\n",
    "#         feature_group_empty = True\n",
    "#         df = None\n",
    "\n",
    "#     # Deduplicate new_df in-memory before upload\n",
    "#     if new_df is not None:\n",
    "#         # Remove duplicates within new_df itself (by sensor_id and date)\n",
    "#         new_df = new_df.sort_values(['sensor_id', 'date'])\n",
    "#         new_df = new_df.drop_duplicates(subset=['sensor_id', 'date'], keep='last')\n",
    "#         if not feature_group_empty:\n",
    "#             # Remove rows from new_df that already exist in the feature group\n",
    "#             df_keys = df[['sensor_id', 'date']].drop_duplicates()\n",
    "#             new_df = new_df.copy()\n",
    "#             df_keys = df_keys.copy()\n",
    "#             # Ensure both are timezone-naive\n",
    "#             new_df['date'] = pd.to_datetime(new_df['date']).dt.tz_localize(None)\n",
    "#             df_keys['date'] = pd.to_datetime(df_keys['date']).dt.tz_localize(None)\n",
    "#             merged = new_df.merge(df_keys, on=['sensor_id', 'date'], how='left', indicator=True)\n",
    "#             deduped_new_df = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "#             print(f\"Filtered out {len(new_df) - len(deduped_new_df)} rows from new data that already exist in feature group.\")\n",
    "#             new_df = deduped_new_df\n",
    "#         # Final check: ensure no duplicates remain in new_df\n",
    "#         final_dupes = new_df.duplicated(subset=['sensor_id', 'date'], keep=False)\n",
    "#         if final_dupes.any():\n",
    "#             print(\"Warning: Duplicates still present in new_df after deduplication. Removing all but the last occurrence.\")\n",
    "#             new_df = new_df.drop_duplicates(subset=['sensor_id', 'date'], keep='last')\n",
    "#         return new_df\n",
    "\n",
    "#     # If feature group is not empty, deduplicate it\n",
    "#     if not feature_group_empty:\n",
    "#         df_sorted = df.sort_values(['sensor_id', 'date'])\n",
    "#         mask = df_sorted.duplicated(subset=['sensor_id', 'date'], keep='last')\n",
    "#         duplicates = df_sorted[mask]\n",
    "#         print(f\"Found {len(duplicates)} duplicate rows to delete in feature group.\")\n",
    "#         for _, row in duplicates.iterrows():\n",
    "#             air_quality_fg.delete_record({\"sensor_id\": row[\"sensor_id\"], \"date\": row[\"date\"]})\n",
    "#         print(\"Duplicate rows deleted from feature group.\")\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ad363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_air_quality_description(air_quality_fg):\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"date\", \"Date of measurement of air quality\"\n",
    "    )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\"\n",
    "    )\n",
    "    # air_quality_fg.update_feature_description(\n",
    "    #     \"country\",\n",
    "    #     \"Country where the air quality was measured (sometimes a city in aqicn.org)\",\n",
    "    # )\n",
    "    # air_quality_fg.update_feature_description(\n",
    "    #     \"city\", \"City where the air quality was measured\"\n",
    "    # )\n",
    "    # air_quality_fg.update_feature_description(\n",
    "    #     \"street\", \"Street in the city where the air quality was measured\"\n",
    "    # )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"pm25\",\n",
    "        \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\",\n",
    "    )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"pm25_rolling_3d\",\n",
    "        \"3-day rolling mean of PM2.5 from previous days (lagged by 1 day for point-in-time correctness).\",\n",
    "    )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"pm25_lag_1d\",\n",
    "        \"PM2.5 value from 1 day ago.\",\n",
    "    )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"pm25_lag_2d\",\n",
    "        \"PM2.5 value from 2 days ago.\",\n",
    "    )\n",
    "    air_quality_fg.update_feature_description(\n",
    "        \"pm25_lag_3d\",\n",
    "        \"PM2.5 value from 3 days ago.\",\n",
    "    )\n",
    "    # air_quality_fg.update_feature_description(\n",
    "    #     \"pm25_nearby_avg\",\n",
    "    #     \"Average PM2.5 value from the 3 closest sensors.\",\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_and_insert_air_quality_data():\n",
    "#     air_quality_fg = create_air_quality_feature_group()\n",
    "#     # air_quality_fg.insert(df)\n",
    "#     # update_air_quality_description(air_quality_fg)\n",
    "#     # # remove_duplicates()\n",
    "#     # deduped_df = remove_duplicates(df)\n",
    "#     # # Check for dict-typed columns\n",
    "#     # for col in deduped_df.columns:\n",
    "#     #     if deduped_df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "#     #         print(f\"Warning: Column '{col}' contains dict values!\")\n",
    "#     # # air_quality_fg.insert(deduped_df)\n",
    "#     # update_air_quality_description(air_quality_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e044ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sensor_metadata_feature_group():\n",
    "    sensor_metadata_fg = fs.get_or_create_feature_group(\n",
    "        name=\"sensor_metadata\",\n",
    "        description=\"Metadata for each air quality sensor\",\n",
    "        version=1,\n",
    "        primary_key=[\"sensor_id\"],\n",
    "        expectation_suite=None,\n",
    "    )\n",
    "    return sensor_metadata_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f533ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sensor_metadata_description(sensor_metadata_fg):\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\"\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"city\", \"City where the air quality was measured\"\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"street\", \"Street in the city where the air quality was measured\"\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"country\",\n",
    "        \"Country where the air quality was measured (sometimes a city in aqicn.org)\",\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"aqicn_url\", \"URL to the AQICN feed for this sensor\"\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"latitude\", \"Latitude of the sensor location\"\n",
    "    )\n",
    "    sensor_metadata_fg.update_feature_description(\n",
    "        \"longitude\", \"Longitude of the sensor location\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_and_insert_sensor_metadata_data():\n",
    "#     sensor_metadata_fg = create_sensor_metadata_feature_group()\n",
    "#     # sensor_metadata_fg.insert(df)\n",
    "#     # update_sensor_metadata_description(sensor_metadata_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2150ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_feature_group():\n",
    "    weather_fg = fs.get_or_create_feature_group(\n",
    "        name=\"weather\",\n",
    "        description=\"Weather characteristics of each day for all sensors\",\n",
    "        version=1,\n",
    "        primary_key=[\"sensor_id\"],\n",
    "        event_time=\"date\",\n",
    "        expectation_suite=weather_expectation_suite,\n",
    "    )\n",
    "    return weather_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbe5b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weather_description(weather_fg):\n",
    "    weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "    weather_fg.update_feature_description(\n",
    "        \"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"city\", \"City where weather is measured/forecast for\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"temperature_2m_mean\", \"Temperature in Celsius\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"precipitation_sum\", \"Precipitation (rain/snow) in mm\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"latitude\", \"Latitude of sensor location used for weather retrieval\"\n",
    "    )\n",
    "    weather_fg.update_feature_description(\n",
    "        \"longitude\", \"Longitude of sensor location used for weather retrieval\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_and_insert_weather_data():\n",
    "#     global weather_fg\n",
    "#     weather_fg = create_weather_feature_group()\n",
    "#     # weather_fg.insert(df)\n",
    "# #    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1eea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"'FeatureGroup' object has no feature called 'date'.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m air_quality_fg = \u001b[43mcreate_and_insert_air_quality_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m sensor_metadata_fg = create_and_insert_sensor_metadata_data()\n\u001b[32m      3\u001b[39m weather_fg = create_and_insert_weather_data()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcreate_and_insert_air_quality_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m air_quality_fg = create_air_quality_feature_group()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# air_quality_fg.insert(df)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mupdate_air_quality_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mair_quality_fg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mupdate_air_quality_description\u001b[39m\u001b[34m(air_quality_fg)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_air_quality_description\u001b[39m(air_quality_fg):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mair_quality_fg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_feature_description\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDate of measurement of air quality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     air_quality_fg.update_feature_description(\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msensor_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAQICN sensor identifier (e.g., 59893)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m     )\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# air_quality_fg.update_feature_description(\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m#     \"country\",\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m#     \"Country where the air quality was measured (sometimes a city in aqicn.org)\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m#     \"street\", \"Street in the city where the air quality was measured\"\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py:974\u001b[39m, in \u001b[36mFeatureGroupBase.update_feature_description\u001b[39m\u001b[34m(self, feature_name, description)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_feature_description\u001b[39m(\n\u001b[32m    947\u001b[39m     \u001b[38;5;28mself\u001b[39m, feature_name: \u001b[38;5;28mstr\u001b[39m, description: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    948\u001b[39m ) -> Union[FeatureGroupBase, FeatureGroup, ExternalFeatureGroup, SpineGroup]:\n\u001b[32m    949\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update the description of a single feature in this feature group.\u001b[39;00m\n\u001b[32m    950\u001b[39m \n\u001b[32m    951\u001b[39m \u001b[33;03m    !!! example\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m \u001b[33;03m        `FeatureGroup`. The updated feature group object.\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     f_copy = copy.deepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    975\u001b[39m     f_copy.description = description\n\u001b[32m    976\u001b[39m     \u001b[38;5;28mself\u001b[39m._feature_group_engine.update_features(\u001b[38;5;28mself\u001b[39m, [f_copy])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krist\\Documents\\GitHub\\pm25-forecast-openmeteo-aqicn\\.venv\\Lib\\site-packages\\hsfs\\feature_group.py:1756\u001b[39m, in \u001b[36mFeatureGroupBase.__getitem__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m feature[\u001b[32m0\u001b[39m]\n\u001b[32m   1755\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1756\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFeatureGroup\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object has no feature called \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"'FeatureGroup' object has no feature called 'date'.\""
     ]
    }
   ],
   "source": [
    "air_quality_fg = create_air_quality_feature_group()\n",
    "\n",
    "sensor_metadata_fg = create_sensor_metadata_feature_group()\n",
    "weather_fg = create_weather_feature_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019a0e6",
   "metadata": {},
   "source": [
    "Load historical data from Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = sensor_metadata_fg.read()\n",
    "metadata_df = metadata_df.set_index(\"sensor_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fg_meta = fs.get_feature_group(\"sensor_metadata\", version=1)\n",
    "# fg_aq = fs.get_feature_group(\"air_quality\", version=1)\n",
    "# fg_weather = fs.get_feature_group(\"weather\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fv = fs.get_or_create_feature_view(\n",
    "    name=\"air_quality_complete_fv\",\n",
    "    version=1,\n",
    "    query=air_quality_fg.select_all()\n",
    "        .join(weather_fg.select_all(), on=[\"sensor_id\", \"date\"])\n",
    "        .join(sensor_metadata_fg.select_all(), on=\"sensor_id\"),\n",
    "    labels=[\"pm25\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = air_quality_fv.get_batch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2e9a1",
   "metadata": {},
   "source": [
    "Detect latest timestamp per sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_per_sensor = (\n",
    "    historical_df.groupby(\"sensor_id\")[\"date\"]\n",
    "    .max()\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bfc17",
   "metadata": {},
   "source": [
    "Incremental air quality fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_latest_aq_data(sensor_id, feed_url, since):\n",
    "    response = requests.get(feed_url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    if data.get(\"status\") != \"ok\":\n",
    "        print(f\"[WARN] AQICN returned error for {sensor_id}: {data.get('data')}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    time_info = data[\"data\"].get(\"time\")\n",
    "\n",
    "    if isinstance(time_info, dict):\n",
    "        ts_str = time_info.get(\"s\")\n",
    "    elif isinstance(time_info, str):\n",
    "        ts_str = time_info\n",
    "    else:\n",
    "        print(f\"[WARN] Unexpected time format for {sensor_id}: {time_info}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ts = pd.to_datetime(ts_str).tz_localize(None)\n",
    "\n",
    "    if since is not None:\n",
    "        since = since.tz_localize(None)\n",
    "\n",
    "    if since is not None and ts <= since:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pm25 = (\n",
    "        data[\"data\"]\n",
    "        .get(\"iaqi\", {})\n",
    "        .get(\"pm25\", {})\n",
    "        .get(\"v\", None)\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        \"sensor_id\": sensor_id,\n",
    "        \"date\": ts,\n",
    "        \"pm25\": pm25,\n",
    "        \"aqicn_url\": feed_url\n",
    "    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7140905",
   "metadata": {},
   "source": [
    "Incremental weather fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_weather(latitude, longitude, since):\n",
    "    if since is None:\n",
    "        since = datetime.now(timezone.utc) - pd.Timedelta(days=7)\n",
    "\n",
    "    since = since.replace(tzinfo=None)\n",
    "\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m,wind_speed_10m\",\n",
    "        \"start_date\": since.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d\"),\n",
    "        \"timezone\": \"UTC\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    if \"hourly\" not in data or \"time\" not in data[\"hourly\"]:\n",
    "        print(f\"[WARN] No weather data returned for lat={latitude}, lon={longitude}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data[\"hourly\"])\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.tz_localize(None)\n",
    "\n",
    "    df = df[df[\"date\"] > since]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60347210",
   "metadata": {},
   "source": [
    "## 1.8. Script\n",
    "Main processing logic - processes all sensors in the data folder, cleans data, fetches weather data, adds rolling averages and lagged features, and combines all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43c02d",
   "metadata": {},
   "source": [
    "Incremental ingestion loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg_weather = fs.get_feature_group(\"weather\", version=1)\n",
    "# fg_weather.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd26786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg_meta = fs.get_feature_group(\"sensor_metadata\", version=1)\n",
    "metadata_df = sensor_metadata_fg.read().set_index(\"sensor_id\")\n",
    "\n",
    "# fg_aq = fs.get_feature_group(\"air_quality\", version=1)\n",
    "# fg_weather = fs.get_feature_group(\"weather\", version=1)\n",
    "\n",
    "for sensor_id, meta in metadata_df.iterrows():\n",
    "\n",
    "    last_ts = latest_per_sensor.get(sensor_id)\n",
    "\n",
    "    aq_new = fetch_latest_aq_data(\n",
    "        sensor_id=sensor_id,\n",
    "        feed_url=meta[\"aqicn_url\"],\n",
    "        since=last_ts\n",
    "    )\n",
    "\n",
    "    weather_new = get_latest_weather(\n",
    "        latitude=meta[\"latitude\"],\n",
    "        longitude=meta[\"longitude\"],\n",
    "        since=last_ts\n",
    "    )\n",
    "\n",
    "    if not aq_new.empty:\n",
    "        aq_new[\"date\"] = aq_new[\"date\"].dt.tz_localize(None)\n",
    "        aq_new = airquality.add_rolling_window_feature(aq_new, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "        aq_new = airquality.add_lagged_features(aq_new, column=\"pm25\", lags=[1, 2, 3])\n",
    "        air_quality_fg.insert(aq_new)\n",
    "\n",
    "    if not weather_new.empty:\n",
    "        weather_new[\"date\"] = weather_new[\"date\"].dt.tz_localize(None)\n",
    "        weather_fg.insert(weather_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_air_quality_description(air_quality_fg)\n",
    "update_sensor_metadata_description(sensor_metadata_fg)\n",
    "update_weather_description(weather_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13eb2f",
   "metadata": {},
   "source": [
    "rebuild feature view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fv = fs.get_or_create_feature_view(\n",
    "#     name=\"air_quality_complete_fv\",\n",
    "#     version=1,\n",
    "#     query=fg_aq.select_all()\n",
    "#         .join(fg_weather.select_all(), on=[\"sensor_id\", \"date\"])\n",
    "#         .join(fg_meta.select_all(), on=\"sensor_id\"),\n",
    "#     labels=[\"pm25\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_aq_dfs = []\n",
    "# all_weather_dfs = []\n",
    "# locations = {}\n",
    "\n",
    "# # Process all files in data directory\n",
    "# data_dir = os.path.join(root_dir, \"data\")\n",
    "# dir_list = os.listdir(data_dir)\n",
    "# for file in dir_list:\n",
    "#     if file.endswith(\".csv\"):\n",
    "#         file_path = os.path.join(data_dir, file)\n",
    "#         aq_df_raw, street, city, country, feed_url, sensor_id = airquality.read_sensor_data(file_path, AQICN_API_KEY)\n",
    "#         aq_df = clean_and_append_data(aq_df_raw, street, city, country, feed_url, sensor_id)\n",
    "#         weather_df, latitude, longitude = get_historical_weather(\n",
    "#             city, aq_df, today, feed_url, sensor_id\n",
    "#         )\n",
    "#         aq_df[\"date\"] = aq_df[\"date\"].dt.tz_localize(None)\n",
    "#         weather_df[\"date\"] = weather_df[\"date\"].dt.tz_localize(None)\n",
    "#         all_aq_dfs.append(aq_df)\n",
    "#         all_weather_dfs.append(weather_df)\n",
    "#         locations[sensor_id] = {\n",
    "#             \"country\": country,\n",
    "#             \"city\": city,\n",
    "#             \"street\": street,\n",
    "#             \"aqicn_url\": feed_url,\n",
    "#             \"latitude\": latitude,\n",
    "#             \"longitude\": longitude,\n",
    "#         }\n",
    "\n",
    "# # Concatenate into single, uniform dfs\n",
    "# aq_df_all = pd.concat(all_aq_dfs, ignore_index=True)\n",
    "# weather_df_all = pd.concat(all_weather_dfs, ignore_index=True)\n",
    "# aq_df_all = airquality.add_rolling_window_feature(aq_df_all, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "# aq_df_all = airquality.add_lagged_features(aq_df_all, column=\"pm25\", lags=[1, 2, 3])\n",
    "# aq_df_all = airquality.add_nearby_sensor_feature(aq_df_all, locations, column=\"pm25_lag_1d\", n_closest=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in weather_df_all.columns:\n",
    "#     if weather_df_all[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "#         print(f\"‚ùå Column '{col}' contains dict values before insert!\")\n",
    "# print(weather_df_all.dtypes)\n",
    "# print(weather_df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in aq_df_all.columns:\n",
    "#     if aq_df_all[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "#         print(f\"‚ùå Column '{col}' contains dict values before insert!\")\n",
    "# print(aq_df_all.dtypes)\n",
    "# print(aq_df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741db4f",
   "metadata": {},
   "source": [
    "## 1.9. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9222740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üîç AIR QUALITY DATA EXPLORATION\")\n",
    "# print(\"=\"*40)\n",
    "# print(f\"Shape: {aq_df_all.shape}\")\n",
    "# print(f\"Date range: {aq_df_all['date'].min().date()} to {aq_df_all['date'].max().date()}\")\n",
    "# print(f\"Number of unique sensors: {aq_df_all['sensor_id'].nunique()}\")\n",
    "# print(f\"Countries: {aq_df_all['country'].unique()}\")\n",
    "# print(f\"Cities: {aq_df_all['city'].nunique()} unique cities\")\n",
    "\n",
    "# print(\"\\nüìä PM2.5 Statistics:\")\n",
    "# print(aq_df_all['pm25'].describe())\n",
    "# print(f\"Missing values: {aq_df_all['pm25'].isna().sum()}\")\n",
    "\n",
    "# print(\"\\nüìà Engineered Features Statistics:\")\n",
    "# for col in ['pm25_rolling_3d', 'pm25_lag_1d', 'pm25_lag_2d', 'pm25_lag_3d', 'pm25_nearby_avg']:\n",
    "#     if col in aq_df_all.columns:\n",
    "#         missing = aq_df_all[col].isna().sum()\n",
    "#         print(f\"{col}: {missing} missing values ({missing/len(aq_df_all)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab388f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üå§Ô∏è WEATHER DATA EXPLORATION\") \n",
    "# print(\"=\"*40)\n",
    "# print(f\"Shape: {weather_df_all.shape}\")\n",
    "# print(f\"Date range: {weather_df_all['date'].min().date()} to {weather_df_all['date'].max().date()}\")\n",
    "# print(f\"Number of unique sensors: {weather_df_all['sensor_id'].nunique()}\")\n",
    "\n",
    "# print(\"\\nüå°Ô∏è Weather Statistics:\")\n",
    "# for col in ['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']:\n",
    "#     if col in weather_df_all.columns:\n",
    "#         print(f\"{col}:\")\n",
    "#         print(f\"  Range: {weather_df_all[col].min():.2f} to {weather_df_all[col].max():.2f}, Mean: {weather_df_all[col].mean():.2f}, Missing: {weather_df_all[col].isna().sum()}\")\n",
    "\n",
    "# print(\"\\nüìç Geographic Coverage:\")\n",
    "# print(f\"Latitude range: {weather_df_all['latitude'].min():.3f} to {weather_df_all['latitude'].max():.3f}, Longitude range: {weather_df_all['longitude'].min():.3f} to {weather_df_all['longitude'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129aa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"üîó DATA QUALITY & RELATIONSHIPS\")\n",
    "# print(\"=\"*40)\n",
    "\n",
    "# # Overall data completeness\n",
    "# sensor_day_counts = aq_df_all.groupby('sensor_id')['date'].count()\n",
    "# total_records = len(aq_df_all)\n",
    "# data_completeness = (1 - aq_df_all['pm25'].isna().sum() / total_records) * 100\n",
    "\n",
    "# print(f\"üìä Overall Data Quality:\")\n",
    "# print(f\"Total records: {total_records:,}\")\n",
    "# print(f\"Data completeness: {data_completeness:.1f}%\")\n",
    "# print(f\"Days per sensor - Min: {sensor_day_counts.min()}, Median: {sensor_day_counts.median():.0f}, Max: {sensor_day_counts.max()}\")\n",
    "# print(f\"Sensors with <30 days: {(sensor_day_counts < 30).sum()}, >365 days: {(sensor_day_counts > 365).sum()}\")\n",
    "\n",
    "# # Extreme values summary\n",
    "# extreme_count = (aq_df_all['pm25'] > 100).sum()\n",
    "# very_high_count = (aq_df_all['pm25'] > 50).sum()\n",
    "# print(f\"\\n‚ö†Ô∏è Air Quality Levels:\")\n",
    "# print(f\"Extreme readings (>100 Œºg/m¬≥): {extreme_count} ({extreme_count/total_records*100:.1f}%)\")\n",
    "# print(f\"Very high readings (>50 Œºg/m¬≥): {very_high_count} ({very_high_count/total_records*100:.1f}%)\")\n",
    "\n",
    "# # Seasonal patterns\n",
    "# if len(aq_df_all) > 0:\n",
    "#     # Create temporary month column without modifying original DataFrame\n",
    "#     temp_months = pd.to_datetime(aq_df_all['date']).dt.month\n",
    "#     monthly_pm25 = aq_df_all.groupby(temp_months)['pm25'].mean()\n",
    "#     print(f\"\\nüóìÔ∏è Seasonal Patterns (PM2.5 Œºg/m¬≥):\")\n",
    "#     seasons = {(12,1,2): \"Winter\", (3,4,5): \"Spring\", (6,7,8): \"Summer\", (9,10,11): \"Autumn\"}\n",
    "#     for months, season in seasons.items():\n",
    "#         season_avg = monthly_pm25[monthly_pm25.index.isin(months)].mean()\n",
    "#         print(f\"  {season}: {season_avg:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3415e",
   "metadata": {},
   "source": [
    "## 1.10. Store Sensor Location\n",
    "Create Hopsworks secrets for each sensor's location metadata (coordinates, address, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82031a",
   "metadata": {},
   "source": [
    "## 1.11. Upload to Hopsworks\n",
    "Insert the processed air quality and weather data into Hopsworks feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = meta[\"latitude\"]\n",
    "lon = meta[\"longitude\"]\n",
    "feed_url = meta[\"aqicn_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b277c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_feature_group(\"air_quality\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67896847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(air_quality_fg.read().dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
