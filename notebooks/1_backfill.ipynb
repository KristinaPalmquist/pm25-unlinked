{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a14877f",
   "metadata": {},
   "source": [
    "# 1. Backfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae8d7e",
   "metadata": {},
   "source": [
    "## 1.1. Environment Setup\n",
    "Handle repository cloning, dependency installation, and set up Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b485ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HopsworksSettings initialized!\n",
      "2025-12-15 09:42:41,431 INFO: Initializing external client\n",
      "2025-12-15 09:42:41,432 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-15 09:42:42,180 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-15 09:42:43,199 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import hopsworks\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    repo_dir = Path(\"pm25-forecast-openmeteo-aqicn\")\n",
    "    if repo_dir.exists():\n",
    "        print(f\"Repository already exists at {repo_dir.absolute()}\")\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "    else:\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/KristinaPalmquist/pm25-forecast-openmeteo-aqicn.git\n",
    "        %cd pm25-forecast-openmeteo-aqicn\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "for folder in (\"src\", \"airquality\", \"notebooks\"):\n",
    "    if root_dir.parts[-1:] == (folder,):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir)\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "from utils import config\n",
    "\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad128c99",
   "metadata": {},
   "source": [
    "## 1.2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3649091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "import hopsworks\n",
    "from utils import airquality\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322e26a",
   "metadata": {},
   "source": [
    "## 1.3. Setup\n",
    "Configure Hopsworks connection, feature store access, and AQICN API key handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad12486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-15 09:42:45,710 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-12-15 09:42:45,717 INFO: Initializing external client\n",
      "2025-12-15 09:42:45,718 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-15 09:42:47,227 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279184\n",
      "Replacing existing AQICN_API_KEY\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "\n",
    "HOPSWORKS_API_KEY = settings.HOPSWORKS_API_KEY.get_secret_value()\n",
    "project = hopsworks.login(engine=\"python\", api_key_value=HOPSWORKS_API_KEY)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"You need to set AQICN_API_KEY either in this cell or in ~/.env\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "try:\n",
    "    secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "    if secret is not None:\n",
    "        secret.delete()\n",
    "        print(\"Replacing existing AQICN_API_KEY\")\n",
    "except hopsworks.RestAPIError as e:\n",
    "    if hasattr(e, \"error_code\") and getattr(e, \"error_code\", None) == 160048:\n",
    "        pass\n",
    "    elif \"Could not find Secret\" in str(e):\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fff50",
   "metadata": {},
   "source": [
    "## 1.4. Processing Mode\n",
    "This notebook processes all sensors that have CSV files in the `data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1641ed",
   "metadata": {},
   "source": [
    "## 1.5. Data Validation Setup\n",
    "Creates Great Expectations validation suites for air quality and weather data with column value constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef87eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"pm25\",\n",
    "            \"min_value\": -0.1,\n",
    "            \"max_value\": 500.0,\n",
    "            \"strict_min\": True,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\": col,\n",
    "                \"min_value\": -0.1,\n",
    "                \"max_value\": 1000.0,\n",
    "                \"strict_min\": True,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68ea8b",
   "metadata": {},
   "source": [
    "## 1.6. Helper Methods\n",
    "Data processing functions - clean air quality data and fetch historical weather data with API rate limiting and retry logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffcc2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_append_data(df, street, city, country, feed_url, sensor_id):\n",
    "    \"\"\"\n",
    "    Remove any unused columns, set the daily median value to pm25. Remove NaN's and append the metadata.\n",
    "    \"\"\"\n",
    "    clean_df = pd.DataFrame()\n",
    "    clean_df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    clean_df[\"pm25\"] = df[\"median\"]\n",
    "    clean_df = clean_df.dropna(subset=[\"pm25\"])\n",
    "    clean_df[\"sensor_id\"] = sensor_id\n",
    "    clean_df[\"street\"] = street\n",
    "    clean_df[\"city\"] = city\n",
    "    clean_df[\"country\"] = country\n",
    "    clean_df[\"feed_url\"] = feed_url\n",
    "    return clean_df\n",
    "\n",
    "def get_historical_weather(city, df, today, feed_url, sensor_id):\n",
    "    earliest_aq_date = pd.Series.min(df[\"date\"])\n",
    "    earliest_aq_date = earliest_aq_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    try:\n",
    "        latitude, longitude, working_feed_url = airquality.get_sensor_coordinates_with_fallback(sensor_id, AQICN_API_KEY)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to get coordinates for sensor {sensor_id}: {e}\")\n",
    "    \n",
    "    max_retries = 5\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            weather_df = airquality.get_historical_weather(\n",
    "                city, earliest_aq_date, str(today), latitude, longitude\n",
    "            )\n",
    "            weather_df[\"sensor_id\"] = sensor_id\n",
    "            weather_df[\"city\"] = city\n",
    "            weather_df[\"latitude\"] = latitude\n",
    "            weather_df[\"longitude\"] = longitude\n",
    "            return weather_df, latitude, longitude\n",
    "        except Exception as e:\n",
    "            if hasattr(e, \"args\") and any(\n",
    "                \"Minutely API request limit exceeded\" in str(a) for a in e.args\n",
    "            ):\n",
    "                wait_time = 70\n",
    "                print(\n",
    "                    f\"OpenMeteo API limit exceeded, retrying in {wait_time} seconds... (Attempt {attempt + 1} of {max_retries})\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            elif \"Minutely API request limit exceeded\" in str(e):\n",
    "                wait_time = 70\n",
    "                print(\n",
    "                    f\"OpenMeteo API limit exceeded, retrying in {wait_time} seconds... (Attempt {attempt + 1} of {max_retries})\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                raise\n",
    "    raise RuntimeError(\n",
    "        \"Failed to obtain historical weather after multiple retries due to API rate limits.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1310d",
   "metadata": {},
   "source": [
    "## 1.7. Hopsworks\n",
    "Feature Group Management - functions to create and manage air quality and weather feature groups in Hopsworks, including schema descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a89e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create air quality feature group\n",
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name=\"air_quality_all\",\n",
    "    description=\"Air Quality characteristics of each day for all sensors\",\n",
    "    version=1,\n",
    "    primary_key=[\"sensor_id\"],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ea6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(new_df=None):\n",
    "    \"\"\"\n",
    "    Remove duplicate entries from the Hopsworks feature group, keeping only the latest for each (sensor_id, date).\n",
    "    If new_df is provided, also remove any rows from new_df that would duplicate (sensor_id, date) already present in the feature group.\n",
    "    Returns a deduplicated DataFrame for upload (if new_df is provided), else None.\n",
    "    \"\"\"\n",
    "    # Try to read from the feature group, handle empty case\n",
    "    try:\n",
    "        df = air_quality_fg.read()\n",
    "        feature_group_empty = df.empty\n",
    "    except Exception as e:\n",
    "        print(\"Feature group is empty or cannot be read. Skipping FG deduplication.\")\n",
    "        feature_group_empty = True\n",
    "        df = None\n",
    "\n",
    "    # Deduplicate new_df in-memory before upload\n",
    "    if new_df is not None:\n",
    "        # Remove duplicates within new_df itself (by sensor_id and date)\n",
    "        new_df = new_df.sort_values(['sensor_id', 'date'])\n",
    "        new_df = new_df.drop_duplicates(subset=['sensor_id', 'date'], keep='last')\n",
    "        if not feature_group_empty:\n",
    "            # Remove rows from new_df that already exist in the feature group\n",
    "            df_keys = df[['sensor_id', 'date']].drop_duplicates()\n",
    "            new_df = new_df.copy()\n",
    "            df_keys = df_keys.copy()\n",
    "            # Ensure both are timezone-naive\n",
    "            new_df['date'] = pd.to_datetime(new_df['date']).dt.tz_localize(None)\n",
    "            df_keys['date'] = pd.to_datetime(df_keys['date']).dt.tz_localize(None)\n",
    "            merged = new_df.merge(df_keys, on=['sensor_id', 'date'], how='left', indicator=True)\n",
    "            deduped_new_df = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "            print(f\"Filtered out {len(new_df) - len(deduped_new_df)} rows from new data that already exist in feature group.\")\n",
    "            new_df = deduped_new_df\n",
    "        # Final check: ensure no duplicates remain in new_df\n",
    "        final_dupes = new_df.duplicated(subset=['sensor_id', 'date'], keep=False)\n",
    "        if final_dupes.any():\n",
    "            print(\"Warning: Duplicates still present in new_df after deduplication. Removing all but the last occurrence.\")\n",
    "            new_df = new_df.drop_duplicates(subset=['sensor_id', 'date'], keep='last')\n",
    "        return new_df\n",
    "\n",
    "    # If feature group is not empty, deduplicate it\n",
    "    if not feature_group_empty:\n",
    "        df_sorted = df.sort_values(['sensor_id', 'date'])\n",
    "        mask = df_sorted.duplicated(subset=['sensor_id', 'date'], keep='last')\n",
    "        duplicates = df_sorted[mask]\n",
    "        print(f\"Found {len(duplicates)} duplicate rows to delete in feature group.\")\n",
    "        for _, row in duplicates.iterrows():\n",
    "            air_quality_fg.delete_record({\"sensor_id\": row[\"sensor_id\"], \"date\": row[\"date\"]})\n",
    "        print(\"Duplicate rows deleted from feature group.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ad363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_air_quality_description(air_quality_fg):\n",
    "#     \"\"\"\n",
    "#     Update feature descriptions for the air quality feature group in Hopsworks.\n",
    "#     \"\"\"\n",
    "#     air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "#     air_quality_fg.update_feature_description(\"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\")\n",
    "#     air_quality_fg.update_feature_description(\"pm25\", \"Daily median PM2.5 value (Î¼g/mÂ³)\")\n",
    "#     air_quality_fg.update_feature_description(\"street\", \"Street where sensor is located\")\n",
    "#     air_quality_fg.update_feature_description(\"city\", \"City where sensor is located\")\n",
    "#     air_quality_fg.update_feature_description(\"country\", \"Country where sensor is located\")\n",
    "#     air_quality_fg.update_feature_description(\"feed_url\", \"AQICN feed URL for the sensor\")\n",
    "\n",
    "def update_air_quality_description(air_quality_fg):\n",
    "    air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "    air_quality_fg.update_feature_description(\"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\")\n",
    "    air_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in aqicn.org)\")\n",
    "    air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "    air_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\n",
    "    air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "    air_quality_fg.update_feature_description(\"pm25_rolling_3d\", \"3-day rolling mean of PM2.5 from previous days (lagged by 1 day for point-in-time correctness).\")\n",
    "    air_quality_fg.update_feature_description(\"pm25_lag_1d\", \"PM2.5 value from 1 day ago.\")\n",
    "    air_quality_fg.update_feature_description(\"pm25_lag_2d\", \"PM2.5 value from 2 days ago.\")\n",
    "    air_quality_fg.update_feature_description(\"pm25_lag_3d\", \"PM2.5 value from 3 days ago.\")\n",
    "    air_quality_fg.update_feature_description(\"pm25_nearby_avg\", \"Average PM2.5 value from the 3 closest sensors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45dfd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_insert_weather_data(df):\n",
    "    # Create or get the weather feature group\n",
    "    weather_fg = fs.get_or_create_feature_group(\n",
    "        name=\"weather_all\",\n",
    "        description=\"Weather characteristics of each day for all sensors\",\n",
    "        version=1,\n",
    "        primary_key=[\"sensor_id\"],\n",
    "        event_time=\"date\",\n",
    "        expectation_suite=weather_expectation_suite,\n",
    "    )\n",
    "    # Deduplicate new data before upload (by sensor_id, date)\n",
    "    df = df.sort_values(['sensor_id', 'date'])\n",
    "    deduped_df = df.drop_duplicates(subset=['sensor_id', 'date'], keep='last')\n",
    "    weather_fg.insert(deduped_df)\n",
    "    # Update feature descriptions\n",
    "    weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "    weather_fg.update_feature_description(\"sensor_id\", \"AQICN sensor identifier (e.g., 59893)\")\n",
    "    weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "    weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "    weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "    weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m above ground\")\n",
    "    weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the days\")\n",
    "    weather_fg.update_feature_description(\"latitude\", \"Latitude of sensor location used for weather retrieval\")\n",
    "    weather_fg.update_feature_description(\"longitude\", \"Longitude of sensor location used for weather retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70d76a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_insert_air_quality_data(df):\n",
    "    # 1. Clean up the feature group (remove existing duplicates)\n",
    "    remove_duplicates()\n",
    "    # 2. Deduplicate new data before upload (prevents new duplicates)\n",
    "    deduped_df = remove_duplicates(df)\n",
    "    air_quality_fg.insert(deduped_df)\n",
    "    # 3. Update feature group schema descriptions\n",
    "    update_air_quality_description(air_quality_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60347210",
   "metadata": {},
   "source": [
    "## 1.8. Script\n",
    "Main processing logic - processes all sensors in the data folder, cleans data, fetches weather data, adds rolling averages and lagged features, and combines all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66998612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Skipping sensor 84085: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 87319: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 88372: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 88876: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 89584: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 90676: OpenMeteo hourly API limit exceeded\n",
      "âš ï¸  Skipping sensor 92683: OpenMeteo hourly API limit exceeded\n",
      "\n",
      "==================================================\n",
      "ðŸ“‹ PROCESSING SUMMARY\n",
      "==================================================\n",
      "âœ… Successfully processed: 96 sensors\n",
      "âŒ Skipped sensors (7): 84085, 87319, 88372, 88876, 89584, 90676, 92683\n",
      "   - 7 sensors: OpenMeteo hourly API limit exceeded\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_aq_dfs = []\n",
    "all_weather_dfs = []\n",
    "locations = {}\n",
    "skipped_sensors = []\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "dir_list = os.listdir(data_dir)\n",
    "for file in dir_list:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    if os.path.isdir(file_path) or not file.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        aq_df_raw, street, city, country, feed_url, sensor_id = airquality.read_sensor_data(file_path)\n",
    "        aq_df = clean_and_append_data(aq_df_raw, street, city, country, feed_url, sensor_id)\n",
    "        weather_df, latitude, longitude = get_historical_weather(\n",
    "            city, aq_df, today, feed_url, sensor_id\n",
    "        )\n",
    "    except Exception as e:\n",
    "        file_sensor_id = file.replace('.csv', '')\n",
    "        \n",
    "        error_type = type(e).__name__\n",
    "        if \"OpenMeteoRequestsError\" in error_type:\n",
    "            if \"Hourly API request limit exceeded\" in str(e):\n",
    "                reason = \"OpenMeteo hourly API limit exceeded\"\n",
    "            elif \"Minutely API request limit exceeded\" in str(e):\n",
    "                reason = \"OpenMeteo minutely API limit exceeded\"\n",
    "            else:\n",
    "                reason = \"OpenMeteo API error\"\n",
    "        elif \"ValueError\" in error_type:\n",
    "            reason = \"Coordinate/data error\"\n",
    "        else:\n",
    "            reason = error_type\n",
    "        \n",
    "        print(f\"âš ï¸  Skipping sensor {file_sensor_id}: {reason}\")\n",
    "        skipped_sensors.append((file_sensor_id, reason))\n",
    "        continue\n",
    "\n",
    "    all_aq_dfs.append(aq_df)\n",
    "    all_weather_dfs.append(weather_df)\n",
    "    locations[sensor_id] = {\n",
    "        \"country\": country,\n",
    "        \"city\": city,\n",
    "        \"street\": street,\n",
    "        \"aqicn_url\": feed_url,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "    }\n",
    "\n",
    "# Print processing summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“‹ PROCESSING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"âœ… Successfully processed: {len(locations)} sensors\")\n",
    "if skipped_sensors:\n",
    "    print(f\"âŒ Skipped sensors ({len(skipped_sensors)}): {', '.join([s[0] for s in skipped_sensors])}\")\n",
    "    \n",
    "    # Group by reason for clean summary\n",
    "    from collections import Counter\n",
    "    reason_counts = Counter([reason for _, reason in skipped_sensors])\n",
    "    for reason, count in reason_counts.items():\n",
    "        print(f\"   - {count} sensors: {reason}\")\n",
    "else:\n",
    "    print(\"âœ… No sensors were skipped!\")\n",
    "\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Concatenate into single, uniform dfs\n",
    "aq_df_all = pd.concat(all_aq_dfs, ignore_index=True)\n",
    "weather_df_all = pd.concat(all_weather_dfs, ignore_index=True)\n",
    "aq_df_all = airquality.add_rolling_window_feature(aq_df_all, window_days=3, column=\"pm25\", new_column=\"pm25_rolling_3d\")\n",
    "aq_df_all = airquality.add_lagged_features(aq_df_all, column=\"pm25\", lags=[1, 2, 3])\n",
    "aq_df_all = airquality.add_nearby_sensor_feature(aq_df_all, locations, column=\"pm25_lag_1d\", n_closest=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741db4f",
   "metadata": {},
   "source": [
    "## 1.9. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9222740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” AIR QUALITY DATA EXPLORATION\n",
      "========================================\n",
      "Shape: (151517, 12)\n",
      "Date range: 2019-12-09 to 2025-12-04\n",
      "Number of unique sensors: 96\n",
      "Countries: ['Sweden']\n",
      "Cities: 81 unique cities\n",
      "\n",
      "ðŸ“Š PM2.5 Statistics:\n",
      "count    151517.000000\n",
      "mean          3.226778\n",
      "std          12.361850\n",
      "min           0.000000\n",
      "25%           0.900000\n",
      "50%           1.800000\n",
      "75%           3.500000\n",
      "max         999.900000\n",
      "Name: pm25, dtype: float64\n",
      "Missing values: 0\n",
      "\n",
      "ðŸ“ˆ Engineered Features Statistics:\n",
      "pm25_rolling_3d: 96 missing values (0.1%)\n",
      "pm25_lag_1d: 96 missing values (0.1%)\n",
      "pm25_lag_2d: 192 missing values (0.1%)\n",
      "pm25_lag_3d: 288 missing values (0.2%)\n",
      "pm25_nearby_avg: 3354 missing values (2.2%)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” AIR QUALITY DATA EXPLORATION\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Shape: {aq_df_all.shape}\")\n",
    "print(f\"Date range: {aq_df_all['date'].min().date()} to {aq_df_all['date'].max().date()}\")\n",
    "print(f\"Number of unique sensors: {aq_df_all['sensor_id'].nunique()}\")\n",
    "print(f\"Countries: {aq_df_all['country'].unique()}\")\n",
    "print(f\"Cities: {aq_df_all['city'].nunique()} unique cities\")\n",
    "\n",
    "print(\"\\nðŸ“Š PM2.5 Statistics:\")\n",
    "print(aq_df_all['pm25'].describe())\n",
    "print(f\"Missing values: {aq_df_all['pm25'].isna().sum()}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Engineered Features Statistics:\")\n",
    "for col in ['pm25_rolling_3d', 'pm25_lag_1d', 'pm25_lag_2d', 'pm25_lag_3d', 'pm25_nearby_avg']:\n",
    "    if col in aq_df_all.columns:\n",
    "        missing = aq_df_all[col].isna().sum()\n",
    "        print(f\"{col}: {missing} missing values ({missing/len(aq_df_all)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab388f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¤ï¸ WEATHER DATA EXPLORATION\n",
      "========================================\n",
      "Shape: (176470, 9)\n",
      "Date range: 2019-12-09 to 2025-12-15\n",
      "Number of unique sensors: 96\n",
      "\n",
      "ðŸŒ¡ï¸ Weather Statistics:\n",
      "temperature_2m_mean:\n",
      "  Range: -31.30 to 27.15, Mean: 7.93, Missing: 0\n",
      "precipitation_sum:\n",
      "  Range: 0.00 to 105.10, Mean: 2.22, Missing: 0\n",
      "wind_speed_10m_max:\n",
      "  Range: 3.05 to 74.15, Mean: 18.60, Missing: 0\n",
      "wind_direction_10m_dominant:\n",
      "  Range: 0.00 to 360.00, Mean: 199.71, Missing: 0\n",
      "\n",
      "ðŸ“ Geographic Coverage:\n",
      "Latitude range: 55.476 to 64.944, Longitude range: 11.166 to 20.874\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŒ¤ï¸ WEATHER DATA EXPLORATION\") \n",
    "print(\"=\"*40)\n",
    "print(f\"Shape: {weather_df_all.shape}\")\n",
    "print(f\"Date range: {weather_df_all['date'].min().date()} to {weather_df_all['date'].max().date()}\")\n",
    "print(f\"Number of unique sensors: {weather_df_all['sensor_id'].nunique()}\")\n",
    "\n",
    "print(\"\\nðŸŒ¡ï¸ Weather Statistics:\")\n",
    "for col in ['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']:\n",
    "    if col in weather_df_all.columns:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"  Range: {weather_df_all[col].min():.2f} to {weather_df_all[col].max():.2f}, Mean: {weather_df_all[col].mean():.2f}, Missing: {weather_df_all[col].isna().sum()}\")\n",
    "\n",
    "print(\"\\nðŸ“ Geographic Coverage:\")\n",
    "print(f\"Latitude range: {weather_df_all['latitude'].min():.3f} to {weather_df_all['latitude'].max():.3f}, Longitude range: {weather_df_all['longitude'].min():.3f} to {weather_df_all['longitude'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3415e",
   "metadata": {},
   "source": [
    "## 1.10. Store Sensor Location\n",
    "Create Hopsworks secrets for each sensor's location metadata (coordinates, address, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dfef0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    }
   ],
   "source": [
    "for sensor_id, location in locations.items():\n",
    "    secret_name = f\"SENSOR_LOCATION_JSON_{sensor_id}\"\n",
    "    location_str = json.dumps(location)\n",
    "    \n",
    "    try:\n",
    "        secret = secrets.get_secret(secret_name)\n",
    "        if secret is not None:\n",
    "            secret.delete()\n",
    "    except hopsworks.RestAPIError as e:\n",
    "        if hasattr(e, \"error_code\") and getattr(e, \"error_code\", None) == 160048:\n",
    "            pass\n",
    "        elif \"Could not find Secret\" in str(e):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    secrets.create_secret(secret_name, location_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82031a",
   "metadata": {},
   "source": [
    "## 1.11. Upload to Hopsworks\n",
    "Insert the processed air quality and weather data into Hopsworks feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f08d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (4.80s) \n",
      "Found 0 duplicate rows to delete in feature group.\n",
      "Duplicate rows deleted from feature group.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.51s) \n",
      "Filtered out 151511 rows from new data that already exist in feature group.\n",
      "2025-12-15 09:47:51,889 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1774972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 0.00% |          | Rows 0/0 | Elapsed Time: 00:00 | Remaining Time: ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/air_quality_all_1_offline_fg_materialization/executions\n",
      "2025-12-15 09:48:14,125 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279184/fs/1265800/fg/1783130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 176470/176470 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_all_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279184/jobs/named/weather_all_1_offline_fg_materialization/executions\n"
     ]
    }
   ],
   "source": [
    "create_and_insert_air_quality_data(aq_df_all)\n",
    "create_and_insert_weather_data(weather_df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
